<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" xml:id="_nyUEXzS" coord="1,80.70,104.54,425.78,13.41;1,80.70,121.48,113.43,13.41">GRACE: A General Graph Convolution Framework for Attributed Graph Clustering</title>
				<funder>
					<orgName type="full">RGC of HKSAR</orgName>
				</funder>
				<funder ref="#_AH674zK">
					<orgName type="full">GRF</orgName>
				</funder>
				<funder ref="#_kVDevC5">
					<orgName type="full">RGC Early Career Scheme</orgName>
				</funder>
				<funder ref="#_Cuxc24B">
					<orgName type="full">NSFC Young Scientists Fund</orgName>
				</funder>
				<funder ref="#_U5Tu6Pg">
					<orgName type="full">CUHK</orgName>
				</funder>
				<funder ref="#_tWBgkD4">
					<orgName type="full">RGC RIF</orgName>
				</funder>
				<funder ref="#_jDsXcuH #_DTTPBdA">
					<orgName type="full">RGC GRF</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computing Machinery (ACM)</publisher>
				<availability status="unknown"><p>Copyright Association for Computing Machinery (ACM)</p>
				</availability>
				<date type="published" when="2023-02-22">2023-02-22</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,80.70,146.85,162.53,11.29;1,243.23,144.77,1.00,8.28"><forename type="first">Barakeel</forename><surname>Fanseu Kamhoua</surname></persName>
							<idno type="ORCID">0000-0001-5801-3216</idno>
						</author>
						<author>
							<persName><forename type="first">Lin</forename><surname>Zhang</surname></persName>
							<idno type="ORCID">0000-0001-8493-4705</idno>
						</author>
						<author>
							<persName><forename type="first">Kaili</forename><surname>Ma</surname></persName>
							<idno type="ORCID">0000-0001-9484-8915</idno>
						</author>
						<author>
							<persName><forename type="first">James</forename><surname>Cheng</surname></persName>
							<idno type="ORCID">0000-0001-6313-6288</idno>
						</author>
						<author>
							<persName><forename type="first">Bo</forename><surname>Li</surname></persName>
							<idno type="ORCID">0000-0003-2955-750X</idno>
						</author>
						<author>
							<persName><forename type="first">Bo</forename><surname>Han</surname></persName>
							<idno type="ORCID">0000-0002-6338-0958</idno>
						</author>
						<author>
							<affiliation key="aff0">
								<note type="raw_affiliation">The Chinese University of Hong Kong,</note>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<note type="raw_affiliation">LIN ZHANG * , The Hong Kong University of Science and Technology,</note>
								<orgName type="institution" key="instit1">LIN ZHANG *</orgName>
								<orgName type="institution" key="instit2">The Hong Kong University of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<note type="raw_affiliation">KAILI MA, The Chinese University of Hong Kong,</note>
								<orgName type="institution" key="instit1">KAILI MA</orgName>
								<orgName type="institution" key="instit2">The Chinese University of Hong Kong</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<note type="raw_affiliation">JAMES CHENG</note>
								<orgName type="institution">JAMES CHENG</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<note type="raw_affiliation"><label>2</label> , The Chinese University of Hong Kong, BO LI, The Hong Kong University of Science and Technology, BO HAN, Hong Kong Baptist University,</note>
								<orgName type="institution" key="instit1">The Chinese University of Hong Kong</orgName>
								<orgName type="institution" key="instit2">The Hong Kong University of Science and Technology</orgName>
								<orgName type="institution" key="instit3">HAN</orgName>
								<orgName type="institution" key="instit4">Hong Kong Baptist University</orgName>
								<address>
									<region>BO LI, BO</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<note type="raw_affiliation">The Chinese University of Hong Kong, Hong Kong, ; Lin Zhang,</note>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
								<address>
									<settlement>Hong Kong, ; Lin Zhang</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<note type="raw_affiliation">The Hong Kong University of Science and Technology, Hong Kong, ; Kaili Ma,</note>
								<orgName type="institution">The Hong Kong University of Science and Technology</orgName>
								<address>
									<settlement>Hong Kong, Kaili Ma</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff7">
								<note type="raw_affiliation">The Chinese University of Hong Kong, Hong Kong, ; James Cheng,</note>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
								<address>
									<settlement>Hong Kong, ; James Cheng</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff8">
								<note type="raw_affiliation">The Chinese University of Hong Kong, Hong Kong, ; Bo Li,</note>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
								<address>
									<settlement>Hong Kong, ; Bo Li</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff9">
								<note type="raw_affiliation">The Hong Kong University of Science and Technology, Hong Kong, ; Bo Han,</note>
								<orgName type="institution">The Hong Kong University of Science and Technology</orgName>
								<address>
									<settlement>Hong Kong, ; Bo Han</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff10">
								<note type="raw_affiliation">Baptist University, Hong Kong,</note>
								<orgName type="institution">Baptist University</orgName>
								<address>
									<settlement>Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" xml:id="_kWzsuUa" coord="1,80.70,104.54,425.78,13.41;1,80.70,121.48,113.43,13.41">GRACE: A General Graph Convolution Framework for Attributed Graph Clustering</title>
					</analytic>
					<monogr>
						<title level="j" type="main" xml:id="_TQvsVCQ">ACM Transactions on Knowledge Discovery from Data</title>
						<title level="j" type="abbrev">ACM Trans. Knowl. Discov. Data</title>
						<idno type="ISSN">1556-4681</idno>
						<idno type="eISSN">1556-472X</idno>
						<imprint>
							<publisher>Association for Computing Machinery (ACM)</publisher>
							<biblScope unit="volume">17</biblScope>
							<biblScope unit="issue">3</biblScope>
							<biblScope unit="page" from="1" to="31"/>
							<date type="published" when="2023-02-22" />
						</imprint>
					</monogr>
					<idno type="MD5">D468534541B5F5A825979FD1CF09EBFC</idno>
					<idno type="DOI">10.1145/3544977</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-14T01:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords xml:id="_h9YGVBh">Attributed graph clustering; Graph convolution</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0" xml:id="_z7htSsK"><p xml:id="_r7XpM69"><s xml:id="_nvfCvsz" coords="1,80.38,236.90,450.92,8.48;1,80.70,247.86,212.80,8.48">Attributed graph clustering (AGC) is an important problem in graph mining as more and more complex data in real-world have been represented in graphs with attributed nodes.</s><s xml:id="_NM7BQUc" coords="1,296.76,247.86,234.55,8.48;1,80.70,258.81,450.61,8.48;1,80.70,269.77,424.44,8.48">While it is a common practice to leverage both attribute and structure information for improved clustering performance, most existing AGC algorithms consider only a speciic type of relations, which hinders their applicability to integrate various complex relations into node attributes for AGC.</s><s xml:id="_2dJqeJV" coords="1,507.45,269.77,23.85,8.48;1,80.70,280.73,308.62,8.48">In this paper, we propose GRACE, an extended graph convolution framework for AGC tasks.</s><s xml:id="_Ht6XAyS" coords="1,391.56,280.73,139.75,8.48;1,80.70,291.69,450.60,8.48;1,80.70,302.65,104.17,8.48">Our framework provides a general and interpretative solution for clustering many diferent types of attributed graphs, including undirected, directed, heterogeneous and hyper attributed graphs.</s><s xml:id="_9PDQxYE" coords="1,187.12,302.65,344.18,8.48;1,80.70,313.61,370.95,8.48">By building suitable graph Laplacians for each of the aforementioned graph types, GRACE can seamlessly perform graph convolution on node attributes to fuse all available information for clustering.</s><s xml:id="_aar3B4C" coords="1,453.59,313.61,77.71,8.48;1,80.70,324.57,231.46,8.48">We conduct extensive experiments on 14 real-world datasets of 4 diferent graph types.</s><s xml:id="_J5uZkMH" coords="1,314.35,324.57,216.96,8.48;1,80.70,335.53,418.01,8.48">The experimental results show that GRACE outperforms the state-of-the-art AGC methods on the diferent graph types in terms of clustering quality, time, and memory usage.</s><s xml:id="_vwVWu59" coords="1,80.70,350.77,277.85,8.56">CCS Concepts: • Information systems → Clustering and classiication.</s></p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="17" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="18" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="19" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="20" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="21" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="22" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="23" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="24" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="25" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="26" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="27" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="28" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="29" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="30" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1" xml:id="_4uAWKQs">INTRODUCTION</head><p xml:id="_nvWbbjx"><s xml:id="_FGrgXTq" coords="1,80.35,402.08,452.05,9.42;1,80.33,414.04,165.96,9.42">Attributed graphs can be used to represent complex data in many application domains including social networks, web pages, and recommendation systems.</s><s xml:id="_BvwX483" coords="1,248.50,414.04,282.80,9.42;1,80.70,425.99,450.61,9.42;1,80.70,437.95,76.42,9.42">Nodes in an attributed graph are associated with a number of attributes that describe the characteristics of objects, and edges (which can be of diferent types) represent the relationships among the objects.</s></p><p xml:id="_8Q6eUqU"><s xml:id="_uNrm7RT" coords="1,90.66,449.90,442.17,9.42">Attributed graph clustering (AGC) is one of the most signiicant graph mining problems with many applications.</s><s xml:id="_MsxaWdn" coords="1,80.35,461.86,450.95,9.42;1,80.70,473.81,451.70,9.42;2,80.70,107.52,295.60,9.42">AGC aims at partitioning the nodes in an attributed graph into a number of clusters such that <ref type="bibr" coords="1,467.68,461.86,10.70,9.42" target="#b0">(1)</ref> nodes in the same cluster should share similar attributes, and (2) nodes in diferent clusters should be minimally connected, i.e., a cluster should have minimal edges connecting it to other clusters.</s><s xml:id="_evjJnYV" coords="2,378.80,107.52,152.51,9.42;2,80.70,119.47,150.18,9.42">Clustering results are very helpful to study and understand the graph data.</s><s xml:id="_vhd4yVe" coords="2,233.38,119.47,298.18,9.42;2,80.70,131.43,451.96,9.42">For example, AGC can be used to discover social circles for social network analysis <ref type="bibr" coords="2,115.70,131.43,16.31,9.42" target="#b33">[34]</ref> or improve the search quality by ranking web pages associated with their cluster information <ref type="bibr" coords="2,514.17,131.43,14.79,9.42" target="#b60">[61]</ref>.</s><s xml:id="_Cc9F8Hv" coords="2,90.66,345.88,279.78,9.42">However, clustering attributed graphs poses signiicant challenges.</s><s xml:id="_7hVZB5K" coords="2,373.41,345.88,157.88,9.42;2,80.70,357.84,450.61,9.42;2,80.70,369.79,209.87,9.42">On the one hand, traditional methods that focus on either node attributes or graph structure can lead to poor clustering results, as only one type of information is utilized in clustering the graph.</s><s xml:id="_JMdVc2g" coords="2,294.18,369.79,224.99,9.42">An illustrating example of AGC is given in Figure <ref type="figure" coords="2,512.21,369.79,3.48,9.42" target="#fig_0">1</ref>.</s><s xml:id="_4qyzWb5" coords="2,522.78,369.79,8.53,9.42;2,80.70,381.75,450.61,9.42;2,80.70,393.70,207.45,9.42">In attribute-based clustering, as shown in Figure <ref type="figure" coords="2,274.49,381.75,3.63,9.42" target="#fig_0">1</ref>(b), nodes with the same attributes are grouped together but many connections exist between these two clusters.</s><s xml:id="_9EGzNxY" coords="2,290.65,393.70,240.65,9.42;2,80.70,405.66,452.14,9.42">In structure-based clustering, as shown in Figure <ref type="figure" coords="2,488.74,393.70,3.32,9.42" target="#fig_0">1</ref>(c), nodes belonging to diferent clusters are minimally connected, but nodes within the same cluster have diferent attributes.</s><s xml:id="_kJzWfcj" coords="2,80.70,417.61,450.60,9.42;2,80.33,429.57,450.97,9.42;2,80.70,441.52,41.87,9.42">In addition, the clustering results obtained from attribute-based or structure-based clustering are inconsistent with each other, and there is no simple solution to choose one of these two diferent results, nor to combine them <ref type="bibr" coords="2,104.02,441.52,14.84,9.42" target="#b20">[21]</ref>.</s></p><p xml:id="_xAWcbJP"><s xml:id="_vm4CHap" coords="2,90.66,453.48,440.64,9.42;2,80.70,465.43,251.96,9.42">On the other hand, diferent approaches that combine node attributes and graph structure information have been proposed to produce better clustering results <ref type="bibr" coords="2,286.30,465.43,14.97,9.42" target="#b76">[77,</ref><ref type="bibr" coords="2,303.76,465.43,11.44,9.42" target="#b83">84,</ref><ref type="bibr" coords="2,317.69,465.43,11.23,9.42" target="#b87">88]</ref>.</s><s xml:id="_HB6497v" coords="2,335.14,465.43,196.17,9.42;2,80.70,477.39,305.46,9.42">As shown in Figure <ref type="figure" coords="2,416.37,465.43,3.51,9.42" target="#fig_0">1</ref>(d), such approaches return better clusters by balancing the attribute and structure similarities properly.</s><s xml:id="_8arPJeX" coords="2,388.64,477.39,142.67,9.42;2,80.70,489.34,434.69,9.42">However, existing AGC approaches are mainly designed for speciic types of attributed graphs and cannot be easily generalized to other types.</s><s xml:id="_Xz7nbkG" coords="2,517.87,489.34,13.61,9.42;2,80.70,501.30,450.61,9.42;2,80.70,513.25,451.70,9.42;2,80.70,525.21,161.63,9.42">For example, AGC methods designed for attributed graphs with simple undirected edges cannot be easily extended to capture asymmetric, higher-order, and heterogeneous relationships, which are represented by directed, hyper-, and multi-relational edges, respectively.</s><s xml:id="_Hg4jnUM" coords="2,244.82,525.21,286.49,9.42;2,80.70,537.16,450.61,9.42;2,80.70,549.12,450.61,9.42;2,80.70,561.07,450.61,9.42;2,80.70,573.03,20.26,9.42">This is because undirected edges are only used to represent symmetric pairwise relationships and do not capture higher order relationships, e.g., in a social network, friendship is undirected, while the inluencerśfollower relationship is directed, social tagging that involves a group of users is modelled by hyper-edges, and multi-relational edges can describe rich user interactions on diferent social media sites.</s></p><p xml:id="_7w2SZBa"><s xml:id="_HMyh2ra" coords="2,90.66,584.98,440.90,9.42;2,80.70,596.94,187.90,9.42">Some existing methods have been extended to handle more types of graphs, but the generalization to many types of graphs remains a challenging problem.</s><s xml:id="_uBGExTh" coords="2,270.86,596.94,260.45,9.42;2,80.70,608.89,450.61,9.42;2,80.70,620.85,297.52,9.42">For example, on heterogeneous graphs, the recent state-of-the-art SpectralMix <ref type="bibr" coords="2,131.35,608.89,16.26,9.42" target="#b52">[53]</ref> can be easily extended to undirected graphs as well as directed graphs by simply using a single adjacency in place of the sum in the structure part of its objective function.</s><s xml:id="_s6W27ur" coords="2,380.52,620.85,150.79,9.42;2,80.70,632.80,450.86,9.42;2,80.70,644.76,44.08,9.42">However, it is not clear how to extend it to hypergraphs since the structure part of its objective function assumes that an edge only connects exactly two nodes.</s></p><p xml:id="_72FMVqE"><s xml:id="_NTR4dH7" coords="3,90.66,107.52,440.64,9.42;3,80.70,119.47,158.24,9.42">For AGC on undirected graphs (Undi-AGC), graph convolution-based models have been shown to achieve state-of-the-art performance<ref type="foot" coords="3,200.00,117.76,3.38,6.88" target="#foot_0">1</ref>  <ref type="bibr" coords="3,206.36,119.47,15.04,9.42" target="#b48">[49,</ref><ref type="bibr" coords="3,223.90,119.47,11.28,9.42" target="#b83">84]</ref>.</s><s xml:id="_Zw8YZFD" coords="3,241.43,119.47,289.87,9.42;3,80.70,131.43,450.61,9.42;3,80.70,143.38,450.61,9.42;3,80.70,155.34,297.02,9.42">In an efort to extend the graph convolution-based methods in order to tackle AGC on hyper-graphs (hyper-AGC), in our prior work <ref type="bibr" coords="3,333.88,131.43,16.44,9.42" target="#b26">[27]</ref> we provide solid theoretical analysis on the excellent performance of graph convolution on AGC for simple undirected graphs, and we extended the results to clustering hypergraphs and proposed a model (GRAC) for hyper-AGC.</s></p><p xml:id="_XCqM7KN"><s xml:id="_KCbrAkb" coords="3,90.66,167.29,441.74,9.42;3,80.70,179.25,58.03,9.42;3,138.73,177.54,3.38,6.88;3,142.61,179.25,388.69,9.42;3,80.33,191.20,405.96,9.42">In this paper, we further extend our prior work <ref type="bibr" coords="3,281.57,167.29,16.23,9.42" target="#b26">[27]</ref> to propose a general graph convolution-based framework, called GRACE <ref type="foot" coords="3,138.73,177.54,3.38,6.88" target="#foot_1">2</ref> , for AGC on diferent types of edges, i.e., a general framework for clustering attributed graphs with directed, hyper-, or multi-relational edges (or any graphs with a well deined graph Laplacian).</s></p><p xml:id="_EYh8MwK"><s xml:id="_eHRmmCv" coords="3,90.66,203.16,440.64,9.42;3,80.70,215.11,71.96,9.42">GRACE is the irst graph convolution-based algorithm proposed to work on all types of graphs with a well deined Laplacian.</s><s xml:id="_sPHMHTD" coords="3,154.74,215.11,376.56,9.42;3,80.70,227.07,450.61,9.42;3,80.70,239.02,450.61,9.42;3,80.70,250.98,61.08,9.42">The graph convolution is a iltering operation that is used to de-noise graph signals by allowing speciic graph signals contained in the node attributes to pass through, where graph signals correspond to columns of the node attribute matrix and the graph convolution ilter corresponds to functions of the graph Laplacian <ref type="bibr" coords="3,123.04,250.98,14.99,9.42" target="#b57">[58]</ref>.</s><s xml:id="_zpp47Tj" coords="3,144.26,250.98,387.04,9.42;3,80.70,262.93,67.03,9.42">As such, GRACE consists mainly of two phases, a de-noising (graph convolution) phase and a clustering phase.</s><s xml:id="_Uw29Nsb" coords="3,150.10,262.93,381.20,9.42;3,80.70,274.89,450.60,9.42;3,80.70,286.84,176.05,9.42">To integrate both phases and decide how much de-noising is needed, GRACE utilizes the notion of cluster compactness on the de-noised node attributes (i.e., how close the nodes in the same cluster are to each other with respect to their node attributes).</s></p><p xml:id="_6syVYwZ"><s xml:id="_s5vTFCd" coords="3,90.66,298.80,440.64,9.42;3,80.70,310.75,450.60,9.42;3,80.70,322.71,450.61,9.42;3,80.70,334.67,41.03,9.42">Based on graph convolution, we irst show from a Graph Signal Processing perspective <ref type="bibr" coords="3,436.59,298.80,16.22,9.42" target="#b57">[58]</ref> that GRACE can be interpreted as a two-step algorithm guided by the compactness measure, with the irst step being the de-noising step and the second being the clustering step, where the compactness measure controls what level of de-noising is needed.</s><s xml:id="_D3f9G9G" coords="3,124.22,334.67,407.08,9.42;3,80.70,346.62,65.45,9.42">Second, we show that GRACE is easy to understand with respect to its efects on AGC on diferent types of graphs.</s><s xml:id="_UUQxzgV" coords="3,148.63,346.62,382.67,9.42;3,80.70,358.58,450.61,9.42;3,80.70,370.53,200.60,9.42">Speciically, GRACE helps ind the trade-of between ensuring that nodes in diferent clusters are as minimally connected as possible, while at the same time ensuring that nodes in the same cluster have attributes that are not too dissimilar to each other.</s><s xml:id="_jeUayXs" coords="3,283.78,370.53,247.52,9.42;3,80.70,382.49,450.61,9.42;3,80.70,394.44,125.67,9.42">In addition, GRACE is easy to implement as it only consists of two (easy-to-implement) phases, a graph convolution phase and then a clustering phase, both of which have a relatively low time complexity.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2" xml:id="_b4H2dsU">BACKGROUND</head><p xml:id="_dEKGVa5"><s xml:id="_Vk4Ntqm" coords="3,80.70,431.83,434.84,9.42">In this section, we introduce the background of attribute-based and structure-based clustering algorithms.</s><s xml:id="_FmB2duc" coords="3,518.02,431.83,13.29,9.42;3,80.70,443.78,373.14,9.42">We also give the preliminaries of graph convolution and four diferent types of graph structures.</s><s xml:id="_9qCSnjR" coords="3,456.32,443.78,74.98,9.42;3,80.70,455.74,148.70,9.42">We summarize the frequently used notations in Table <ref type="table" coords="3,222.57,455.74,3.41,9.42" target="#tab_0">1</ref>.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1" xml:id="_RFGU6Nd">Atribute-based Clustering</head><p xml:id="_SCrjSqa"><s xml:id="_cDZBAkK" coords="3,80.70,493.13,450.61,9.42;3,80.70,505.08,61.57,9.42">Clustering attributed graphs involves both node attributes and graph structure to measure the similarity between diferent nodes.</s><s xml:id="_S5C5cqw" coords="3,144.36,505.08,388.04,9.42;3,80.70,517.09,414.99,9.51">In attribute-based clustering, as shown in Fig. <ref type="figure" coords="3,326.26,505.08,3.49,9.42" target="#fig_0">1</ref>(b), each node is described by an attribute vector, denoted by x ∈ R , and nodes with similar attribute vectors should be assigned to the same cluster.</s><s xml:id="_X5xJ6ag" coords="3,498.31,517.17,33.00,9.42;3,80.70,529.13,450.79,9.42;3,80.70,541.08,149.88,9.42">For that purpose, the K-means <ref type="bibr" coords="3,171.74,529.13,16.37,9.42" target="#b43">[44]</ref> algorithm was proposed to ind a number of clusters that minimize the intra-cluster feature distance (IntraFD) as follows:</s></p><formula xml:id="formula_0" coords="3,252.68,563.64,279.22,24.35">min 1 ,••• , ︁ =1 ︁ ∈ ||x -m || 2 ,<label>(1)</label></formula><p xml:id="_Yx2UVHh"><s xml:id="_xTNKfNb" coords="3,80.33,594.40,50.42,9.42;3,148.44,598.46,8.76,6.68;3,161.91,594.31,276.09,9.51">where m = ∈ /| | is the centroid of cluster , and is the number of clusters.</s><s xml:id="_FmFZHCD" coords="3,440.72,594.40,90.58,9.42;3,80.70,606.36,122.24,9.42">Lower IntraFD means higher quality of clusters w.r.t.</s><s xml:id="_DdPhHmW" coords="3,205.42,606.36,62.64,9.42">node attributes.</s><s xml:id="_wTnU5fY" coords="3,270.56,606.36,260.92,9.42;3,80.70,618.31,35.85,9.42">In other words, nodes in the same cluster should be close to their centroid.</s><s xml:id="_Bekbw8J" coords="4,90.66,309.61,432.10,9.42">Following the work of <ref type="bibr" coords="4,183.47,309.61,14.84,9.42" target="#b14">[15]</ref>, it is useful to rewrite the IntraFD minimization problem in an alternative way:</s></p><formula xml:id="formula_1" coords="4,243.53,326.72,288.37,15.28">min = ( ) -( ),<label>(2)</label></formula><p xml:id="_bD9AXv8"><s xml:id="_8f4m4M3" coords="4,80.33,348.04,450.97,9.42;4,80.70,360.15,16.26,9.42;4,116.08,358.44,52.05,10.78;4,171.12,360.15,127.71,9.42">where is the node attribute matrix whose rows are node attributes. is the cluster assignment matrix such that = (1/| |) 1/2 if node belongs to cluster .</s><s xml:id="_54jkt2j" coords="4,301.32,360.15,44.52,9.42;4,364.96,360.15,15.51,9.42">Otherwise, = 0.</s><s xml:id="_7ak4Cvq" coords="4,382.96,360.06,137.47,9.51">And (•) is the trace of a matrix.</s><s xml:id="_pYSNV6G" coords="4,522.92,360.15,8.38,9.42;4,80.70,372.10,162.47,9.42;4,268.83,372.10,14.59,9.42">In this case, always fulills the condition = .</s></p><p xml:id="_MztmCjW"><s xml:id="_NSmVxkU" coords="4,90.66,384.06,188.74,9.42">The IntraFD minimization problem is NP-hard.</s><s xml:id="_b3fTrEH" coords="4,281.89,384.06,250.50,9.42;4,90.60,394.37,131.87,11.06;4,226.00,396.01,11.19,9.42">However, when the discreteness condition of is relaxed (i.e., can take arbitrary values in R × s.t.</s><s xml:id="_xN3hMgK" coords="4,262.66,396.01,268.63,9.42;4,80.70,407.97,105.21,9.42">= ), the continuous optimal solution for is given by the principal components of via SVD.</s><s xml:id="_5nx5v6c" coords="4,188.30,407.97,343.01,9.42;4,80.70,419.92,206.92,9.42">Therefore, it is suggested to perform SVD on node attributes before applying K-means to ind high-quality clusters with low IntraFD <ref type="bibr" coords="4,269.07,419.92,14.84,9.42" target="#b14">[15]</ref>.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2" xml:id="_F4ccCmp">Structure-based Clustering</head><p xml:id="_6cdDhyg"><s xml:id="_bAkBjsV" coords="4,80.70,457.16,451.21,9.42;4,80.70,469.11,450.60,9.42;4,80.70,481.07,65.31,9.42">In structure-based clustering, as shown in Fig. <ref type="figure" coords="4,275.99,457.16,10.32,9.42" target="#fig_0">1(c</ref>), only graph structure information (i.e., edge connections) is utilized to partition nodes into groups with dense edge connections internally and sparse edge connections between groups.</s><s xml:id="_FfVK89p" coords="4,148.09,481.07,383.21,9.42;4,80.70,493.02,353.50,9.42">Spectral clustering <ref type="bibr" coords="4,224.15,481.07,14.89,9.42" target="#b25">[26,</ref><ref type="bibr" coords="4,241.12,481.07,12.74,9.42" target="#b41">42]</ref> is one of the most popular graph clustering algorithms to ind clusters that minimize the intra-cluster edge density (InterED), also known as NCut, as follows:</s></p><formula xml:id="formula_2" coords="4,255.01,514.44,276.89,25.49">min 1 ,••• , ︁ =1 ∈ , ∉ volume( ) ,<label>(3)</label></formula><p xml:id="_h844wnf"><s xml:id="_9tcJsrK" coords="4,80.33,545.19,24.83,9.42;4,122.85,545.10,408.64,9.51;4,80.70,557.15,122.22,9.42">where is the edge weight between nodes and , and volume( ) measures the size of by summing over the degrees of all nodes in .</s><s xml:id="_5quupWF" coords="4,205.41,557.15,221.97,9.42">Lower InterED implies higher quality of clusters w.r.t.</s><s xml:id="_K2Ug6vu" coords="4,429.88,557.15,66.11,9.42">graph structure.</s><s xml:id="_p3YNW9Y" coords="4,498.49,557.15,32.99,9.42;4,80.33,569.10,452.51,9.42">In other words, nodes in diferent clusters should be minimally connected, while the size of all clusters should be balanced.</s></p><p xml:id="_rkuT7xV"><s xml:id="_nqKsQXP" coords="4,90.66,581.06,436.83,9.42">To understand spectral clustering, it is helpful to rewrite the InterED minimization problem as follows <ref type="bibr" coords="4,508.78,581.06,14.97,9.42" target="#b41">[42]</ref>:</s></p><formula xml:id="formula_3" coords="4,266.77,598.17,265.13,15.28">min = ( ),<label>(4)</label></formula><p xml:id="_S8mUnqK"><s xml:id="_HvphTkB" coords="4,80.33,621.40,210.74,9.42;4,310.19,619.69,122.25,10.78;4,435.42,621.31,39.45,9.51">where is the cluster assignment matrix such that = (degree( )/volume( )) 1/2 if ∈ .</s><s xml:id="_NXP77j6" coords="4,477.35,621.40,55.05,9.42;4,97.33,633.36,60.00,9.42;4,182.90,633.36,68.48,9.42;4,275.49,633.36,255.81,9.42;4,80.70,645.31,38.90,9.42">In other case, = 0. Obviously, = always holds. is the symmetric graph Laplacian matrix derived from the graph structure.</s></p><p xml:id="_qXSdN4P"><s xml:id="_RD5HSna" coords="5,90.66,107.52,393.66,9.42;5,508.58,107.52,22.72,9.42;5,80.70,119.47,108.40,9.42">In a similar manner, the optimal continuous solution of is given by the irst eigen-vectors of when its discreteness is removed.</s><s xml:id="_Z4WPPXv" coords="5,191.58,119.47,281.48,9.42;5,497.30,119.47,34.01,9.42;5,80.70,131.43,238.33,9.42">Therefore, spectral clustering is to compute the irst eigen-vectors of and feed them into K-means to ind good clusters with low interED.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3" xml:id="_gtG8B6D">Graph Convolution on Node Atributes</head><p xml:id="_zhJhhd7"><s xml:id="_EuWQ7Yt" coords="5,80.70,168.62,450.61,9.42;5,80.70,180.58,450.61,9.42;5,80.70,192.53,155.18,9.42">In the task of Undi-AGC, as shown in igure 1(d), approaches that combine the information of node attributes and graph structure can achieve better clustering performance compared with either attribute-based or structure-based clustering methods (see also <ref type="bibr" coords="5,200.08,192.53,15.12,9.42" target="#b20">[21,</ref><ref type="bibr" coords="5,217.73,192.53,10.89,9.42" target="#b83">84]</ref>).</s><s xml:id="_9txKtee" coords="5,238.41,192.53,292.90,9.42;5,80.70,204.49,450.61,9.42;5,80.70,216.44,115.00,9.42">Recently, graph convolution has gained much attention for integrating graph structure information on node attributes efectively, and improving the performance over many graph mining tasks <ref type="bibr" coords="5,135.30,216.44,15.00,9.42" target="#b23">[24,</ref><ref type="bibr" coords="5,152.80,216.44,11.46,9.42" target="#b26">27,</ref><ref type="bibr" coords="5,166.74,216.44,11.46,9.42" target="#b66">67,</ref><ref type="bibr" coords="5,180.69,216.44,11.25,9.42" target="#b83">84]</ref>.</s></p><p xml:id="_6Br6UKr"><s xml:id="_fr4gz4A" coords="5,90.66,228.40,440.64,9.42;5,80.70,240.35,236.53,9.42">From the graph signal processing perspective <ref type="bibr" coords="5,273.59,228.40,10.26,9.42" target="#b8">[9,</ref><ref type="bibr" coords="5,286.21,228.40,11.17,9.42" target="#b57">58]</ref>, graph convolution is regarded as a ilter that removes the attribute noise at some frequencies in the spectral domain.</s><s xml:id="_wCDQBzf" coords="5,319.71,240.35,211.60,9.42;5,80.70,252.31,264.04,9.42;5,272.53,269.34,1.56,9.16">Formally, given a speciic ilter function , the graph convolution operation on node attributes is deined as follows:</s></p><formula xml:id="formula_4" coords="5,274.09,269.34,257.81,9.51">* = (Λ) ,<label>(5)</label></formula><p xml:id="_WqRwb8y"><s xml:id="_x8VPPkD" coords="5,80.33,286.27,389.60,9.42;5,493.94,286.27,37.96,9.42;5,80.70,298.22,77.37,9.42">where Λ and are eigenvalues and orthogonal eigenvectors of the symmetric graph Laplacian (i.e., = Λ ) in increasing order.</s><s xml:id="_mQx7kU4" coords="5,160.54,298.22,370.76,9.42;5,80.70,310.18,68.13,9.42;5,171.34,310.18,359.97,9.42;5,80.70,322.85,175.66,9.42">The graph convolution consists of three steps: (1) transform node attributes into the spectral domain (i.e., = ); (2) remove attribute noise by scaling the spectrum with a scalar-valued ilter function on eigen-values (i.e., = (Λ) , in which</s></p><formula xml:id="formula_5" coords="5,258.72,322.76,129.34,10.37">(Λ) = diag(( 1 ), • • • , ( )));</formula><p xml:id="_HTyUfYE"><s xml:id="_qHRvH8a" coords="5,390.91,322.85,140.58,9.42;5,80.70,335.53,247.65,9.42;5,345.03,335.53,5.16,9.42">(3) perform inverse graph Fourier transform on the scaled spectrum of node attributes (i.e., = ).</s><s xml:id="_jNRRBVv" coords="5,90.66,347.49,369.50,9.42">The efects of graph convolution on node attributes depend on the design of graph ilters.</s><s xml:id="_bQpf48K" coords="5,462.65,347.49,68.66,9.42;5,80.70,359.35,451.78,9.51;5,210.30,376.84,1.56,9.16">For example, the graph ilter in well-known GCNs <ref type="bibr" coords="5,216.61,359.44,16.31,9.42" target="#b27">[28]</ref> is () = 1 -, whose graph convolution on node attributes is as follows:</s></p><formula xml:id="formula_6" coords="5,211.86,374.66,320.04,11.70">* = ( -Λ) = ( -) = -1/2 -1/2 ,<label>(6)</label></formula><p xml:id="_ZwUCp3V"><s xml:id="_Y6ff8Wv" coords="5,80.33,393.77,450.97,9.42;5,80.70,405.88,64.14,9.42;5,169.39,405.79,20.93,9.16;5,200.11,404.10,44.63,6.68;5,245.24,405.88,2.15,9.42">where and are adjacency matrix and diagonal degree matrix, and they are used to construct the symmetric graph Laplacian = --1/2 -1/2 .</s><s xml:id="_25srTxj" coords="5,249.87,405.88,281.43,9.42;5,80.70,417.83,299.38,9.42">However, the graph convolution in GCNs only utilizes graph structure information by aggregating the node attributes from their 1-hop neighbors.</s><s xml:id="_eVXTZwk" coords="5,382.40,417.83,149.99,9.42;5,80.70,429.79,451.78,9.42;5,198.16,447.19,1.56,9.16">To capture the global graph structure, simpliied graph convolution (SGC) performs the 1-hop graph convolution operation multiple times as follows <ref type="bibr" coords="5,513.96,429.79,14.82,9.42" target="#b71">[72]</ref>:</s></p><formula xml:id="formula_7" coords="5,199.72,445.01,332.18,11.70">* = ( -Λ) = ( -) = ( -1/2 -1/2 ) ,<label>(7)</label></formula><p xml:id="_nuUPjYk"><s xml:id="_PSqnBpC" coords="5,80.33,464.12,437.88,9.42">where is the length of hops that determines how far two nodes can aggregate information from each other.</s><s xml:id="_7gk6KHc" coords="5,520.71,464.12,10.86,9.42;5,80.70,476.07,450.61,9.42;5,80.70,488.03,110.63,9.42">By performing SGC on attributed graphs, it has been shown to achieve the state-of-the-art performance on node classiication tasks <ref type="bibr" coords="5,158.83,488.03,15.00,9.42" target="#b37">[38,</ref><ref type="bibr" coords="5,176.33,488.03,11.25,9.42" target="#b71">72]</ref>.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4" xml:id="_XmmhMuJ">Four Types of Graph Structures</head><p xml:id="_KjgeGzh"><s xml:id="_aC3ZTYx" coords="5,80.70,525.22,450.61,9.42;5,80.70,537.18,120.90,9.43;5,219.63,537.18,311.67,9.42;5,88.78,549.13,5.16,9.42">In undirected or directed graphs, as shown in Figure <ref type="figure" coords="5,291.75,525.22,3.67,9.42" target="#fig_1">2</ref>(a) or (b), the edge connections are often represented by an adjacency matrix , such that = 1 if there is an edge connecting between node and (or from node to ).</s><s xml:id="_G9r2Z5M" coords="5,96.43,549.13,44.38,9.42;5,158.84,549.13,15.49,9.42">Otherwise, = 0.</s><s xml:id="_J6B93Jw" coords="5,90.66,561.09,440.83,9.42;5,80.70,573.04,247.56,9.42">In hyper-graphs, as shown in Figure <ref type="figure" coords="5,241.14,561.09,3.38,9.42" target="#fig_1">2</ref>(c), an adjacency matrix cannot be applied to express the higher-order relations when hyper-edges connect more than two nodes.</s><s xml:id="_nataApp" coords="5,331.39,573.04,199.91,9.42;5,80.70,585.00,96.32,9.42;5,198.00,585.00,172.32,9.42">Instead, an incidence matrix is used to model hyper-edges, such that = 1 if node belongs to hyper-edge .</s><s xml:id="_e4ruE6Z" coords="5,373.94,585.00,45.27,9.42;5,440.18,585.00,91.12,9.42;5,80.70,596.86,76.51,9.51;5,190.85,596.95,340.45,9.42;5,80.70,608.82,51.66,9.51;5,162.35,608.91,249.40,9.42">Otherwise, = 0. Accordingly, the node degree( ) = represents the number of hyper-edges that are incident to node , and the edge degree( ) = represents the number of nodes that belong to hyper-edge .</s></p><p xml:id="_4P7jqVa"><s xml:id="_xX89MCq" coords="5,90.66,620.87,199.67,9.42;6,80.70,310.36,44.83,9.42;6,143.55,310.36,15.56,9.42">In multi-relational graphs, as shown in Figure <ref type="figure" coords="5,286.73,620.87,3.60,9.42" target="#fig_1">2</ref> Otherwise, = 0.</s><s xml:id="_U3CNZrE" coords="6,161.59,310.36,369.72,9.42;6,80.70,322.74,98.59,9.42">In other words, an multi-relational graph can be decomposed as a set of simple undirected graphs of all edge types.</s></p><p xml:id="_GZCWjck"><s xml:id="_6rU5XYS" coords="6,90.66,334.69,440.64,9.42;6,80.70,346.65,450.61,9.42;6,80.35,358.61,67.52,9.42">In summary, due to the diferent expressions among diferent types of graph structures, it is nontrivial to generalize the AGC framework from Undi-AGC to directed AGC (Di-AGC), Hyper-AGC, and multi-relational AGC (MR-AGC).</s></p><p xml:id="_2ZKHcQj"><s xml:id="_Heht5hX" coords="6,90.66,370.61,175.48,9.37">Discussion on Heterogeneous Graphs.</s><s xml:id="_6W7Dgjt" coords="6,272.00,370.56,259.49,9.42;6,80.45,382.52,94.35,9.42">Heterogeneous graphs contain multiple types of nodes and/or various types of edges.</s><s xml:id="_KDjK4g2" coords="6,177.31,382.52,353.99,9.42;6,80.70,394.47,452.29,9.42;6,80.70,406.43,72.09,9.42">For example, in citation networks like ACM, there are three types of nodes (including author, paper, and subject), and there are two types of edges (representing author-write-paper and paper-belongsubject relations).</s><s xml:id="_MUaqqhE" coords="6,155.29,406.43,376.01,9.42;6,80.70,418.38,451.70,9.42;6,80.70,430.34,346.31,9.42">To cluster nodes of a speciic type (e.g., papers), it is a common practice to construct various meta-paths between two papers, such as paper-author-paper (describing two papers written by the same author), and paper-subject-paper (meaning that two papers belong to the same subject) <ref type="bibr" coords="6,394.94,430.34,14.89,9.42" target="#b56">[57,</ref><ref type="bibr" coords="6,412.12,430.34,11.17,9.42" target="#b69">70]</ref>.</s><s xml:id="_tKsZjZu" coords="6,429.31,430.34,102.00,9.42;6,80.70,442.29,450.60,9.42;6,80.70,454.25,87.87,9.42">Therefore, heterogeneous graphs can be transformed into multi-relational graphs having homogeneous nodes (papers) and diferent types of edges (meta-paths).</s><s xml:id="_7JkqASa" coords="6,171.03,454.25,360.28,9.42;6,80.70,466.20,116.16,9.42">For ease of presentation, we use multi-relational graph structure to express heterogeneous graphs based on meta-paths.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3" xml:id="_eVWP2DD">PROBLEM STATEMENT</head><p xml:id="_hwQNyKN"><s xml:id="_C6ZKxqa" coords="6,80.70,510.35,213.24,9.42">In this section, we formulate a general AGC problem.</s><s xml:id="_3VsvV23" coords="6,296.43,510.26,234.87,9.51;6,90.31,522.21,441.19,10.37;6,80.44,534.17,154.45,10.37;6,250.16,534.17,281.13,9.51;6,80.33,546.22,43.50,9.42">A general attributed graph is deined by = ( , ), where = {( 1 , x 1 ), ( 2 , x 2 ), • • • , ( , x )} is a set of attributed nodes, each node is associated with an attribute vector x , and = {( 1 , 1 ), ( 2 , 2 ), • • • , ( , )} consists of a set of weighted edges, each edge is associated with a weight .</s></p><p xml:id="_yQhTq2y"><s xml:id="_SV6qKAm" coords="6,90.66,558.17,257.37,9.42">The deinition of edges depends on the speciic graph structure.</s><s xml:id="_8mjrT3a" coords="6,350.50,558.17,180.80,9.42;6,80.70,570.04,382.67,9.52">In undirected (or directed) graphs, each edge is denoted by a pair of nodes ( , ) connecting between nodes and (or from node to ).</s><s xml:id="_r6SuVWb" coords="6,465.81,570.13,66.59,9.42;6,80.70,581.99,243.98,9.51">In hyper-graphs, each hyper-edge is represented by a subset of nodes ⊂ .</s><s xml:id="_V58PaYW" coords="6,327.17,582.08,204.40,9.42;6,81.20,593.95,253.28,9.51">In multi-relational graphs, each edge is deined by ( , , ) that connects nodes and with a edge type ∈ R.</s></p><p xml:id="_TkTxZVK"><s xml:id="_utU4TXh" coords="6,90.66,605.99,440.64,9.43;6,90.34,617.86,175.79,10.37;6,265.84,623.71,12.03,6.81;6,291.81,617.86,53.89,9.51;6,360.78,617.86,171.13,9.52;6,80.70,629.90,450.61,9.42;6,80.70,641.86,153.84,9.42">Given an attributed graph and the number of clusters , the problem of AGC is to partition the nodes into disjoint subsets 1 , 2 , • • • , , such that ∪ =1 = and ∩ = ∅ for any ≠ , with two objectives: (1) nodes in the same cluster have similar node attributes (i.e., low IntraFD), and (2) nodes from diferent clusters are sparsely connected (i.e., low InterED).</s></p><p xml:id="_rVYXUAY"><s xml:id="_m3nSNj4" coords="7,80.70,122.46,371.48,9.42">In this section, we present a graph convolution based algorithm for Undi-AGC speciically.</s><s xml:id="_tfMMeGN" coords="7,454.67,122.46,76.64,9.42;7,80.70,134.42,344.09,9.42">Then we provide a theoretical analysis on how graph convolution improves the clustering performance.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1" xml:id="_MJrp5w5">Overview</head><p xml:id="_D4juFV4"><s xml:id="_f848F6Y" coords="7,80.70,173.11,450.60,9.51;7,80.70,185.15,241.85,9.42">Given an attributed undirected graph = ( , ), the node attributes and graph structure are represented by an attribute matrix and an adjacency matrix , respectively.</s><s xml:id="_As28RMH" coords="7,325.04,185.15,206.52,9.42;7,80.70,197.11,128.99,9.42">The overview of our Undi-AGC algorithm, namely GRAC, is illustrated in Figure <ref type="figure" coords="7,202.86,197.11,3.41,9.42" target="#fig_2">3</ref>.</s><s xml:id="_zXqBVCc" coords="7,90.66,362.10,440.64,9.51;7,80.70,374.14,320.53,9.42">The basic idea is to perform graph convolution on nodes attributes (i.e., = * ), and then feed processed node attributes ( ) into an attribute-based clustering algorithm to ind clusters.</s><s xml:id="_AFSV8tq" coords="7,403.72,374.14,127.59,9.42;7,80.70,386.10,449.11,9.42">While it is simple to implement the algorithm, the challenge lies in how to select efective and eicient convolution and clustering approaches.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2" xml:id="_z5fk8dT">Convolution and Clustering Details</head><p xml:id="_Bcr8CYW"><s xml:id="_AcJRjgk" coords="7,80.35,424.88,450.95,9.42;7,80.70,436.83,43.48,9.42">As we have discussed, the graph convolution in GCNs can only aggregate node attribute information from 1-hop neighbors.</s><s xml:id="_dRyS4ce" coords="7,126.67,436.83,404.63,9.42;7,80.40,448.79,167.56,9.42;7,235.32,468.86,1.56,9.16">To capture the global structure information, we apply a generalized high-order graph convolution (HGC) on node attributes as follows <ref type="bibr" coords="7,229.25,448.79,14.97,9.42" target="#b26">[27]</ref>:</s></p><formula xml:id="formula_8" coords="7,236.88,468.86,295.02,9.51">* = ( -Λ) = ( -) ,<label>(8)</label></formula><p xml:id="_S7ftsTt"><s xml:id="_wvwKWK7" coords="7,80.33,489.12,450.97,9.54;7,80.70,501.08,321.30,9.42">where &gt; 0 is the graph iltering rate that controls the degree of iltering attribute noise. is the length of hops that determines how far two nodes can aggregate information from each other.</s><s xml:id="_jDgF2vh" coords="7,90.66,513.03,208.48,9.42">Even though the only diference between HGC (Eq.</s><s xml:id="_7ytUwqD" coords="7,301.63,513.03,69.72,9.42">( <ref type="formula" coords="7,305.01,513.03,3.38,9.42" target="#formula_7">7</ref>)) and SGC (Eq.</s><s xml:id="_x9usnNW" coords="7,373.86,513.03,157.44,9.43;7,80.70,524.99,434.01,9.42">( <ref type="formula" coords="7,377.24,513.03,3.38,9.42" target="#formula_8">8</ref>)) is the graph iltering rate , tuning this hyper-parameter is very important to improve the efectiveness of higher-order graph convolution.</s><s xml:id="_gNDgbm7" coords="7,517.66,524.99,13.83,9.42;7,80.70,536.94,337.80,9.42">For example, Zhang et al. <ref type="bibr" coords="7,170.90,536.94,16.36,9.42" target="#b83">[84]</ref> set = 1/2, making HGC work well as a low-pass ilter.</s><s xml:id="_5kDC8NB" coords="7,420.99,536.94,110.31,9.42;7,80.70,548.90,450.60,9.42;7,80.70,560.85,187.93,9.42">On the other hand, HGC is diferent from GCN-based methods, as it has not introduced any trainable parameter and training process, so that it is much more time eicient than GCNs.</s></p><p xml:id="_J2yUgZM"><s xml:id="_PhWfpyn" coords="7,90.66,572.81,203.04,9.42;7,320.18,572.72,211.13,9.51;7,80.70,584.76,452.14,9.42">By performing HGC on attributed graphs, i.e., = * , we integrate the information of graph structure into node attributes, and the processed node attributes are readily fed into attribute-based clustering algorithms.</s><s xml:id="_4b29pSH" coords="7,80.35,596.72,450.95,9.42;7,80.70,608.67,42.65,9.42">As suggested in <ref type="bibr" coords="7,146.54,596.72,14.98,9.42" target="#b14">[15,</ref><ref type="bibr" coords="7,164.01,596.72,11.24,9.42" target="#b26">27]</ref>, we apply SVD on to obtain the irst K eigen-vectors, and then use them for K-means clustering.</s><s xml:id="_VkcjaqK" coords="7,125.84,608.67,153.12,9.42">Note that is the number of clusters.</s></p><p xml:id="_bNdHf4z"><s xml:id="_hK9Th96" coords="7,90.66,620.63,440.64,9.42;7,80.70,632.59,147.96,9.42">In practice, the number of clusters and graph iltering rate are pre-deined, and the number of hops is determined by a stopping algorithm.</s><s xml:id="_nwc2Njk" coords="7,231.14,632.50,236.62,9.51;7,497.55,632.59,33.76,9.42;7,80.70,644.54,347.34,9.42">That is, we perform HGC by repeating left multiplyingmultiple times, until there is not much change in the stopping metric of consecutive iterations.</s><s xml:id="_kJgzFb4" coords="7,430.53,644.54,100.78,9.42;8,80.33,107.45,277.95,9.42;8,97.63,123.17,294.06,8.56;8,124.53,134.21,181.27,9.42;8,97.63,145.17,92.17,8.48;8,87.06,156.13,207.57,8.48;8,87.07,167.09,21.76,8.48;8,124.81,167.01,76.09,8.56;8,87.07,178.05,146.24,8.48;8,256.82,175.92,70.96,10.28;8,87.07,188.36,68.85,10.60;8,87.07,201.44,84.87,9.42;8,87.07,213.11,5.59,7.54">The stopping metric that Algorithm 1 GRAC: Graph convolution based Undi-AGC algorithm Input: Attributed graph = ( , ), number of clusters , graph iltering rate , maximum iteration number max , tolerance value Output: A set of clusters 1: Build adjacency matrix and attribute matrix from 2: Set = 1 for all nodes ∈ 3: Compute symmetric graph Laplacian = --1/2 -1/2 4: Initialize (0) = 5: for = 1 to max do 6:</s></p><p xml:id="_hrE6YY8"><s xml:id="_g9A5rXe" coords="8,111.08,210.28,72.72,10.60;8,209.81,210.28,26.37,10.28;8,87.07,225.55,5.59,7.54">Perform ( ) = ( -) ( -1)   7:</s></p><p xml:id="_uWm9GKw"><s xml:id="_xZ74auy" coords="8,111.08,222.72,224.14,10.60">Obtain clusters ( ) by applying SVD and K-means on ( )</s></p><formula xml:id="formula_9" coords="8,83.36,234.23,185.75,54.67">8: if ( ( -1) ) -( ( ) ) ≤ then 9: count = count + 1 10: if count ≥ 2 then 11: break 12: Set = ( )</formula><p xml:id="_amrBxKE"><s xml:id="_pwPeybV" coords="8,80.70,321.01,231.62,9.42">measures the compactness of clusters is given as follows:</s></p><formula xml:id="formula_10" coords="8,215.10,346.01,316.80,27.39">() = 1 | | ︁ =1 1 | |(| | -1) ︁ , ∈ , ≠ ||y -y || 2 ,<label>(9)</label></formula><p xml:id="_XRRgM62"><s xml:id="_pszqHzR" coords="8,80.33,385.91,25.33,9.42">where</s></p><formula xml:id="formula_11" coords="8,117.16,385.82,138.17,10.37">= { 1 , • • • , } is a set of clusters.</formula><p xml:id="_w2G6t7b"><s xml:id="_unPjP8a" coords="8,257.82,385.91,217.15,9.42">Each node is associated with an attribute vector y .</s><s xml:id="_CyZRMUe" coords="8,90.66,397.86,440.64,9.42;8,80.40,409.82,450.90,9.42;8,80.70,421.93,97.02,9.42;8,187.62,420.15,8.05,6.68;8,196.75,421.93,334.55,9.42;8,80.70,433.88,78.80,9.42">The pseudo-code of GRAC is described in Algorithm 1. First, we build an attribute matrix and graph Laplacian (with self-loops) in Lines 1-3, and then perform HGC on node attributes and obtain clusters via SVD and K-means on processed attributes ( ) , until the compactness of clusters changes very little or the maximum iteration number is reached.</s><s xml:id="_2eFrnNs" coords="8,162.01,433.88,369.29,9.43;8,80.70,444.12,450.60,11.14;8,88.20,457.70,280.94,9.51;8,396.46,456.08,135.04,11.14;8,80.70,469.75,37.83,9.42">Given the dimension of node attributes as , the number of iterations as , the number of nodes as , and the number of edges as , the total time complexity of GRAC is (( + 2 + 2 )), where () is the complexity for one left-multiplication by sparse matrix -, ( 2 ) for SVD, and ( 2 ) for K-means.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3" xml:id="_6e3pZp2">Properties of GRAC</head><p xml:id="_K3gcMuR"><s xml:id="_Xj85WuH" coords="8,80.22,509.58,383.50,9.42">We provide an analysis on how to improve clustering performance via graph convolution.</s><s xml:id="_UyufpG3" coords="8,467.12,509.58,64.18,9.42;8,80.70,521.54,164.21,9.42">In GRAC, node attributes are transformed to via HGC.</s><s xml:id="_BvUHJMZ" coords="8,247.40,521.54,275.05,9.42;8,80.70,533.49,204.11,9.42">As we have discussed in Section 2, performing SVD and K-means on is equivalent to optimizing the following problem:</s></p><formula xml:id="formula_12" coords="8,191.76,553.95,336.34,17.40">min = ( ) -( ) = min = || -|| 2 , (<label>10</label></formula><formula xml:id="formula_13" coords="8,528.10,556.17,3.80,9.42">)</formula><p xml:id="_MZM686n"><s xml:id="_gufnsY7" coords="8,80.33,582.98,452.51,9.51">where is the transformed node attributes, is the cluster assignment matrix, and || • || is the Frobenius norm.</s><s xml:id="_zB3XpCX" coords="8,80.40,594.94,208.16,9.51;8,311.40,593.32,47.50,10.78;8,383.29,594.94,54.55,9.51;8,469.64,594.94,5.96,9.16">The right-hand is derived from the fact that || -|| 2 = ( ) + -2 ( ).</s><s xml:id="_JjBkBUq" coords="8,478.02,595.03,53.54,9.42;8,80.70,607.87,334.19,9.42;8,456.97,607.78,6.34,9.16;8,483.97,607.87,2.18,9.42">Therefore, by solving the right-hand optimization problem <ref type="bibr" coords="8,263.57,607.87,14.80,9.42" target="#b15">[16]</ref>, the optimal solution retains that ≈ .</s><s xml:id="_3K7dW6y" coords="8,488.64,607.87,21.77,9.42;8,80.70,620.10,202.97,9.42">Here, is a good approximate solution of clustering on .</s></p><p xml:id="_c9ANz4v"><s xml:id="_Mu3tsAp" coords="8,90.66,632.06,364.07,9.42">On the other hand, the aim of Undi-AGC is to ind clusters with low IntraFD and InterED.</s><s xml:id="_zqZ2pw2" coords="8,457.23,632.06,74.07,9.42;8,80.70,644.01,450.61,9.42;9,80.70,107.52,48.55,9.42;9,152.64,107.52,42.93,9.42">To understand the efects of graph convolution on the quality of clusters, we measure both IntraFD and InterED approximately with the solution as follows:</s></p><formula xml:id="formula_14" coords="9,150.71,126.43,381.19,9.51">IntraFD( ) = ( ) -( ) ≈ ( ) -( ),<label>(11)</label></formula><formula xml:id="formula_15" coords="9,150.09,143.46,381.81,9.51">InterED( ) = ( ) ≈ ( ).<label>(12)</label></formula><p xml:id="_WRGHJYv"><s xml:id="_mqsAeud" coords="9,80.70,163.02,195.11,9.42;9,318.28,162.93,6.34,9.16;9,345.54,162.93,187.30,9.51">Both derivations are based on the properties of ≈ , and () = () for any two matrices.</s><s xml:id="_2PXyPpA" coords="9,80.40,175.25,343.99,9.42">The approximate terms are called IntraFD_approx and InterED_approx, respectively.</s></p><p xml:id="_BsntCFy"><s xml:id="_FbNQRC6" coords="9,90.66,187.21,377.65,9.42">We now provide a proof on the efects of HGC on both IntraFD_approx and InterED_approx.</s></p><p xml:id="_u4ZaBzW"><s xml:id="_eJkwm2v" coords="9,90.66,206.23,53.92,7.07">Theorem 4.1.</s><s xml:id="_2fqtFrS" coords="9,149.57,206.13,381.74,9.42;9,80.70,218.09,331.08,9.42">The graph convolution based algorithm for attributed graph clustering produces clusters with lower InterED_approx and higher IntraFD_approx, compared to attribute-based clustering.</s></p><p xml:id="_VacaEcg"><s xml:id="_SU42rtx" coords="9,90.66,237.12,28.45,7.07">Proof.</s><s xml:id="_yYHAwYV" coords="9,123.10,236.93,289.28,9.51;9,439.16,236.93,17.84,9.51">In Algorithm 1, the transformed node attributes are obtained by = ( -) .</s><s xml:id="_vkGtv48" coords="9,459.29,237.02,12.60,9.42;9,496.25,237.52,28.25,7.56;9,80.70,249.60,32.03,9.42;9,137.29,249.60,29.23,9.42;9,183.20,249.51,112.85,9.51">Let = Λ and = (or = ), we have = ( -Λ) .</s><s xml:id="_8rnG2Dj" coords="9,298.12,249.60,234.27,9.42;9,80.33,261.55,33.54,9.42">Replacing and in IntraFD_approx and InterED_approx, we have</s></p><formula xml:id="formula_16" coords="9,174.96,281.23,356.93,23.70">IntraFD_approx = ︁ =1 z z - ︁ =1 ︁ =1 (1 -) (1 -) (z z ) 2 ,<label>(13)</label></formula><formula xml:id="formula_17" coords="9,174.35,315.20,357.55,23.70">InterED_approx = ︁ =1 (1 -) 2 (z z ),<label>(14)</label></formula><p xml:id="_NQSvxhZ"><s xml:id="_RmYTAuU" coords="9,80.33,345.00,150.12,10.37;9,255.06,345.09,78.99,9.42">where 1 , • • • , are eigen-values of in ascending order.</s><s xml:id="_aRcak8C" coords="9,336.70,345.09,191.65,9.42;9,80.40,357.67,95.22,9.43">Each node has its spectral attribute vector z (i.e., the -th row in ).</s><s xml:id="_YjruBKu" coords="9,178.31,355.96,295.82,11.14;9,477.32,357.67,53.98,9.42;9,80.70,369.63,193.57,9.42;9,364.27,369.63,18.74,9.42">Given any attribute graph, it is clear that the values of z z and (z z ) 2 are ixed and non-negative, and the eigen-values hold that 0 <ref type="bibr" coords="9,364.27,369.63,14.99,9.42" target="#b41">[42]</ref>.</s><s xml:id="_r6YQBqU" coords="9,385.72,369.63,145.58,9.42;9,80.70,381.49,450.80,9.63;9,80.70,393.54,392.78,9.42">Therefore, if we set a proper graph iltering rate, i.e., ≤ 1/ , the graph convolution based algorithm (when &gt; 0) produces clusters with higher IntraFD_approx and lower InterED_approx compared to attribute-based clustering (when = 0).</s><s xml:id="_fMFTKAG" coords="9,524.97,393.57,6.34,7.09">□</s></p><formula xml:id="formula_18" coords="9,277.53,369.54,84.02,10.37">= 1 ≤ • • • ≤ ≤ 2</formula><p xml:id="_ufYZxRk"><s xml:id="_pUdhgrS" coords="9,90.66,413.96,440.64,9.42;9,80.70,425.91,426.83,9.42">From the above analysis, we can conclude that our graph convolution based algorithm helps to improve the clustering performance by producing clusters with very low InterED, at the cost of increasing IntraFD.</s><s xml:id="_vn5nCpQ" coords="9,510.21,425.91,21.10,9.42;9,80.70,437.87,450.61,9.42;9,80.70,449.82,90.61,9.42">With proper hyper-parameters ( and ), it is efective to ind good clusters that achieve a balance between IntraFD and InterED measures.</s><s xml:id="_T6ZUFWA" coords="9,173.80,449.82,357.50,9.42;9,80.70,461.78,185.81,9.42">Furthermore, this argument holds for any other graph structure when its graph Laplacian and graph convolution are properly designed.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5" xml:id="_gDDzg7P">EXTENSIONS TO OTHER TYPES OF GRAPH STRUCTURES</head><p xml:id="_7rrQ5x7"><s xml:id="_QDnJKJ6" coords="9,80.70,499.47,451.70,9.42;9,80.70,511.42,223.35,9.42">In this section, we develop an extension of GRAC algorithm (called GRACE) to other types of graph structures, including directed, hyper-, and multi-relational graphs.</s><s xml:id="_kRPdUq2" coords="9,306.55,511.42,224.76,9.42;9,80.70,523.38,372.59,9.42">This means that GRACE is a general graph convolution based framework that is applicable to Undi-AGC, Di-AGC, Hyper-AGC, and MR-AGC tasks.</s><s xml:id="_ZfDDBeq" coords="9,455.78,523.38,75.51,9.42;9,80.70,535.33,381.66,9.42">By using a general framework, it is useful and lexible to model many diferent relations with speciic edge types.</s></p><p xml:id="_WPtcacQ"><s xml:id="_cs2mvqf" coords="9,90.66,547.29,440.64,9.42;9,80.70,559.24,242.48,9.42">In our GRAC algorithm, it consists of building graph Laplacian, performing graph convolution on node attributes, and applying K-means with SVD to ind clusters.</s><s xml:id="_XfYEccw" coords="9,325.66,559.24,205.64,9.42;9,80.70,571.20,402.83,9.42">To extend GRAC from Undi-AGC to other types of graph structures, we need to build a suitable graph Laplacian for other types of graph structures.</s><s xml:id="_uVXDBNa" coords="9,486.19,571.20,45.12,9.42;9,80.70,583.15,267.73,9.42">For ease of presentation, we summarize diferent graph Laplacians in Table <ref type="table" coords="9,341.61,583.15,3.41,9.42" target="#tab_1">2</ref>.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1" xml:id="_uAt3hhj">Graph Laplacians for Directed Graphs</head><p xml:id="_wBUxsTN"><s xml:id="_x89sGvB" coords="9,80.70,621.18,214.21,9.42;9,319.36,621.18,92.09,9.42">So far we have built the symmetric graph Laplacian for undirected graphs.</s><s xml:id="_qDaeeK5" coords="9,436.29,621.09,21.23,9.16;9,467.39,619.40,44.63,6.68;9,515.11,621.18,16.20,9.42;9,80.70,633.13,450.61,9.42;9,80.70,645.09,203.08,9.42">= --1/2 -1/2 was proposed in spectral clustering to ind clusters by minimizing the NCut (Eq. 3 or Eq. 4), where and are the adjacency matrix and degree matrix, respectively.</s><s xml:id="_972rQBa" coords="9,286.28,645.09,245.28,9.42">However, the symmetric graph Laplacian cannot be directly</s></p><formula xml:id="formula_19" coords="10,125.18,133.20,354.06,40.21">= --1/2 -1/2 random walk directed graph Laplacian = -(Π 1/2 Π -1/2 + Π -1/2 Π 1/2 )/2 fast spectral normalized directed Laplacian = -( -1 2 ( + ) -<label>1</label></formula><p xml:id="_Dh2BVkD"><s xml:id="_4fzTHP2" coords="10,425.28,163.63,2.55,5.18">2</s></p><formula xml:id="formula_20" coords="10,125.18,163.90,320.12,23.59">)/2. symmetric directed graph Laplacian = --1/2 -1/2</formula><p xml:id="_UeAWycc"><s xml:id="_uFxbPAX" coords="10,404.50,178.06,30.02,9.42;10,449.91,177.97,22.99,9.16;10,125.18,192.13,118.54,9.42">, where = + linear hyper-graph Laplacian</s></p><formula xml:id="formula_21" coords="10,125.18,189.03,304.89,26.60">= --1/2 -1 -1/2 non-linear hyper-graph Laplacian = --1/2 -1/2</formula><p xml:id="_5HgH4X5"><s xml:id="_sdYCGbY" coords="10,413.65,206.21,66.27,9.42;10,125.18,218.56,131.56,9.42">, with mediators multi-relational graph Laplacian</s></p><formula xml:id="formula_22" coords="10,328.96,218.47,46.72,10.83">= ∈ R •</formula><p xml:id="_dBCRQT4"><s xml:id="_JKnCntF" coords="10,80.70,248.56,450.60,9.42;10,80.70,260.51,91.91,9.42">built for a directed graph, as its adjacency matrix is asymmetric and its degree matrix varies from in-degree and out-degree deinitions.</s></p><p xml:id="_VKX9Qkc"><s xml:id="_tnyzHbr" coords="10,90.66,272.47,442.18,9.42">In <ref type="bibr" coords="10,101.77,272.47,15.12,9.42" target="#b10">[11,</ref><ref type="bibr" coords="10,119.46,272.47,11.50,9.42" target="#b42">43,</ref><ref type="bibr" coords="10,133.54,272.47,11.34,9.42" target="#b85">86]</ref>, the NCut objective has been extended to directed graphs using the concept of random walk.</s><s xml:id="_4qmQ6r9" coords="10,80.35,284.42,350.01,9.42">Accordingly, the random walk directed graph Laplacian has been proposed as follows:</s></p><formula xml:id="formula_23" coords="10,241.74,299.22,286.35,11.70">= -(Π 1/2 Π -1/2 + Π -1/2 Π 1/2 )/2, (<label>15</label></formula><formula xml:id="formula_24" coords="10,528.10,301.49,3.80,9.42">)</formula><p xml:id="_2J5gTeb"><s xml:id="_veX32ft" coords="10,80.33,317.91,451.23,9.42;10,80.70,329.87,57.61,9.42">where is the transition matrix of a random walk, and Π is the diagonal matrix of its associated stationary distribution .</s><s xml:id="_t9W4sFx" coords="10,140.80,329.87,390.50,9.42;10,80.70,341.82,32.28,9.42;10,130.07,341.92,16.94,9.32">However, it is time-consuming to obtain the stationary distribution (e.g., via power iteration) that satisies = .</s><s xml:id="_kaxQnxy" coords="10,149.50,341.82,381.80,9.42">Due to the complexity of computing the stationary distribtion, <ref type="bibr" coords="10,407.25,341.82,16.40,9.42" target="#b34">[35]</ref> proposed the fast spectral</s></p><formula xml:id="formula_25" coords="10,80.70,351.71,245.12,17.95">normalized directed Laplacian = -1 2 -1 2 ( + ) -1 2</formula><p xml:id="_zEqGtDH"><s xml:id="_Dm8PQcy" coords="10,330.57,357.45,93.78,9.42;10,445.76,357.45,2.19,9.42">as an approximation to .</s><s xml:id="_6syQrjs" coords="10,90.66,369.40,442.18,9.42">Moreover, a simple but efective method is to symmetrize a directed graph into an undirected graph <ref type="bibr" coords="10,500.28,369.40,15.03,9.42" target="#b45">[46,</ref><ref type="bibr" coords="10,517.80,369.40,11.27,9.42" target="#b54">55]</ref>.</s><s xml:id="_znxBeNy" coords="10,80.70,381.36,450.84,9.42;10,80.40,393.31,26.68,9.42;10,122.39,393.22,38.59,9.51">For example, we can derive the symmetric adjacency matrix ( ) from the original asymmetric adjacency matrix () via = + .</s><s xml:id="_S59UZEA" coords="10,163.38,393.31,367.92,9.42;10,80.70,405.27,88.90,9.42">In other words, the weight of an edge in the built symmetric graph is the sum of the weights on two directed edges.</s><s xml:id="_gTgJ2Nq" coords="10,171.83,405.27,308.66,9.42">Note that this is diferent from simply ignoring the directionality of the edges.</s><s xml:id="_AXfRVpq" coords="10,482.71,405.27,48.59,9.42;10,80.70,418.70,174.84,9.42">With , we have symmetric directed graph Laplacian as</s></p><formula xml:id="formula_26" coords="10,273.50,415.60,78.27,12.17">= --1/2 -1/2</formula><p xml:id="_U6XpteX"><s xml:id="_hHs22CY" coords="10,352.27,418.70,29.32,9.42;10,396.93,418.70,135.91,9.42">, where is the degree matrix built from .</s><s xml:id="_P5MevFe" coords="10,80.70,430.66,46.75,9.42;10,143.08,430.66,389.76,9.42">In addition, can be replaced by either out-degree matrix or in-degree matrix built from directed graphs <ref type="bibr" coords="10,514.27,430.66,14.85,9.42" target="#b34">[35]</ref>.</s><s xml:id="_8fqdFyW" coords="10,80.70,442.61,118.87,9.42;10,217.40,442.61,93.10,9.42;10,326.13,442.61,176.51,9.42">In this work, we observe that with the degree matrix performs best, which is adopted in GRACE.</s><s xml:id="_wuBB6Ae" coords="10,505.14,442.61,26.17,9.42;10,80.70,454.57,202.43,9.42;10,298.54,454.48,232.76,9.51;10,80.70,466.43,450.60,9.51;10,80.70,478.48,119.17,9.42">As the number of undirected edges is at most doubled by = + , the time complexity of its corresponding graph convolution is () for one sparse matrix multiplication, where is the number of directed edges and is the dimension of node attributes.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2" xml:id="_KDyu3DH">Graph Laplacians for Hyper-Graphs</head><p xml:id="_zuY9aDf"><s xml:id="_XxGxeQR" coords="10,80.70,515.47,277.61,9.42">For hyper-graphs, each hyper-edge can connect more than two nodes.</s><s xml:id="_Z5CV6xM" coords="10,360.53,515.47,162.65,9.42;10,80.70,527.43,152.86,9.42;10,250.83,527.43,202.29,9.42">As discussed, we use an incidence matrix to represent all hyper-edges, such that = 1 if and only if node belongs to hyper-edge .</s><s xml:id="_Uv2BHsW" coords="10,455.56,527.43,75.74,9.42;10,80.70,539.38,252.85,9.43;10,349.60,539.38,181.70,9.42;10,80.70,551.34,250.88,9.42">With the incidence matrix , we have two diagonal matrices, node degree matrix and edge degree matrix , which represent the number of incident hyper-edges and nodes, respectively.</s><s xml:id="_ukVBDYh" coords="10,334.24,551.34,197.25,9.42;10,80.70,563.29,385.60,9.42">Therefore, in hyper-graph clustering, the linear hyper-graph Laplacian was proposed to minimize the NCut on hyper-edges as follows <ref type="bibr" coords="10,433.64,563.29,15.00,9.42" target="#b53">[54,</ref><ref type="bibr" coords="10,451.14,563.29,11.37,9.42" target="#b84">85]</ref>:</s></p><formula xml:id="formula_27" coords="10,262.58,578.09,265.52,12.53">= --1/2 -1 -1/2 . (<label>16</label></formula><formula xml:id="formula_28" coords="10,528.10,581.19,3.80,9.42">)</formula><p xml:id="_r23VF93"><s xml:id="_dJgBK2s" coords="10,99.11,597.61,76.48,9.42;10,200.35,597.61,66.74,9.42">is the extension of on hyper-edges.</s><s xml:id="_JatvbeQ" coords="10,269.83,597.61,261.47,9.42;10,80.70,609.57,165.69,9.42">Speciically, each hyper-edge is regarded as a clique, i.e., nodes inside a hyper-edge are fully connected.</s><s xml:id="_JM9ZFMq" coords="10,248.90,609.57,282.41,9.42;10,80.70,621.52,64.69,9.42">Then, when a hyper-edge is cut, it is equivalent to partitioning the resulting clique.</s><s xml:id="_y95Q3Ck" coords="10,147.89,621.52,263.15,9.42">There are other variants of linear hyper-graph Laplacians <ref type="bibr" coords="10,383.22,621.52,10.34,9.42" target="#b0">[1,</ref><ref type="bibr" coords="10,396.06,621.52,11.23,9.42" target="#b51">52]</ref>.</s><s xml:id="_Wu65emC" coords="10,413.54,621.52,117.76,9.42;10,80.70,633.39,450.61,9.52">However, the construction of these Laplacians has sufered from ineicient graph convolution, with the time complexity of ( ), where</s></p><formula xml:id="formula_29" coords="10,101.59,645.34,90.47,10.83">= ∈ (| |)(| | -1)/2</formula><p xml:id="_VQUsz7F"><s xml:id="_pZgu9yd" coords="10,194.56,645.43,175.32,9.42">is the number of the resulting clique edges.</s></p><p xml:id="_JzuSXyR"><s xml:id="_5kahvSS" coords="11,90.66,107.52,440.64,9.42;11,80.70,119.47,314.03,9.42">To design an eicient hyper-graph convolution, we leverage the non-linear hyper-graph Laplacian <ref type="bibr" coords="11,491.72,107.52,10.35,9.42" target="#b7">[8,</ref><ref type="bibr" coords="11,504.57,107.52,11.45,9.42" target="#b26">27,</ref><ref type="bibr" coords="11,518.51,107.52,8.53,9.42" target="#b79">80</ref>] by converting an attributed hyper-graph into an undirected graph as follows:</s></p><p xml:id="_RdANnQa"><s xml:id="_d3ZBhUb" coords="11,96.17,132.18,366.44,11.99;11,463.11,133.89,64.30,9.42;11,105.11,145.85,156.13,9.42">• We ind two farthest nodes inside each hyper-edge, i.e., ( , ) = arg max , ∈ ||xx || 2 , where x and x are attribute vectors of nodes and .</s><s xml:id="_DESAYCd" coords="11,263.69,145.85,268.72,9.42;11,116.99,157.71,97.25,9.51;11,96.17,169.67,435.13,9.51;11,105.11,181.62,334.15,9.51">The rest of nodes in each hyper-edge is denoted as mediators, i.e., = { ∈ , ≠ , ≠ }. • We construct an edge ( , ) between two farthest nodes, and construct other edges between and mediators of , and between and mediators of for each hyper-edge ∈ .</s><s xml:id="_NUG4ZjP" coords="11,442.16,181.71,89.14,9.42;11,104.74,193.58,296.33,9.51">We choose each edge weight as 1/(2| | -3) as there are 2| | -3 edges built for a hyper-edge .</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_Cz7mmYz">• We build the symmetric non-linear hyper-graph Laplacian as</head><formula xml:id="formula_30" coords="11,378.79,204.00,79.02,12.17">= --1/2 -1/2</formula><p xml:id="_XNDERnm"><s xml:id="_w5ExB7q" coords="11,458.31,207.11,29.85,9.42;11,503.27,207.11,14.90,9.42;11,105.11,219.06,327.43,9.42">, where and are the adjacency matrix and degree matrix of the constructed undirected graph.</s><s xml:id="_a4SJ5Rx" coords="11,90.66,233.48,88.01,9.42;11,203.17,233.48,328.13,9.42;11,80.70,245.44,283.86,9.42">In the construction of , we only consider a part of representative edges that are incident to two farthest nodes, instead of using a fully connected sub-graph for each hyper-edge.</s><s xml:id="_pQcHkF6" coords="11,366.43,245.44,165.06,9.42;11,80.70,257.39,437.12,9.42">This is because nodes with very dissimilar attributes are more likely partitioned into diferent clusters and then counted as a cut on this hyper-edge.</s><s xml:id="_VBAR9DY" coords="11,520.40,257.39,10.90,9.42;11,80.70,269.35,188.44,9.42;11,296.12,269.35,6.68,9.42;11,332.50,270.27,29.02,9.82;11,364.11,269.26,32.31,9.51">As a result, the number of edges for constructing is = ∈ 2| | -3.</s><s xml:id="_GbHrbdD" coords="11,398.91,269.35,132.40,9.42;11,80.70,281.21,298.22,9.51;11,395.69,281.40,11.63,9.32">The corresponding hyper-graph convolution becomes much more eicient with a time complexity of ( ).</s></p><p xml:id="_FkGVsFA"><s xml:id="_J8fvsxq" coords="11,90.66,293.26,81.07,9.42;11,198.71,293.26,334.12,9.42">The construction of relies on the node attributes by choosing two farthest nodes for each hyper-edge.</s><s xml:id="_VFJU5c2" coords="11,80.22,305.21,451.08,9.42;11,80.70,318.65,36.28,9.42">When applying high-order hyper-graph convolution, the node attributes are processed and changed at each iteration.</s><s xml:id="_9PQF22Q" coords="11,119.37,318.65,41.27,9.42;11,168.98,315.55,16.64,6.68;11,189.09,318.65,285.50,9.42;11,483.90,316.87,16.64,6.68;11,501.63,318.65,29.67,9.42;11,80.33,333.27,47.39,9.42;11,137.14,331.49,37.07,10.84;11,188.18,330.16,16.64,6.68;11,205.90,333.18,8.87,9.16;11,216.65,331.49,16.64,6.68;11,236.86,333.27,68.33,9.42">Therefore, ( -1)  should be constructed dynamically based on the current node attributes ( -1) , before we perform ( ) = ( - ( -1)  ) ( -1) at each iteration.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3" xml:id="_Kmr8zss">Graph Laplacians to Multi-relational Graphs</head><p xml:id="_q27bFbJ"><s xml:id="_vsmBUPw" coords="11,80.70,370.49,452.29,9.42;11,80.70,382.44,21.71,9.42">Finally, in a multi-relational graph, diferent types of edge connections can be modelled by a set of adjacency matrices</s></p><formula xml:id="formula_31" coords="11,104.79,382.08,428.05,9.78">A = { 1 , • • • , }. Correspondingly, we can derive a set of symmetric graph Laplacians { 1 , • • • , }.</formula><p xml:id="_6TURfS4"><s xml:id="_U6cy6Wg" coords="11,80.40,394.40,450.90,9.42;11,80.70,406.35,201.99,9.42">To cluster a multi-relational graph, it is a common practice to ind clusters by minimizing the weighted sum of heterogeneous NCuts of all edge types as follows:</s></p><formula xml:id="formula_32" coords="11,186.97,421.13,344.93,23.87">min = ︁ ∈ R • ( ) = min = ( ︁ ∈ R )<label>(17)</label></formula><p xml:id="_hShVG9J"><s xml:id="_7Q7TVzv" coords="11,80.33,450.50,450.97,9.63;11,80.70,462.54,450.61,9.42;11,80.70,474.50,245.01,9.42">where denotes the cluster assignment matrix, &gt; 0 is the coeicient for each edge type ∈ R. The above equation implies that minimizing the weighted sum of heterogeneous NCuts is equivalent to minimizing the NCut with the weighted sum of symmetric graph Laplacians.</s><s xml:id="_wembEa2" coords="11,328.20,474.50,203.10,9.42;11,80.70,486.46,84.50,9.42">And then we can deine our multi-relational graph Laplacian as follows:</s></p><formula xml:id="formula_33" coords="11,284.65,497.05,247.25,23.87">= ︁ ∈ R • .<label>(18)</label></formula><p xml:id="_gFVTvtg"><s xml:id="_cEBZC2r" coords="11,80.70,524.42,451.70,9.42;11,80.70,536.37,306.28,9.42">It is worth noting that tuning the coeicients separately can further improve the clustering performance, compared to simply setting them the same for all diferent relation types.</s><s xml:id="_rx8cV6H" coords="11,389.81,536.37,41.24,9.42;11,453.55,536.37,79.43,9.42;11,80.70,548.24,425.68,9.51">When the is applied to multirelational graph convolution, the time complexity is (), where is the number of edges of all types.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4" xml:id="_DMEXGFf">A General Graph Convolution Framework</head><p xml:id="_BBjvvk7"><s xml:id="_5DTzwvR" coords="11,80.70,585.55,435.59,9.42">Now we have studied diferent graph Laplacians (summarized in Table <ref type="table" coords="11,361.04,585.55,3.72,9.42" target="#tab_1">2</ref>) for all four types of graph structures.</s><s xml:id="_usznQB7" coords="11,518.45,585.55,12.86,9.42;11,80.70,597.50,452.14,9.42">We can put them into the GRACE framework for clustering attributed graphs with diferent types of graph structures.</s><s xml:id="_AV5Krjt" coords="11,80.40,609.46,370.86,9.42;11,466.93,609.46,64.37,9.42;11,80.70,621.41,43.24,9.42;11,138.96,621.41,57.47,9.42">The pseudo-code of GRACE is given in Algorithm 2. First, we build a speciic graph Laplacian according to the graph type in Lines 14-30.</s><s xml:id="_pVnWRHB" coords="11,198.76,621.41,332.54,9.42;11,80.70,633.37,207.33,9.42">That is, we convert the given graph into the undirected graph (or graphs), and build the corresponding adjacency matrix (or matrices).</s><s xml:id="_DfeKgm3" coords="11,290.69,633.37,240.61,9.42;11,80.70,645.32,177.46,9.42">And then we add self-loops before constructing the graph Laplacian in the form as we have discussed.</s><s xml:id="_tDJkSCE" coords="12,111.08,165.49,214.93,10.60;12,87.07,179.28,5.59,7.54">Build node attribute matrix from , and initialize (0) = 3:</s></p><p xml:id="_wcF7dua"><s xml:id="_PHqxcbW" coords="12,111.08,178.57,94.70,8.48;12,221.08,176.45,116.16,10.60;12,87.07,190.24,5.59,7.54">Compute graph Laplacian = BuildLaplacian(, , (0) ) 4:</s></p><p xml:id="_ThP879p"><s xml:id="_UkavjXp" coords="12,111.08,189.53,74.30,9.42;12,87.07,201.20,5.59,7.54">for = 1 to max do 5:</s></p><p xml:id="_ESWJxT4"><s xml:id="_FEv52hb" coords="12,124.53,198.37,72.72,10.60;12,215.03,198.37,26.37,10.28;12,87.07,212.35,5.59,7.54">Perform ( ) = ( -) ( -1)   6:</s></p><p xml:id="_H5HQQhA"><s xml:id="_wcFZjCu" coords="12,124.53,209.53,224.13,10.60">Obtain clusters ( ) by applying SVD and K-means on ( )</s></p><formula xml:id="formula_34" coords="12,83.36,221.04,199.20,54.43">7: if ( ( -1) ) -( ( ) ) ≤ then 8: count = count + 1 9: if count ≥ 2 then 10: break 11:</formula><p xml:id="_N9uUgYq"><s xml:id="_UpAaYkN" coords="12,124.53,267.22,96.33,8.48;12,111.08,452.73,125.51,8.48;12,83.36,464.39,9.29,7.54">if is hyper-graph then else if is multi-relational then 27:</s></p><p xml:id="_t37JUTv"><s xml:id="_t57A6Kx" coords="12,124.53,463.69,119.76,8.48">Build a set of adjacency matrices</s></p><formula xml:id="formula_35" coords="12,83.36,463.61,255.85,21.35">A = { 1 , • • • , } from 28:</formula><p xml:id="_TyTKC4Q"><s xml:id="_FfSBSXN" coords="12,111.08,476.71,11.19,8.48;12,138.26,476.71,24.58,8.48;12,178.83,476.63,158.24,8.56">Set = 1 (or = 1) for all nodes ∈ (of all types ∈ R)</s></p><p xml:id="_RWGDc4P"><s xml:id="_2rUbUxy" coords="12,83.36,490.11,9.29,7.54">29:</s></p><p xml:id="_mnQpmQG"><s xml:id="_JXXUxhp" coords="12,111.08,489.40,33.65,8.48;12,160.02,487.28,202.07,10.60;12,385.37,489.40,42.96,8.48;12,83.36,501.07,9.29,7.54">Compute = --1/2 -1/2 (or the weighted sum of Laplacians of all types) 30:</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_rEzCGyk">Return</head><p xml:id="_c9Pjbap"><s xml:id="_XMUDJ7M" coords="12,90.66,568.97,440.64,9.42;12,80.70,580.93,450.61,9.42;12,80.70,592.88,43.17,9.42">Next, similarly to GRAC, we use the constructed graph Laplacian to perform graph convolution on node attributes, and then apply K-means with SVD on processed node attributes to ind good clusters until the iteration is stopped.</s><s xml:id="_ugse9J3" coords="12,126.35,592.88,89.83,9.42;12,232.21,592.88,283.28,9.42">It is worth noting that is built once at the beginning for all graph types except hyper-graphs.</s><s xml:id="_sApxJJB" coords="12,517.97,592.88,13.52,9.42;12,80.70,604.84,110.54,9.42;12,207.30,604.84,238.75,9.42">For hyper-graphs, we construct dynamically at each iteration before the graph convolution.</s><s xml:id="_2tcgBGZ" coords="12,448.55,604.84,83.01,9.42;12,80.70,616.70,370.32,9.51">The time complexity of building graph Laplacian is (), where is the number of edges of the built graph.</s><s xml:id="_Fgyqh8N" coords="12,454.00,616.79,77.30,9.42;12,80.70,627.03,450.61,11.14;12,80.70,640.70,349.65,9.42">And the total time complexity of GRACE is (( + 2 + 2 )), where , , , , and are the number of nodes, the number of edges, attribute dimension, the number of clusters, and iteration number, respectively.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6" xml:id="_WPnZECe">EXPERIMENTS</head><p xml:id="_rv9KTJb"><s xml:id="_GcP3c4q" coords="13,80.22,362.42,451.09,9.42;13,80.70,374.38,107.46,9.42">We conduct experiments to show the efectiveness, eiciency and generality of GRACE for clustering diferent types of attributed graphs.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1" xml:id="_knsAms8">Datasets</head><p xml:id="_DGYMFSz"><s xml:id="_vduCBMs" coords="13,80.22,416.39,451.09,9.42;13,80.70,428.35,118.46,9.42">We used 14 datasets in our experiments with 4 diferent graph types: undirected (Undi), directed (Di), Hyper, and multi-relational (MR) graphs.</s><s xml:id="_Y8rXPgH" coords="13,201.64,428.35,329.66,9.42;13,80.70,440.30,111.98,9.42">The statistics of the datasets are summarized in Table <ref type="table" coords="13,420.83,428.35,3.41,9.42" target="#tab_3">3</ref>. #Node and #Edge are the number of nodes and edges.</s><s xml:id="_qYSWdeq" coords="13,195.58,440.21,223.45,9.51">|R| represents the number of edge types for MR graphs.</s><s xml:id="_McYz8hC" coords="13,421.51,440.30,109.79,9.42;13,80.70,452.26,113.22,9.42">#Attribute is the dimension of the node attribute vector.</s><s xml:id="_cdvU8PF" coords="13,196.40,452.26,285.53,9.42">#Class is the number of classes i.e., the number of ground-truth labels.</s></p><p xml:id="_m3anvAF"><s xml:id="_ZdjhV6w" coords="13,90.66,469.88,440.65,9.42;13,80.70,481.84,145.68,9.42">For undirected graphs, Undirected Cora, Citeseer, Pubmed, and Wiki are commonly used to evaluate undirected AGC algorithms <ref type="bibr" coords="13,194.02,481.84,14.93,9.42" target="#b65">[66,</ref><ref type="bibr" coords="13,211.44,481.84,11.20,9.42" target="#b83">84]</ref>.</s><s xml:id="_mzTSUm9" coords="13,228.86,481.84,302.45,9.42;13,80.70,493.79,284.24,9.42">The irst three datasets are citation networks, where nodes are publications and they are connected if one cites another (ignoring the directionality).</s><s xml:id="_zEkDNYr" coords="13,367.07,493.79,164.24,9.42;13,80.70,505.75,211.66,9.42">Wiki is a web-page network whose nodes are websites and are connected if one links another.</s><s xml:id="_YsdSzeb" coords="13,294.84,505.75,236.47,9.42;13,80.33,517.70,452.51,9.42">The nodes in Undirected Cora and Citeseer are associated with binary word vectors, while the nodes in Pubmed and Wiki are associated with tf-idf weighted word vectors.</s><s xml:id="_BRSBzN6" coords="13,80.70,529.66,450.60,9.42;13,80.22,541.61,53.51,9.42">Pubmed is connected, i.e., there is a path from any node to any other node, while Undirected Cora, Citeseer and Wiki are not.</s><s xml:id="_VUaQtQM" coords="13,136.23,541.61,345.27,9.42;13,499.75,541.52,32.65,9.51;13,80.33,553.57,172.84,9.42;13,271.39,553.48,36.48,9.51">Moreover, the edges of Undirected Cora, Citeseer, and Pubmed are not weighted, i.e., ∈ {0, 1}, while the edges of Wiki are weighted, i.e., ∈ [0, 16].</s><s xml:id="_Jn43WNc" coords="13,310.36,553.57,220.94,9.42;13,80.70,565.52,285.28,9.42">For directed graphs, we used two citation networks Cora-ML and Directed Citeseer by maintaining the directionality <ref type="bibr" coords="13,347.43,565.52,14.84,9.42" target="#b63">[64]</ref>.</s></p><p xml:id="_b8CEzwF"><s xml:id="_fczQeF9" coords="13,90.66,583.15,441.74,9.42;13,80.70,595.10,418.02,9.42">For hyper-graphs, we used two Co-authorship networks: Cora Co-authorship and DBLP Co-authorship, and three Co-citation networks: Cora Co-citation, Citeseer Co-citation and Pubmed Co-citation <ref type="bibr" coords="13,479.99,595.10,14.99,9.42" target="#b79">[80]</ref>.</s><s xml:id="_gGYaYKu" coords="13,501.38,595.10,31.60,9.42;13,80.70,607.06,450.60,9.42;13,80.70,619.01,274.13,9.42">For Coauthorship data, publications co-authored by an author are connected in one hyper-edge, while for Co-citation data, all publications cited by a publication are in one hyper-edge.</s><s xml:id="_4JrCkjh" coords="13,357.44,619.01,175.54,9.42;13,80.33,630.97,94.87,9.42">Each publication is represented by bag-ofwords attribute vector.</s><s xml:id="_7q9QwEY" coords="13,178.20,630.97,243.27,9.42">Hyper-edges that have only one hyper-node are removed.</s><s xml:id="_aTY5G7D" coords="13,424.46,630.97,106.84,9.42;13,80.70,642.92,410.41,9.42">The larger datasets DBLP Co-authorship and Pubmed Co-citation are typically used for time and memory eiciency validation.</s></p><p xml:id="_FJBfVjW"><s xml:id="_TP6KV79" coords="14,90.66,107.52,441.74,9.42;14,80.33,119.47,211.36,9.42">For multi-relational graphs, we used three multi-relational graphs: ACM, IMDB, and Hete DBLP <ref type="bibr" coords="14,499.80,107.52,15.05,9.42" target="#b52">[53,</ref><ref type="bibr" coords="14,517.35,107.52,11.29,9.42" target="#b69">70]</ref>, which are constructed from heterogeneous graphs.</s><s xml:id="_MfATrfd" coords="14,294.28,119.47,237.02,9.42;14,80.70,131.43,48.21,9.42">ACM consists of 3025 papers (P), 5835 authors (A) and 56 subjects (S).</s><s xml:id="_QHNtp8S" coords="14,131.41,131.43,400.99,9.42;14,80.70,143.38,405.74,9.42">To cluster papers into diferent groups, we used the PAP (i.e., papers-authors-papers) and PSP (i.e., papers-subjects-papers) meta-paths to construct the two-type multi-relational (MR) graph for ACM.</s><s xml:id="_zmhpK5E" coords="14,488.90,143.38,42.40,9.42;14,80.70,155.34,277.52,9.42">The IMDB consists of 3550 movies (M), 4441 actors (A), and 1726 directors (D).</s><s xml:id="_ptqdqKw" coords="14,360.70,155.34,170.60,9.42;14,80.70,167.29,329.16,9.42">To cluster movies, we used the MAM and MDM meta-paths to construct the two-type multi-relational (MR) graph for IMDB.</s><s xml:id="_Hq8QuCW" coords="14,412.28,167.29,119.25,9.42;14,80.70,179.25,287.69,9.42">Finally, DBLP consists of 4057 authors (A), 14328 papers (P), 20 conferences (C), and 7723 terms (T).</s><s xml:id="_BqRfzkv" coords="14,371.17,179.25,160.13,9.42;14,80.70,191.20,410.26,9.42">To cluster authors, we constructed the three-type multi-relational (MR) graph for DBLP based on the APA, APCPA, and APTPA meta-paths.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2" xml:id="_QBuwhRq">Evaluation Metrics and Experimental Setups</head><p xml:id="_D2p8kHd"><s xml:id="_F3XZcva" coords="14,80.70,228.88,451.70,9.42;14,80.70,240.84,370.44,9.42">In our experiments, we used four unsupervised measures: IntraFD and InterED, and their approximations, i.e., IntraFD_approx and InterED_approx (see Section 4.3) to evaluate the clustering quality w.r.t.</s><s xml:id="_P5CVxJN" coords="14,453.63,240.84,77.67,9.42;14,80.70,252.79,115.55,9.42">node attributes and graph structure, respectively.</s><s xml:id="_BTkqvYw" coords="14,198.56,252.79,332.75,9.42;14,80.70,264.75,24.72,9.42">For all the measures, the lower their values the better is the quality of the clustering result.</s><s xml:id="_2wdPwt8" coords="14,107.77,264.75,423.54,9.42;14,80.70,276.70,450.61,9.42;14,80.70,288.66,33.59,9.42">Lower IntraFD and IntraFD_approx mean that nodes with similar attributes are more likely grouped in the same cluster, while lower InterED and InterED_approx mean that less edges are connected between diferent clusters.</s><s xml:id="_2g6RjT4" coords="14,116.78,288.66,414.52,9.42;14,80.70,300.62,450.61,9.42;14,80.70,312.57,129.40,9.42">In addition, we also used three commonly used supervised measures to evaluate the clustering results based on the ground-truth labels: clustering accuracy (Acc), normalized mutual information (NMI), and f1-macro score (F1) <ref type="bibr" coords="14,122.00,312.57,14.95,9.42" target="#b48">[49,</ref><ref type="bibr" coords="14,139.44,312.57,11.44,9.42" target="#b65">66,</ref><ref type="bibr" coords="14,153.36,312.57,11.44,9.42" target="#b66">67,</ref><ref type="bibr" coords="14,167.29,312.57,11.44,9.42" target="#b70">71,</ref><ref type="bibr" coords="14,181.22,312.57,11.44,9.42" target="#b73">74,</ref><ref type="bibr" coords="14,195.14,312.57,11.21,9.42" target="#b83">84]</ref>.</s><s xml:id="_Euwscyp" coords="14,212.58,312.57,320.26,9.42">For all supervised measures, a higher value indicates a better clustering quality.</s></p><p xml:id="_3f5nd6z"><s xml:id="_SYewb6A" coords="14,90.66,324.53,440.64,9.42;14,80.70,336.48,274.60,9.42">We conducted all experiments on a Linux system with an Intel (R) Xeon (R) Silver 4114 CPU at 2.20GHz with 256GB of RAM, except the experiments with multi-relational graphs.</s><s xml:id="_PvWqBmj" coords="14,357.79,336.48,173.52,9.42;14,80.70,348.44,173.63,9.42;14,256.81,346.72,3.38,6.88;14,263.18,348.44,213.90,9.42">This is because the state-of-the-art baseline SpectralMix <ref type="bibr" coords="14,132.51,348.44,16.43,9.42" target="#b52">[53]</ref> was implemented in Java <ref type="foot" coords="14,256.81,346.72,3.38,6.88" target="#foot_3">3</ref> and incurred an execution error in our Linux server.</s><s xml:id="_FSbnb5j" coords="14,479.56,348.44,51.74,9.42;14,80.70,360.39,450.61,9.42;14,80.70,372.35,165.75,9.42">To solve this issue, we ran all experiments for multi-relational graphs on a windows system with an Intel(R) Xeon(R) CPU E5-1620 v2 @ 3.70GHz with 16G of RAM.</s><s xml:id="_TCU288C" coords="14,248.93,372.35,282.37,9.42;14,80.70,384.30,450.61,9.42;14,80.70,396.26,42.16,9.42">We report the running time (in seconds) averaged over 10 runs of each dataset (excluding data loading and pre-processing ), and the maximum process memory usage (in MB) of each algorithm.</s><s xml:id="_kYvcjWy" coords="14,125.35,396.26,270.56,9.42">We will release the code and data for reproducibility of the results.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3" xml:id="_xWMK55K">Baselines and Parameter setings</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_Qabc3Qa">Baseline</head><p xml:id="_vZ668Su"><s xml:id="_DsSUwgA" coords="14,262.36,464.85,21.97,9.42;14,309.13,464.85,99.31,9.42">Input Undi Di Hyper MR</s></p><formula xml:id="formula_36" coords="14,203.56,481.81,204.58,110.07">K-Means attribute ✓ ✓ ✓ ✓ N-cut structure ✓ ✓ ✓ ✓ ARGE both ✓ ARVGE both ✓ AdaGCN both ✓ GNMF both ✓ ✓ JNMF both ✓ ✓ SpectralMix both ✓ GRACE both ✓ ✓ ✓ ✓</formula><p xml:id="_ta8ru2M"><s xml:id="_Trv8XwD" coords="14,90.66,612.33,318.22,9.42">We compared GRACE with the baselines on diferent types of graph structures.</s><s xml:id="_Eh7zBce" coords="14,411.38,612.33,119.93,9.42;14,80.70,624.29,295.52,9.42">Their main characteristics are summarized in Table <ref type="table" coords="14,167.94,624.29,3.41,9.42" target="#tab_4">4</ref>, and the parameter settings are introduced below.</s><s xml:id="_MpWsXB6" coords="15,134.51,107.52,396.80,9.42;15,80.70,119.47,49.78,9.42"><ref type="bibr" coords="15,134.51,107.57,18.31,9.37" target="#b43">[44]</ref> and N-cut <ref type="bibr" coords="15,204.61,107.57,18.31,9.37" target="#b25">[26]</ref> are clustering algorithms that use only node attribute or graph structure information.</s><s xml:id="_PbwWTHG" coords="15,132.83,119.47,373.54,9.42">K-means can simply be applied on all datasets because it ignores any type of graph structures.</s><s xml:id="_pNb7MNc" coords="15,508.73,119.47,22.57,9.42;15,80.33,131.43,255.58,9.42">N-cut was originally designed for clustering simple undirected graphs.</s><s xml:id="_cyfr4Sd" coords="15,338.30,131.43,193.00,9.42;15,80.70,143.38,285.25,9.42">However, as stated in Section 5, it can be used to cluster other types of graphs with properly designed graph Laplacians.</s><s xml:id="_Wh7yHPy" coords="15,368.42,143.38,162.87,9.42;15,80.70,155.34,141.96,9.42;15,242.46,155.34,158.09,9.42;15,418.72,155.34,112.59,9.42;15,80.70,167.29,38.77,9.42;15,141.29,167.29,390.01,9.42;15,80.70,179.25,45.23,9.42">Speciically, we selected the fast spectral normalized directed Laplacian <ref type="bibr" coords="15,206.28,155.34,16.38,9.42" target="#b34">[35]</ref> , the linear hyper-graph Laplacian <ref type="bibr" coords="15,384.16,155.34,16.38,9.42" target="#b30">[31]</ref> , and multi-relational graph Laplacian for corresponding graph structures, as they performed better compared to other graph Laplacian candidates.</s><s xml:id="_b8cc4XK" coords="15,128.42,179.25,29.01,9.42;15,179.25,179.25,259.76,9.42">For the laplacian, we used the same weights that we used for GRACE.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_mtZEQAP">K-means</head><p xml:id="_7umsKe8"><s xml:id="_c6SRQHv" coords="15,90.66,196.87,440.64,9.42;15,80.70,208.83,358.80,9.42;15,461.28,208.83,2.15,9.42">ARGE <ref type="bibr" coords="15,120.55,196.92,16.33,9.37" target="#b48">[49]</ref>, ARVGE <ref type="bibr" coords="15,179.86,196.92,16.33,9.37" target="#b48">[49]</ref>, and AdaGCN <ref type="bibr" coords="15,263.15,196.92,18.02,9.37" target="#b83">[84]</ref> are the state-of-the-art Undi-AGC methods that combine both node attribute and graph structure information via graph convolution using the Laplacian .</s><s xml:id="_V7xcK47" coords="15,465.91,208.83,65.40,9.42;15,80.70,220.78,150.12,9.42">We tuned ARGE and ARVGE for better performance.</s><s xml:id="_aMuW5Gm" coords="15,233.70,220.78,297.60,9.42;15,80.70,232.74,275.33,9.42">We used the discriminator's learning rate as of 0.001, 0.0001, 0.005, and 0.0005 on Undirected Cora, Citeseer, Pubmed and Wiki, respectively.</s><s xml:id="_qXdwN2Z" coords="15,358.53,232.74,172.77,9.42;15,80.70,244.69,124.66,9.42">We equally set the learning rate with these same values on these datasets.</s><s xml:id="_jQN78Nz" coords="15,207.84,244.69,323.65,9.42;15,80.70,256.65,450.61,9.42;15,80.70,268.60,252.03,9.42">For all datasets, we used 200 training epochs, 64 units in the third hidden layer and 32 in the irst and 16 in the second, and set the drop out rate and weight decay to 0. As for AdaGCN, we used the same parameter settings following the original paper <ref type="bibr" coords="15,314.18,268.60,14.84,9.42" target="#b83">[84]</ref>.</s></p><p xml:id="_FkQARMu"><s xml:id="_Y7eMVwX" coords="15,90.66,286.23,440.83,9.42;15,80.70,298.18,145.97,9.42">GNMF <ref type="bibr" coords="15,122.39,286.28,13.09,9.37" target="#b5">[6]</ref> and JNMF <ref type="bibr" coords="15,185.46,286.28,18.21,9.37" target="#b16">[17]</ref> are two non-negative matrix factorization (NMF) based methods used to cluster attributed directed or hyper-graphs.</s><s xml:id="_V6kuQPe" coords="15,229.17,298.18,262.23,9.42">Both algorithms were not designed for directed or hyper-graphs.</s><s xml:id="_8tn7wqT" coords="15,493.91,298.18,38.49,9.42;15,80.70,310.14,312.09,9.42;15,410.62,310.14,8.61,9.42;15,439.89,310.14,91.41,9.42;15,80.70,322.09,450.60,9.42;15,80.70,334.05,123.22,9.42">However, following the work of <ref type="bibr" coords="15,170.64,310.14,14.74,9.42" target="#b26">[27]</ref>, we modiied both algorithms by incorporating the or Laplacians for directed graphs and hypergraphs respectively into the objective functions, and applying the same multiplicative update rules as <ref type="bibr" coords="15,113.80,334.05,16.28,9.42" target="#b26">[27]</ref> for optimizations.</s><s xml:id="_PjjPUez" coords="15,206.40,334.05,325.09,9.42;15,80.70,346.00,399.45,9.42">On directed graphs, we set = 0.53 on Cora-ML and = 20 on Directed Citeseer for GNMF, and set = 0.08, = 0.8 on Cora-ML, and = 20, = 1 on Directed Citeseer for JNMF.</s></p><p xml:id="_SEvsXP3"><s xml:id="_4CPXHtx" coords="15,90.66,363.63,425.04,9.42">SpectralMix <ref type="bibr" coords="15,147.27,363.68,18.13,9.37" target="#b52">[53]</ref> is the state-of-the-art algorithm used for clustering attributed multi-relational graphs.</s><s xml:id="_VeEYyF6" coords="15,518.20,363.63,13.10,9.42;15,80.70,375.58,257.57,9.42">We kept the same hyper-parameters as in <ref type="bibr" coords="15,237.09,375.58,16.39,9.42" target="#b52">[53]</ref> for ACM and IMDB.</s><s xml:id="_bGvFKr6" coords="15,340.75,375.58,190.55,9.42;15,80.70,387.54,200.52,9.42;15,301.48,387.54,102.98,9.42">For Hete DBLP, we set dimensionality as 3 (we tried 2, 3 and 9, but 3 gave the best performance), as 10 and _ as 2.</s></p><p xml:id="_8ME89TB"><s xml:id="_723Xb2S" coords="15,90.66,405.16,260.79,9.42">For GRACE, we tuned hyper-parameters on diferent datasets.</s><s xml:id="_QyzXkb6" coords="15,353.93,405.16,177.38,9.42;15,95.73,417.12,288.63,9.42;15,402.23,417.12,67.81,9.42">On undirected graphs, we used = 0.2 and = 0.15 for Undirected Cora, Citeseer, and Wiki, and used = 0.5 and = 0 for Pubmed.</s><s xml:id="_XYHqk7R" coords="15,472.89,417.12,57.92,10.28;15,80.70,429.07,450.61,10.28;15,80.70,441.03,103.88,9.42">We applied 2 normalization (for Undirected Cora) and 1 normalization (for Wiki and Pubmed) on processed node attributes before feeding into SVD.</s><s xml:id="_qnyRxvG" coords="15,187.80,441.03,174.78,9.42;15,381.67,441.03,149.63,9.42;15,80.70,452.98,15.29,9.42;15,114.05,452.98,118.13,9.42">On directed graphs, we used = 0.1 and = 0 for Cora-ML, and used = 0.5 and = 0.15 for Directed Citeseer.</s><s xml:id="_PbsgJWe" coords="15,235.07,452.98,162.84,9.42;15,415.97,452.98,115.33,9.42;15,80.70,464.94,252.34,9.42;15,351.34,464.94,44.70,9.42;15,414.35,464.94,78.48,9.42">On hyper-graphs, we used = 0.5 and = 0.1 for all datasets except Cora Co-authorship and DBLP Co-authorship, where we set = 0.12 and = 0.5, respectively.</s><s xml:id="_znwQJ9e" coords="15,495.81,464.94,35.50,9.42;15,85.77,476.89,403.69,10.28">We used 2 normalization on for Cora Co-authorship, Cora Co-citation and Pubmed Co-citation datasets.</s><s xml:id="_T4NqVmV" coords="15,492.15,476.89,40.83,9.42;15,80.70,488.85,450.60,9.42;15,80.70,500.80,421.50,9.42">On multirelational graphs, we used as 0.7 and 0.3 for the PAP and PSP relations on ACM, as 0.5 and 0.5 for the MAM and MDM relations on IMDB, and as 0.3 each for the APA, APCPA and APTPA relations on Hete DBLP.</s><s xml:id="_yc78uew" coords="15,504.70,500.80,26.61,9.42;15,89.40,512.76,38.61,9.42;15,144.96,512.76,252.85,10.28">We set = 0.1 and = 0 and used 2 normalization for all multi-relational graphs.</s><s xml:id="_AmMZmDX" coords="15,400.37,512.76,130.94,9.43;15,80.70,524.71,450.60,9.42;15,80.70,536.67,450.84,9.42;15,80.70,548.62,451.70,9.42;15,80.70,560.58,49.86,9.42">The s selected by the stopping criterion or maximum power for GRACE were: 40 for all heterogeneous graphs; 11, 16, 2, 23, and 17 for Cora Co-citation, Citeseer Co-citation, Pubmed Co-citation, Cora Co-authorship and DBLP Co-authorship; 26, 14, 21 and 40 for Citeseer, wiki, Undirected Cora, and Pubmed; and inally 18 and 40 for Directed Citeseer and Cora-ML, respectively.</s><s xml:id="_kzHRZWU" coords="15,133.07,560.58,398.24,9.42;15,80.70,572.45,450.79,9.51;15,94.80,584.40,436.50,9.52;15,89.43,594.42,17.39,10.09;15,100.23,601.72,9.81,6.68;15,114.42,596.36,416.88,9.51;15,80.70,612.40,221.16,9.42;15,313.42,609.29,9.81,6.68;15,337.90,612.40,16.76,9.42">Concerning the parameter selection strategy, (a) we used a random search for using values in the range [0.1, 0.5] in order to keep the ilters () low-pass i.e., decaying, (b) likewise we used a random search for using values in the range [0, 1], and (c) for , we started by giving equal importance to all relations using = 1 | R | for all relations, where |R| is the number of relations, and then used random search to give diferent importance to diferent relations while ensuring that | R | = 1.</s><s xml:id="_zGayzth" coords="15,357.67,612.40,120.18,9.42;15,488.70,610.38,3.38,6.88;15,502.94,612.40,28.36,9.42;15,80.70,624.98,82.57,9.43;15,187.75,624.98,178.73,9.42">In general, any values below 1  will be suitable for , where is the maximum eigen-value of the laplacian.</s><s xml:id="_tUD3Hqm" coords="15,368.90,624.98,162.40,9.42;15,80.70,636.93,22.78,9.43">Thus, we propose using values below 0.5 for .</s><s xml:id="_qp9d6ZA" coords="15,106.16,636.93,271.31,9.42">However, for faster graph clustering, should not be set too low.</s><s xml:id="_MNcPQz6" coords="15,380.14,636.93,151.16,9.42;16,80.70,107.52,451.70,9.42;16,80.33,120.95,77.96,9.42;16,169.27,117.85,9.81,6.68;16,192.62,120.95,15.35,9.42">For , we recommend assigning the same weights to all relations (except when the user has prior knowledge of which relation is most important), while ensuring that | R | = 1.</s><s xml:id="_wgypCwH" coords="16,210.39,120.95,321.17,9.42;16,80.70,132.91,148.23,9.42">The main challenge is how to select , for which values close to 0 are generally better according to our experiments.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4" xml:id="_6nAUVvP">Clustering Performance Comparison</head><p xml:id="_2nAM4bh"><s xml:id="_DHkCwej" coords="16,80.70,187.23,170.42,8.92">6.4.1 Performance on undirected graphs.</s><s xml:id="_2dgJkTu" coords="16,254.61,186.73,276.69,9.42;16,80.70,198.68,219.41,9.42">We irst compared the clustering performance on four undirected graphs: Undirected Cora, Citeseer, Pubmed, and Wiki.</s><s xml:id="_9MwbNDU" coords="16,302.60,198.68,191.39,9.42">The results are reported in Table <ref type="table" coords="16,437.97,198.68,4.64,9.42" target="#tab_5">5</ref> and Table <ref type="table" coords="16,487.15,198.68,3.42,9.42" target="#tab_6">6</ref>.</s><s xml:id="_YQ4AWFm" coords="16,496.49,198.68,34.81,9.42;16,80.70,210.64,171.02,9.42">The best results amongst all algorithms are in bold.</s><s xml:id="_9qYnZ7j" coords="16,90.66,501.53,440.64,9.42;16,80.70,513.49,319.87,9.42">From the tables, we can conclude that the K-Means and N-cut algorithms, which utilize only node attribute or graph structure information respectively, produce poorer clustering results.</s><s xml:id="_jgtJ74h" coords="16,403.08,513.49,128.23,9.42;16,80.70,525.44,235.55,9.42">K-Means outperforms N-cut on Undirected Cora, Citeseer, and Pubmed, but not on Wiki.</s><s xml:id="_3HR4tcp" coords="16,318.74,525.44,212.57,9.42;16,80.70,537.40,450.79,9.42;16,80.70,549.35,42.82,9.42">This may be due to the fact that the node attributes provide rich information in the irst three citation networks, while the weighted edges on Wiki help more for clustering.</s><s xml:id="_d63fzy8" coords="16,126.01,549.35,406.83,9.42">K-Means and N-cut are generally fast and use less memory as they do not combine the information.</s><s xml:id="_VyscC9n" coords="16,80.70,561.31,451.70,9.42;16,80.70,573.26,450.61,9.42;16,80.70,585.22,35.22,9.42">Moreover, the structure-based N-cut is more time and memory eicient on small graphs, e.g., Undirected Cora, Citeseer, and Wiki, but becomes more time and memory consuming when the graph size increases, e.g., on Pubmed.</s></p><p xml:id="_Z6XajF5"><s xml:id="_52jahVV" coords="16,90.66,597.18,440.64,9.42;16,80.70,609.04,254.49,9.51">The methods that combine node attribute and graph structure outperform K-Means and N-cut by a large margin, achieving 8.5% -46.1% improvements in terms of Acc.</s><s xml:id="_WwEaQaN" coords="16,337.67,609.13,193.63,9.42;16,80.70,621.09,450.61,9.42;16,80.70,633.04,234.24,9.42">The ARGE and ARVGE algorithms are the most time and memory consuming because they require training neural networks to combine node attribute and graph structure information e.g., for the large Pubmed dataset.</s><s xml:id="_SXjanJe" coords="16,317.74,633.04,213.56,9.42;16,80.35,645.00,316.14,9.42">The running time and memory usage of ARGE and ARVGE are 2000 times and 50 times, respectively more than those of K-Means.</s><s xml:id="_XSGgBAf" coords="16,398.98,645.00,133.42,9.42;17,80.70,107.52,450.87,9.42;17,80.70,119.47,18.51,9.42">Using graph convolution instead, the state-of-the-art AdaGCN algorithm can produce better clustering results with much less time and memory cost.</s></p><p xml:id="_2unYtgd"><s xml:id="_6M9wuQh" coords="17,90.66,131.43,440.64,9.42;17,80.70,143.38,250.23,9.42">Following the idea of AdaGCN, GRACE exploits efective and eicient graph convolution on undirected graphs to combine node attribute and graph structure information.</s><s xml:id="_cXKm7DB" coords="17,334.00,143.38,198.40,9.42;17,80.70,155.34,327.81,9.42">It remarkably outperforms K-Means and N-cut, and signiicantly saves time and memory cost compared to ARGE and ARVGE.</s><s xml:id="_yfkb7YT" coords="17,411.18,155.34,120.12,9.42;17,80.70,167.29,394.82,9.42">Furthermore, it improves the state-of-the-art performance of AdaGCN while being comparable in terms of time and memory cost.</s><s xml:id="_sR4GQV2" coords="17,477.58,167.29,53.91,9.42;17,80.70,179.25,452.14,9.42">Especially for the Wiki dataset, the improvements of GRACE are 15.6%, 10.1% and 7.7% in terms of Acc, NMI, and F1, respectively.</s><s xml:id="_9Vn4dMA" coords="17,80.70,191.20,450.61,9.42;17,80.70,203.16,150.31,9.42">Importantly, GRACE can deal with various types of graph structures (as shown below), while AdaGCN was proposed for undirected graphs only.</s></p><p xml:id="_Tb4VZSx"><s xml:id="_Hyv2eBH" coords="17,80.70,221.55,17.94,8.92">6.4.2</s><s xml:id="_dyqqm6w" coords="17,108.59,221.55,129.34,8.92">Performance on directed graphs.</s><s xml:id="_4TTrvBs" coords="17,241.42,221.05,290.99,9.42;17,80.70,233.01,282.06,9.42">We then evaluated the clustering performance on two directed graphs, Cora-ML and Directed Citeseer, and their results are given in Table <ref type="table" coords="17,355.93,233.01,3.41,9.42" target="#tab_7">7</ref>.</s><s xml:id="_HRAjxVh" coords="17,90.66,366.88,440.64,9.42;17,80.70,378.84,243.41,9.42">The table shows that neither K-Means (attribute-based) nor N-cut (structure-based) algorithm can produce satisfying clustering results on attributed directed graphs.</s><s xml:id="_3FC3vYP" coords="17,327.24,378.84,204.06,9.42;17,80.70,390.79,315.50,9.42">N-cut on these two datasets always outperforms K-Means when the directional information of graph structure has been utilized.</s><s xml:id="_jFJGr82" coords="17,398.52,390.79,133.88,9.42;17,80.33,402.75,450.98,9.42;17,80.70,414.70,378.65,9.42">The GNMF and JNMF algorithms, which combine node attribute and graph structure information using their respective objective functions, can generally obtain better clustering results compared to the K-Means and N-cut competitors.</s><s xml:id="_kzV4Var" coords="17,462.15,414.70,69.15,9.42;17,80.70,426.66,450.61,9.42;17,80.70,438.61,234.31,9.42">The results from GNMF and JNMF are comparable to each other, while GNMF usually takes less time and memory due to its simpler objective function and hence faster update rule.</s><s xml:id="_2acYKjy" coords="17,318.03,438.61,214.37,9.42;17,80.70,450.57,248.50,9.42">By applying graph convolution on directed graphs, GRACE consistently achieves the best clustering performance.</s><s xml:id="_zUsGAvM" coords="17,331.64,450.57,199.66,9.42;17,80.47,462.52,197.46,9.42">The improvements of GRACE in terms of NMI are 17.2% on Cora-ML and 6.0% on Directed Citeseer.</s><s xml:id="_yq8D7YT" coords="17,280.44,462.52,250.86,9.42;17,80.70,474.48,318.95,9.42">Though GRACE takes more time and memory space compared to GNMF, the diferences are negligible as both directed datasets are very small.</s><s xml:id="_gHAQVpD" coords="17,402.12,474.48,129.18,9.42;17,80.70,486.43,265.09,9.42">We will present the eiciency of GRACE later on larger hyper-graphs and multi-relational graphs.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.3" xml:id="_rvPPuWc">Performance on hyper-graphs.</head><p xml:id="_EcZyJ7T"><s xml:id="_hqubbMx" coords="17,233.08,504.33,277.93,9.42;17,513.50,502.61,3.38,6.88;17,519.87,504.33,11.43,9.42;17,80.70,516.28,297.26,9.42">We then analyzed the clustering results on two Co-citation datasets <ref type="foot" coords="17,513.50,502.61,3.38,6.88" target="#foot_4">4</ref> (as shown in Table <ref type="table" coords="17,145.31,516.28,3.26,9.42" target="#tab_8">8</ref>), and two Co-authorship datasets (as shown in Table <ref type="table" coords="17,368.17,516.28,3.26,9.42" target="#tab_9">9</ref>).</s><s xml:id="_hrvxV3W" coords="18,90.66,221.69,440.64,9.42;18,80.70,233.65,66.84,9.42">From the tables, we observe that the attribute-based K-Means algorithm always outperforms the structure-based N-cut algorithm.</s><s xml:id="_mX8Fabp" coords="18,150.04,233.65,381.26,9.42;18,80.70,245.60,276.16,9.42">This implies that node attributes are more informative than hyper-graph structure information for clustering on both the Co-citation and Co-authorship networks.</s><s xml:id="_m8MQDGg" coords="18,359.34,245.60,171.96,9.42;18,80.70,257.56,300.86,9.42">Especially on the Pubmed Co-citation and DBLP Co-authorship datasets, N-cut produces very poor clustering results.</s><s xml:id="_CRFy3rB" coords="18,384.04,257.56,147.26,9.42;18,80.70,269.51,450.61,9.42;18,80.70,281.47,386.06,9.42">Moreover, due to the dense resulting edges, and the time complexity of building the traditional hypergraph laplacian, N-cut can be very time and memory consuming on large hyper-graphs, e.g., Pubmed Co-citation and DBLP Co-authorship.</s></p><p xml:id="_63qF7YT"><s xml:id="_e4NYT9J" coords="18,90.66,293.42,440.83,9.42;18,80.70,305.38,450.61,9.42;18,80.70,317.33,395.47,9.42">As the hyper-graph structure contains very little information that helps for clustering (as shown by the poor N-cut results), the GNMF and JNMF algorithms that simply combine the node attribute and hyper-graph structure information in their objective functions perform even worse than the attribute-based methods.</s><s xml:id="_fTMRWJZ" coords="18,478.99,317.33,53.41,9.42;18,80.70,329.29,450.61,9.42;18,80.70,341.24,81.47,9.42">For example, the performance of GNMF and JNMF are 10.3% and 17.1% lower than K-Means in terms of NMI on the Pubmed Co-citation dataset.</s><s xml:id="_NWgC9ga" coords="18,165.37,341.24,366.19,9.42;18,80.70,353.20,450.86,9.42;18,80.70,365.15,326.98,9.42">Moreover, both GNMF and JNMF algorithms like N-cut also become time and memory consuming for large hyper-graphs, e.g., GNMF is about 50 times slower and takes about 30 times more memory than K-Means on the DBLP Co-authorship and the Pubmed Co-citation datasets.</s></p><p xml:id="_2Kw8MUq"><s xml:id="_9TJVhCh" coords="18,90.66,377.11,309.03,9.42">GRACE consistently outperforms all the baselines on all hyper-graph datasets.</s><s xml:id="_EcuEBCw" coords="18,401.74,377.11,129.56,9.42;18,80.70,389.06,450.60,9.42;18,80.70,401.02,132.88,9.42">Even for the Pubmed Co-citation network, it still well utilizes the inferior hyper-graph structure information to improve clustering performance of the attribute based clustering.</s><s xml:id="_6jsUwje" coords="18,216.06,401.02,316.34,9.42;18,80.70,412.89,391.63,9.51">GRACE outperforms the GNMF and JNMF algorithms by a large margin, e.g., 8.4% -17.1% in terms of NMI, and is time and memory eicient even for large hyper-graphs.</s><s xml:id="_py3ZEE4" coords="18,475.37,412.98,55.93,9.42;18,80.70,424.93,450.60,9.42;18,80.70,436.89,234.74,9.42">On the DBLP Co-authorship datasets, GRACE achieves the best performance, while using only 93 seconds and 1763 MB of memory, which are 39 times and 27 times less than JNMF.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_YSwHaQz">6.4.4</head><p xml:id="_UMeKapr"><s xml:id="_F5WqzFm" coords="18,108.66,455.30,162.36,8.92">Performance on multi-relational graphs.</s><s xml:id="_dA478G8" coords="18,274.50,454.81,256.80,9.42;18,80.70,466.76,252.69,9.42">We inally compared the clustering performance on the three multi-relational graphs (their results are reported in Table <ref type="table" coords="18,318.95,466.76,7.22,9.42" target="#tab_10">10</ref>).</s><s xml:id="_EGWq6mz" coords="18,335.89,466.76,195.41,9.42;18,80.70,478.72,193.01,9.42">Due to the space limitation, we only present the running time on the largest Hete DBLP dataset.</s><s xml:id="_KpVQ96Z" coords="18,90.66,609.63,440.64,9.42;18,80.70,621.59,28.62,9.42">The table shows that the K-Means algorithm with only node attribute information produces inferior clustering results.</s><s xml:id="_6cg56XD" coords="18,111.81,621.59,419.49,9.42;18,80.70,633.54,60.80,9.42">The structure-based method, N-cut, performs poorly on ACM and IMDB but performs exceptionally well on Hete DBLP.</s><s xml:id="_Sse5hFb" coords="18,144.00,633.54,387.31,9.42;18,80.70,645.50,280.19,9.42">This is because the three-type relations of Hete DBLP provide more information for clustering compared with the two-type relations of the ACM and IMDB datasets.</s><s xml:id="_fSHfrj8" coords="18,363.38,645.50,167.93,9.42;19,80.70,107.52,450.96,9.42;19,80.70,119.47,452.14,9.42">The clustering accuracy of using N-cut on the adjacency matrix of each individual relation of Hete DBLP is, 30% for the APA relation, 88.4% for the APCPA relation and 52.7% for the APTPA relation, while that for the combined relations is 92.31% as shown in Table <ref type="table" coords="19,521.46,119.47,7.58,9.42" target="#tab_10">10</ref>.</s><s xml:id="_cXxFnTA" coords="19,80.70,131.43,451.20,9.42;19,80.70,143.38,342.38,9.42">In comparison, the clustering accuracy of using N-cut on each individual relation of ACM and IMDB is: (ACM) 34.8% for PAP and 35.1% for PSP; and (IMDB) 37.5% for MDM and 37.7% for MAM.</s><s xml:id="_QrMzawC" coords="19,425.65,143.38,105.66,9.42;19,80.70,155.34,402.34,9.42">The results show that the relations of Hete DBLP capture more information for clustering than those of ACM and IMDB do.</s><s xml:id="_v8sgjGb" coords="19,485.53,155.34,45.77,9.42;19,80.70,167.29,450.79,9.42;19,80.70,179.25,72.06,9.42">The results also indicate that each relation of Hete DBLP captures diferent information and combining them gives better clustering results.</s></p><p xml:id="_wn97dKy"><s xml:id="_T6Uv6Mv" coords="19,90.66,191.20,401.98,9.42">On ACM, the state-of-the-art method, SpectralMix, outperforms GRACE in terms of clustering quality.</s><s xml:id="_kYC8GvM" coords="19,494.58,191.20,37.82,9.42;19,80.70,203.16,450.80,9.42;19,80.70,215.11,410.87,9.42">However, GRACE still achieves competitive clustering quality, and we remark that GRACE is orders of magnitude faster than SpralMix, which took 13,558 seconds compared to the 10 seconds of GRACE for clustering ACM.</s><s xml:id="_PJxj4DP" coords="19,494.07,215.11,38.32,9.42;19,80.70,227.07,431.47,9.42">However, on IMDB and Hete DBLP, GRACE outperforms SpectralMix (with a signiicant margin on Hete DBLP).</s><s xml:id="_YhjcNrf" coords="19,515.23,227.07,16.08,9.42;19,80.70,239.02,450.61,9.42;19,80.70,250.98,450.60,9.42;19,80.70,262.93,178.80,9.42">The performance diference on Hete DBLP is because SpectralMix takes into account the multi-relational graph structure and node attributes alternatively in its update rule, and as such, the contribution from the informative graph structure of Hete DBLP is weakened.</s><s xml:id="_aG2pZjT" coords="19,261.98,262.93,269.33,9.42;19,80.70,274.89,450.92,9.42;19,80.70,286.84,239.12,9.42">By using multi-relational graph convolution, GRACE can achieve comparable performance on ACM and IMDB, and produce much better performance on Hete DBLP (51.8% improvement in terms of Acc) compared with SpectralMix.</s><s xml:id="_7ceF95Z" coords="19,322.33,286.84,208.98,9.42;19,80.70,298.80,180.92,9.42">Furthermore, GRACE is about 300 times faster than SpectralMix on the large Hete DBLP dataset.</s><s xml:id="_yhSsW8D" coords="19,264.10,298.80,267.20,9.42;19,80.47,310.75,36.81,9.42">Note that the running time of SpectralMix on ACM and IMDB are 13,557.88</s><s xml:id="_vyCzueK" coords="19,119.77,310.75,381.19,9.42">and 51.89 seconds, respectively, while those of GRACE are 9.60 and 2.88 seconds, respectively.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.5" xml:id="_4U6jdaV">Conclusions of performance comparison.</head><p xml:id="_k2aDGFy"><s xml:id="_uRqgXwr" coords="19,269.12,331.82,262.19,9.42;19,80.70,343.77,450.87,9.42;19,80.70,355.73,437.06,9.42">In conclusion, the clustering results on various datasets show that GRACE generally outperforms other algorithms on all types of attributed graphs, while remaining competitively time and memory eicient compared to methods that do not combine node attribute and graph structure.</s><s xml:id="_WXURCV7" coords="19,520.35,355.73,11.21,9.42;19,80.70,367.68,450.61,9.42;19,80.70,379.64,450.61,9.42;19,80.70,391.59,171.65,9.42">By using graph convolution, GRACE can signiicantly outperform the methods that focus on either node attribute or graph structure, and perform much faster and takes much less memory compared to other competitors that combine the information in other manners.</s><s xml:id="_BexCb26" coords="19,254.64,391.59,276.92,9.42;19,80.33,403.55,158.29,9.42">The results demonstrate that our graph convolution based framework works well on various graph structures.</s><s xml:id="_yEpHENr" coords="19,241.00,403.55,290.29,9.42;19,80.70,415.50,185.40,9.42">This in fact shows the capability and universality of GRACE in capturing complex and diverse real-world relationships.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5" xml:id="_yetM2pg">Sensitivity Study</head><p xml:id="_ZTCZbNC"><s xml:id="_QUujaJm" coords="19,80.70,455.50,353.40,9.42">Now we discuss the sensitivity of GRACE's hyper-parameters on diferent graph types.</s><s xml:id="_WB6rFUU" coords="19,436.59,455.50,94.71,9.42;19,80.70,467.45,450.61,9.42;19,80.70,479.41,451.70,9.42;19,80.70,491.36,154.89,9.42">We report the trends of diferent measures (i.e., Acc, IntraFD, IntraFD_approx, InterED, and InterED_approx) when only varying the length of hops or the graph iltering rate using four representative datasets: Undirected Cora, Directed Citeseer, Citeseer Co-citation, and Hete DBLP.</s><s xml:id="_DvhJWYd" coords="19,238.34,491.36,292.97,9.42;19,80.70,503.32,87.56,9.42">All measures (except Acc) are unit normalized to it in the range [0, 1] for a fair comparison.</s><s xml:id="_jJCbNq5" coords="19,170.74,503.32,360.56,9.42;19,80.70,515.27,214.52,9.42">Moreover, same Laplacians, normalizations and parameters are used for the datasets as described in Section 6.3 unless mentioned otherwise.</s><s xml:id="_3VGJ5nN" coords="19,80.70,536.84,184.63,8.92">6.5.1 Sensitivity study on the length of hops.</s><s xml:id="_KpU2Bvr" coords="19,268.81,536.34,262.49,9.42;19,80.70,548.29,450.61,9.42;19,80.70,560.25,47.26,9.42">We irst study the impact of the length of hops while ixing the graph iltering rate () as 0.5 on all datasets, i.e., Undirected Cora, Directed Citeseer, Citeseer Co-citation, and Hete DBLP.</s><s xml:id="_CPNUMgA" coords="19,130.45,560.25,133.47,9.42">The results are given in Figure <ref type="figure" coords="19,257.09,560.25,3.41,9.42" target="#fig_4">4</ref>.</s></p><p xml:id="_QfZ98nZ"><s xml:id="_2TRhfum" coords="19,90.66,572.20,440.90,9.42;19,80.70,584.16,450.60,9.42;19,80.70,596.11,139.99,9.42">From the above igures, one can observe that InterED_approx and InterED decrease exponentially and gradually stabilize at 0, while IntraFD_approx and IntraFD increase rapidly and gradually stabilize at 1 with respect to the increase in the length of hops.</s><s xml:id="_BdNnM3K" coords="19,223.17,596.11,308.12,9.42;19,80.70,608.07,216.72,9.42">This shows that the two approximate metrics are capable of measuring the clustering quality in terms of structure and attribute.</s><s xml:id="_ycvQNZG" coords="19,299.91,608.07,231.62,9.42;19,80.70,620.02,452.14,9.42">Moreover, their trends validate the claim of Theorem 4.1 that graph convolution based GRACE helps the clustering with lower InterED but harms with higher IntraFD.</s><s xml:id="_PMvwRgd" coords="19,80.40,631.98,452.00,9.42;19,80.70,643.93,386.41,9.43">This explains that the clustering performance in terms of Acc irst increases and then drops after the peak, e.g., the decreasing Acc after =10 on Undirected Cora (Figure <ref type="figure" coords="19,325.12,643.93,14.67,9.42" target="#fig_4">4(a)</ref>) and Hete DBLP (Figure <ref type="figure" coords="19,446.09,643.93,14.01,9.42" target="#fig_4">4(d)</ref>).</s><s xml:id="_zmFhFHw" coords="19,469.96,643.93,61.34,9.42;20,80.70,246.61,321.55,9.42">Therefore, it is important to determine a proper length of hops to achieve the best performance.</s><s xml:id="_K9wWyTQ" coords="20,404.74,246.61,126.56,9.42;20,80.70,258.57,282.98,9.42">As such, we will later check the efectiveness of the stopping algorithm used in GRACE in Section 6.6.</s></p><p xml:id="_dW38Wwp"><s xml:id="_6f2AN7W" coords="20,80.70,276.93,17.30,8.92">6.5.2</s><s xml:id="_Kr5h8ge" coords="20,107.96,276.93,167.88,8.92">Sensitivity study on the graph filtering rate.</s><s xml:id="_qzQUhMD" coords="20,279.32,276.43,251.98,9.42;20,80.70,288.39,124.86,9.42">We then investigate the impact of the graph iltering rate while ixing the length of hops as 25.</s><s xml:id="_zdVBRgs" coords="20,208.05,288.39,133.47,9.42">The results are given in Figure <ref type="figure" coords="20,334.69,288.39,3.41,9.42" target="#fig_5">5</ref>.</s><s xml:id="_eRzznYN" coords="20,90.66,447.38,440.90,9.42;20,80.70,459.33,450.60,9.42;20,80.70,471.29,144.20,9.42">The igures on diferent graph types show that InterED_approx and InterED decrease rapidly and gradually stabilize at 0 (except on Hete DBLP), while IntraFD_approx and IntraFD start growing from 0 and inally stabilize as the graph iltering rate increases.</s><s xml:id="_68NYzRQ" coords="20,227.39,471.29,303.92,9.42;20,80.70,483.25,40.06,9.42">As expected, the clustering performance in terms of Acc increases and then decreases.</s><s xml:id="_Aufv8XK" coords="20,123.08,483.25,408.48,9.42;20,80.70,495.20,63.74,9.42">The trends it the analysis in Theorem 4.1 that graph convolution ilters the attributive noise guided by graph structure.</s><s xml:id="_dqUjDEx" coords="20,146.76,495.20,384.55,9.42;20,80.70,507.16,73.09,9.42">The higher graph iltering rate improves the clustering quality in terms of structure but harms in terms of attribute.</s><s xml:id="_8t4AWWb" coords="20,156.28,507.16,375.02,9.42;20,80.70,519.11,452.14,9.42">On Hete DBLP, InterED starts growing and being discrepant from InterED_approx when the graph iltering rate becomes too large, which is caused by over-iltering or over-smoothing the node attributes.</s><s xml:id="_fa2xnYG" coords="20,80.40,531.07,450.90,9.42;20,80.70,543.02,128.88,9.42">Therefore, we set a relatively small graph iltering rate and balance between the IntraFD and InterED measures by adjusting the length of hops.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.6" xml:id="_MVbdxK8">Ablation Study</head><p xml:id="_HA3tMGB"><s xml:id="_ZS6Ze7K" coords="20,80.40,579.81,450.91,9.42;20,80.70,591.77,296.09,9.42">To measure the impact of the stopping algorithm and graph Laplacian selection, we conduct ablation studies on each component following the same experimental settings in Section 6.5.</s><s xml:id="_dQVEzRS" coords="20,80.70,610.13,192.57,8.92">6.6.1 Ablation study on the stopping algorithm.</s><s xml:id="_mad3jbB" coords="20,276.75,609.63,254.55,9.42;20,80.70,621.59,360.36,9.42">To measure the impact of the stopping algorithm, we let graph convolution run for 40 iterations, and report the trends of Acc, NMI, F1, and Compactness.</s><s xml:id="_x7XanCd" coords="20,443.49,621.59,87.81,9.42;20,80.40,633.54,432.97,9.42">We mark the iteration (with a pink line) when the stopping criterion is fulilled, i.e., the compactness of clusters changes very little.</s><s xml:id="_wgeqNdB" coords="20,515.85,633.54,15.45,9.42;20,80.70,645.50,127.57,9.42">The results are reported in Figure <ref type="figure" coords="20,201.44,645.50,3.41,9.42" target="#fig_6">6</ref>.</s><s xml:id="_Qw2wmmN" coords="21,90.66,249.13,415.46,9.42">The igures show that the compactness of the clusters at each iteration indeed decreases exponentially.</s><s xml:id="_Hdc7bK3" coords="21,508.61,249.13,22.70,9.42;21,80.70,261.09,450.60,9.42;21,80.70,273.04,206.89,9.42">It can also be observed that as the compactness is deceasing, Acc, NMI, and F1 are all increasing and then reach the peak as the compactness stabilizes before they drop.</s><s xml:id="_XSH7j2b" coords="21,289.93,273.04,241.38,9.42;21,80.70,285.00,431.78,9.42">Therefore, choosing the stopping criterion at the point when the compactness stabilizes enables us to pick a good balance point for the number of hops or iterations.</s><s xml:id="_v7xGw2R" coords="21,515.23,285.00,16.08,9.42;21,80.70,296.95,450.60,9.42;21,80.70,308.91,379.97,9.42">The igures also validate the efectiveness of our stopping algorithm as the pink lines in the plots (corresponding to the number of hops chosen by our stopping algorithm) are always at the near-best Acc values.</s><s xml:id="_AJ3azwt" coords="21,463.14,308.91,68.15,9.42;21,80.70,320.86,450.86,9.42;21,80.70,332.82,334.14,9.42">In some cases, as the graph iltering rate is set quite small, the performance will maintain after the pink lines, in which the early stopping algorithm helps save the running time by returning good clusters earlier.</s></p><p xml:id="_WAZkx5W"><s xml:id="_fpDfHrE" coords="21,80.70,351.45,17.87,8.92">6.6.2</s><s xml:id="_AP8gVX8" coords="21,108.52,351.45,174.90,8.92">Ablation study on graph Laplacian variants.</s><s xml:id="_AVJDexB" coords="21,286.92,350.95,244.38,9.42;21,80.70,362.91,313.99,9.42">We constructed variants of graph Laplacians to validate the efectiveness of GRACE's graph Laplacians choices on diferent graph types.</s><s xml:id="_Aq56Cwj" coords="21,397.17,362.91,135.23,9.42;21,80.33,374.86,451.57,9.42;21,80.70,386.82,132.68,9.42">The results are given in Figure <ref type="figure" coords="21,525.48,362.91,3.46,9.42" target="#fig_7">7</ref>, where the green curves represent the Acc results of GRACE, and the red curves (and magenta curve in Figure <ref type="figure" coords="21,513.86,374.86,14.43,9.42" target="#fig_7">7(d)</ref>) for the graph Laplacian variants.</s><s xml:id="_cCjpBAk" coords="21,215.87,386.82,262.81,9.42">We used the same alpha values for each dataset as in Section 6.3.</s><s xml:id="_PcbMz2z" coords="21,90.66,549.76,379.04,9.42;21,493.98,549.76,39.00,9.42;21,80.70,561.71,169.49,9.42">On Undirected Cora, we compared the performance of using the symmetric graph Laplacian with selfloops (for GRACE) and without self-loops.</s><s xml:id="_fwMzACd" coords="21,252.66,561.71,278.64,9.42;21,80.70,573.67,183.37,9.42">One can observe from Figure <ref type="figure" coords="21,371.56,561.71,3.70,9.42" target="#fig_7">7</ref>(a) that both graph Laplacians produce comparable clustering results to each other.</s><s xml:id="_34yTxve" coords="21,267.16,573.67,155.95,9.42">Thus, users may decide to use either.</s><s xml:id="_qtPjext" coords="21,426.21,573.67,105.09,9.42;21,80.70,585.62,240.32,9.42;21,337.82,585.62,193.48,9.42;21,100.96,597.58,106.99,9.42">On Directed Citeseer, we compared the symmetric directed graph Laplacian of GRACE to the fast spactral normalized directed Laplacian (with self-loops for both).</s><s xml:id="_hZCS4VA" coords="21,210.92,597.58,320.38,9.42;21,80.70,609.53,434.98,9.42">Figure <ref type="figure" coords="21,240.29,597.58,3.98,9.42" target="#fig_7">7</ref>(b) shows that GRACE's symmetric directed graph Laplacian always outperforms the other and their performance gap increases drastically as the number of hops increases.</s><s xml:id="_BqdWr4c" coords="21,518.66,609.53,12.64,9.42;21,80.70,621.49,276.91,9.42;21,377.56,621.49,153.93,9.42;21,80.70,633.44,90.42,9.42;21,195.22,633.44,2.15,9.42">On Citeseer Co-citation, we constructed the linear hyper-graph Laplacian as a competitor to GRACE's non-linear hyper-graph Laplacian .</s><s xml:id="_uvNxrD4" coords="21,199.48,633.44,331.83,9.42;21,80.70,645.40,450.86,9.42;22,80.70,107.52,148.59,9.42">It is illustrated in Figure <ref type="figure" coords="21,296.18,633.44,3.59,9.42" target="#fig_7">7</ref>(c) that the non-linear hyper-graph Laplacian outperforms the linear one in terms of Acc, and GRACE with sparser non-linear hyper-graph Laplacian is time and memory eicient as shown in Tables <ref type="table" coords="22,197.33,107.52,4.73,9.42" target="#tab_9">9</ref> and<ref type="table" coords="22,222.32,107.52,3.48,9.42" target="#tab_8">8</ref>.</s><s xml:id="_NzuQQdZ" coords="22,231.77,107.52,222.00,9.42;22,473.11,107.52,58.20,9.42;22,80.70,119.47,450.61,10.28;22,80.70,131.43,450.61,10.28;22,85.85,143.38,40.20,10.28">Finally, on ACM, the multi-relational graph Laplacian , GRACE used diferent coeicients for two relation types ( PAP = 0.7 and PSP = 0.3), and we constructed two variants, one that gives a greater weight to PSP ( PAP = 0.3 and PSP = 0.7) and one that gives the same weights ( PAP = 0.5 and PSP = 0.5).</s><s xml:id="_H2e3TUK" coords="22,128.55,143.38,402.75,9.42;22,80.70,155.34,450.61,9.42;22,80.40,167.29,156.06,9.42">The results from Figure <ref type="figure" coords="22,226.01,143.38,3.83,9.42" target="#fig_7">7</ref>(d) show that the performance using the coeicients of GRACE, i.e., giving greater weight to PAP is better than the others, while the performance giving greater weight to PSP is worst (even worse than using same weights).</s><s xml:id="_s6zVz9x" coords="22,238.97,167.29,292.34,9.42;22,80.70,179.25,335.52,9.42">This illustrates the fact that, the multi-relational edges may not have the same importance for clustering (e.g., in this case PAP is more important than PSP).</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.7" xml:id="_776WusP">Case study</head><p xml:id="_HJSURJv"><s xml:id="_zr9eWpY" coords="22,80.22,216.62,451.08,9.42;22,80.70,228.58,30.44,9.42">We notice that the same dataset used in our experiments can be constructed as diferent types of attributed graphs.</s><s xml:id="_mYdvnH3" coords="22,113.87,228.58,417.44,9.42;22,80.70,240.53,316.45,9.42">For example, the Cora citation network can be modelled as an undirected graph (namely Undirected Cora) or hyper-graphs (namely Cora Co-citation and Cora Co-authorship).</s><s xml:id="_3puq4Nn" coords="22,400.54,240.53,130.76,9.42;22,80.70,252.49,224.10,9.42">Prior works usually focus on a speciic type and improve its clustering performance.</s><s xml:id="_hmnyC36" coords="22,307.96,252.49,223.35,9.42;22,80.70,264.44,450.60,9.42;22,80.70,276.40,241.00,9.42">As GRACE can generalize to diferent graph types, it ofers an opportunity to analyze the efects of attributed graph modelling (storing relational information using one graph type over another) under the same framework.</s><s xml:id="_Eqxyddm" coords="22,324.58,276.40,206.72,9.42;22,80.70,288.35,450.79,9.42;22,80.70,300.31,452.14,9.42">From previous results in Section 6.4, one can ind that constructing an undirected graph on Cora can produce better clusters than building the Co-citation or Co-authorship hyper-graphs for GRACE (achieving 16.1% and 11.9% improvements respectively in terms of Acc).</s><s xml:id="_xKxH3ES" coords="22,80.70,312.26,450.61,9.42;22,80.70,324.22,450.60,9.42;22,80.70,336.17,212.46,9.42">It infers that Co-citation and Co-authorship hyper-relations are less useful for clustering citation networks as one paper (Co-citation hyper-edge) can include references from diferent domains and one author (Co-authorship hyper-edge) can publish papers on diferent topics.</s><s xml:id="_aqfpJ3T" coords="22,295.97,336.17,235.34,9.42;22,80.70,348.13,229.03,9.42">This indeed shows that attributed graph modelling itself could be a relevant problem worth further investigation.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7" xml:id="_9aH7y42">RELATED WORK</head><p xml:id="_SpGvCYP"><s xml:id="_Pvvcg7k" coords="22,80.70,385.51,451.70,9.42;22,80.70,397.46,98.74,9.42">For AGC, there are two main approaches; (1) methods that do not combine graph structure and node attributes, and (2) methods that do.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1" xml:id="_txA5H9f">Methods that do not combine graph structure and node atributes</head><p xml:id="_2UX2gXT"><s xml:id="_9uRgKne" coords="22,80.70,434.84,450.85,9.42;22,80.70,446.79,450.61,9.42;22,80.70,458.75,450.61,9.42;22,80.70,470.70,34.16,9.42">Initially designed for undirected graphs, K-Means <ref type="bibr" coords="22,287.15,434.84,14.93,9.42" target="#b44">[45]</ref>, Kernel K-Means <ref type="bibr" coords="22,376.96,434.84,16.45,9.42" target="#b13">[14]</ref> Symmetric-Non-Negative Matrix Factorization (Symm-NMF) <ref type="bibr" coords="22,192.18,446.79,14.70,9.42" target="#b29">[30]</ref>, and Graph-regularised-Non-Negative Matrix Factorization (GNMF) <ref type="bibr" coords="22,483.84,446.79,11.60,9.42" target="#b5">[6]</ref> all focus on the node attributes only and seek to group nodes with similar node attributes in the same cluster by minimizing IntraFD.</s><s xml:id="_UVf78Ms" coords="22,117.69,470.70,413.62,9.42;22,80.70,482.66,450.61,9.42;22,80.70,494.61,232.62,9.42">Two key mentions here are (a) Symm-NMF can focus either on the node attributes or on the graph structure only, but not both; and (b) we classify GNMF in this category because the Laplacian it uses is built from the node attributes rather than from the graph structure.</s><s xml:id="_Rp2H2qa" coords="22,315.82,494.61,215.48,9.42;22,80.70,506.57,217.28,9.42">All these methods can be used on all types of graphs since they do not care about the the graph structure.</s><s xml:id="_7E6CyDx" coords="22,300.49,506.57,230.82,9.42;22,80.70,518.52,450.60,9.42;22,80.70,530.48,145.86,9.42">A classical method that only focuses on graph structure for undirected graphs is the well known Normalized-cut (N-cut) <ref type="bibr" coords="22,351.50,518.52,15.12,9.42" target="#b41">[42,</ref><ref type="bibr" coords="22,369.49,518.52,11.34,9.42" target="#b73">74]</ref>, which seeks to group nodes in the same cluster by minimizing InterED.</s><s xml:id="_6xFEb3X" coords="22,229.02,530.48,205.82,9.42;22,434.84,528.77,3.38,6.88;22,438.72,530.48,92.59,9.42;22,80.70,542.43,122.87,9.42">N-cut has been extended to directed graphs <ref type="bibr" coords="22,404.75,530.48,14.89,9.42" target="#b45">[46,</ref><ref type="bibr" coords="22,422.10,530.48,12.74,9.42" target="#b54">55]</ref>  <ref type="foot" coords="22,434.84,528.77,3.38,6.88" target="#foot_5">5</ref> , heterogeneous graphs <ref type="bibr" coords="22,80.70,542.43,15.00,9.42" target="#b38">[39,</ref><ref type="bibr" coords="22,98.19,542.43,12.81,9.42" target="#b55">56]</ref> and hypergraphs <ref type="bibr" coords="22,185.02,542.43,14.84,9.42" target="#b84">[85]</ref>.</s></p><p xml:id="_E9bHySj"><s xml:id="_Bj4YWre" coords="22,90.66,554.39,440.64,9.42;22,80.70,566.34,450.60,9.42;22,80.70,578.30,405.79,9.42">In this category, speciic to undirected graphs only, we also have node representation learning methods such as Deepwalk <ref type="bibr" coords="22,158.56,566.34,16.50,9.42" target="#b49">[50]</ref> and Node2vec <ref type="bibr" coords="22,239.45,566.34,14.99,9.42" target="#b19">[20]</ref>, which learn node embeddings from the graph structure and feed these embeddings into the traditional clustering algorithms (such as K-Means) to learn the clusters.</s><s xml:id="_yKGNC5G" coords="22,488.96,578.30,42.34,9.42;22,80.70,590.25,450.61,9.42;22,80.70,602.21,450.60,9.42;22,80.40,614.16,450.90,9.42;22,80.33,626.12,259.88,9.42">Speciic to hypergraphs, we have methods that only focus on the hypergraph structure such as the PageRank based algorithm by <ref type="bibr" coords="22,93.15,602.21,16.31,9.42" target="#b62">[63]</ref> (which extended the work of <ref type="bibr" coords="22,230.62,602.21,11.67,9.42" target="#b2">[3]</ref> to hypergraphs), Inhomogeneous hypergraph partitioning method <ref type="bibr" coords="22,515.00,602.21,16.30,9.42" target="#b36">[37]</ref> (which assigns diferent costs to diferent hyperedge cuts), and Eicient Hypergraph Clustering <ref type="bibr" coords="22,471.48,614.16,16.37,9.42" target="#b32">[33]</ref> (a method which updates the cluster membership of all points in parallel).</s><s xml:id="_z4Rvxaz" coords="22,342.70,626.12,188.60,9.42;23,80.70,107.52,450.87,9.42;23,80.70,119.47,450.60,9.42;23,80.70,131.43,450.60,9.42;23,80.70,143.38,452.14,9.42">Finally, speciic to heterogeneous networks in this category we have RankClus <ref type="bibr" coords="23,217.89,107.52,16.50,9.42" target="#b59">[60]</ref> which focuses on bi-typed heterogeneous networks by simultaneously addressing ranking and clustering on heterogenous graphs, NetClus <ref type="bibr" coords="23,353.00,119.47,16.22,9.42" target="#b61">[62]</ref> which extends RanClus to heterogenous graphs with more than two types of nodes, SI-Cluster <ref type="bibr" coords="23,302.25,131.43,16.40,9.42" target="#b90">[91]</ref> which introduces a vertex based similarity measure and proposes an algorithm to iteratively reine the clusters based on this measure, and NMF based methods <ref type="bibr" coords="23,514.40,143.38,14.75,9.42" target="#b50">[51]</ref>.</s></p><p xml:id="_SmbwvDC"><s xml:id="_vqePKNU" coords="23,90.66,155.34,196.33,9.42">There are two main drawbacks to these methods.</s><s xml:id="_tWPS9rF" coords="23,289.49,155.34,241.81,9.42;23,80.70,167.29,450.60,9.42;23,80.70,179.25,377.76,9.42">First, the two sources of information, i.e., the node attributes and the graph structure, do not always contain exactly the same information, but rather are complementary to each other (as seen in Section 6, the results of K-Means are always diferent to those of N-cut).</s><s xml:id="_U5SgMp3" coords="23,460.94,179.25,70.36,9.42;23,80.70,191.20,450.79,9.42;23,80.40,203.16,106.99,9.42">As such, focusing on one source of information only (e.g., graph structure) will neglect the information contained in the other (e.g., the node attributes).</s><s xml:id="_6hVu6aZ" coords="23,190.50,203.16,340.80,9.42;23,80.70,215.11,325.85,9.42">Moreover, once clusters are obtained independently from the diferent sources of information, it is not clear how to combine them both, nor which one to choose.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2" xml:id="_kp93RpV">Methods that combine graph structure and node atributes</head><p xml:id="_eBhcN4K"><s xml:id="_g4UTBX4" coords="23,80.35,259.19,450.95,9.42;23,80.70,271.15,450.61,9.42;23,80.70,283.10,48.25,9.42">AGC methods that combine graph structure and node attributes can be categorized into four approaches: hybrid distance-based, probabilistic model-based, nonnegative matrix factorization (NMF)-based, and node embedding-based approaches.</s></p><p xml:id="_4ydP4z9"><s xml:id="_H7PKvgC" coords="23,90.66,295.06,440.64,9.42;23,80.70,307.01,50.55,9.42">Hybrid distance-based methods design a uniied distance that combines node attributes and graph structure information.</s><s xml:id="_Ahb88Cj" coords="23,133.72,307.01,397.58,9.42;23,80.70,318.97,130.59,9.42">For example, the linear combination of attributive distance (e.g., euclidean distance) and structural distance (e.g., the shortest path).</s><s xml:id="_435r6u2" coords="23,213.78,318.97,317.52,9.42;23,80.70,330.92,450.61,9.42;23,80.70,342.88,451.70,9.42;23,80.70,354.83,181.28,9.42">Based on the hybrid distance, there are two ways to perform clustering: (1) we can directly apply distance-based clustering algorithms (e.g., K-Medoids or K-Means <ref type="bibr" coords="23,426.40,330.92,14.48,9.42" target="#b43">[44]</ref>); <ref type="bibr" coords="23,450.61,330.92,10.61,9.42" target="#b1">(2)</ref> or we can utilize the hybrid distance information to construct a new graph (e.g., a K-NN graph <ref type="bibr" coords="23,393.57,342.88,16.26,9.42" target="#b11">[12]</ref> or edge-weighted graph <ref type="bibr" coords="23,511.04,342.88,14.24,9.42" target="#b47">[48]</ref>), and then apply graph clustering algorithms.</s><s xml:id="_ZCUbPGG" coords="23,264.47,354.83,266.83,9.42;23,80.70,366.79,450.60,9.42;23,80.70,378.74,336.04,9.42">This category cannot easily be extended to other types of graphs because the explicit structural distance measures are usually designed for a speciic graph type, and to extend it to another graph type one will need to redeine the structural distance measure.</s><s xml:id="_nkb9Q9m" coords="23,419.22,378.74,112.08,9.42;23,80.70,390.70,450.61,9.42;23,80.70,402.65,450.61,9.42;23,80.70,414.61,127.39,9.42">For example, on undirected graphs, in SA-Cluster <ref type="bibr" coords="23,171.64,390.70,16.47,9.42" target="#b88">[89]</ref> and its extended versions <ref type="bibr" coords="23,297.50,390.70,15.09,9.42" target="#b9">[10,</ref><ref type="bibr" coords="23,315.08,390.70,11.32,9.42" target="#b89">90]</ref>, the uniied neighborhood random walk distance is computed on a node-augmented graph with new attributive nodes and edges, and the K-Medoids algorithm is then applied to ind clusters.</s><s xml:id="_WC5CtXb" coords="23,210.64,414.61,320.67,9.42;23,80.70,426.56,452.14,9.42">This new augmented graph is built on the assumption that the original graph structure was an undirected graph and it is not obvious how to build it on heterogeneous graphs or hypergraphs.</s><s xml:id="_m4r69dZ" coords="23,80.35,438.52,389.44,9.42">Another example is the distance based state-of-the-art SpectralMix <ref type="bibr" coords="23,348.61,438.52,16.21,9.42" target="#b52">[53]</ref> on heterogeneous graphs.</s><s xml:id="_tK5xbPN" coords="23,472.15,438.52,59.16,9.42;23,80.70,450.47,450.60,9.42;23,80.47,462.43,451.02,9.42;23,80.70,474.38,450.60,9.42;23,80.70,486.34,452.14,9.42">It can easily be reduced to work on undirected graphs, by setting the number of multi-relational graph adjacency matrices to 1 and using the undirected graph adjacency as the multi-relational graph adjacency matrix, but it is not clear how to extend it to hypergraphs, since in hypergraphs each edge can contain much more than a single node, but the structural distance used in SpectralMix' joint objective only accommodates simple edges linking two nodes.</s><s xml:id="_fqANDjc" coords="23,80.70,498.29,450.61,9.42;23,80.70,510.25,408.28,9.42">On heterogeneous graphs, MvAGC <ref type="bibr" coords="23,225.16,498.29,16.36,9.42" target="#b39">[40]</ref> denoises the graph signals (node attributes) and then proposes a graph learning algorithm to learn node similarities and uses the resulting similarity graph for clustering.</s><s xml:id="_59n3fUV" coords="23,491.64,510.25,39.66,9.42;23,80.70,522.20,450.86,9.42;23,80.70,534.16,236.47,9.42">The main diference between MvAGC and GRACE is that in MvAGC, the convolution (denoising) module is not directly connected to the graph learning and clustering modules.</s><s xml:id="_d2by7Rw" coords="23,320.03,534.16,211.27,9.42;23,80.70,546.11,450.61,9.42;23,80.70,558.07,246.70,9.42">Thus, although MvAGC presents a novel approach to clustering, i.e., denoising and learning similarities and then clustering, their work is not directed towards understanding the efects of graph convolution for clustering.</s><s xml:id="_TgvuEVK" coords="23,329.91,558.07,201.40,9.42;23,80.70,570.02,450.61,9.42;23,80.70,581.98,450.79,9.42;23,81.20,593.98,121.62,9.51">One of the limitations of MvAGC is that the graph iltering phase, which is shown to be essential for clustering in our work, is only treated as a prepossessing phase, and hence it is diicult to see why the optimal as the power for their ilter is 3 (i.e., = 3 for the ilter (1 -0.5) ) as they observed.</s><s xml:id="_vdfV8Vu" coords="23,205.30,594.07,326.01,9.42;23,80.70,606.03,450.60,9.42;23,80.70,617.98,258.08,9.42">In addition, it is also non-trivial to generalize MvAGC to hyper-graphs because even if we use the de-noising (convolution) step of GRACE to prepossess the hyper-node embedding, it is still non-trivial to adapt the graph learning phase to hyper-graphs.</s><s xml:id="_XtGWqyX" coords="23,341.27,617.98,190.04,9.42;23,80.70,629.94,450.80,9.42;23,80.70,641.89,377.49,9.42">Moreover, their multi-view learning approach difers from that of GRACE in that GRACE uses a combined laplacian for iltering, while they propose to ilter individually and then use a weighted sum with learned weights to learn the similarity graph.</s></p><p xml:id="_KhE3trT"><s xml:id="_EDrMbCa" coords="24,90.66,107.52,441.74,9.42;24,80.70,119.47,309.98,9.42">Probabilistic model-based methods consider both node attributes and graph structure as probabilistic variables, and model the community memberships of each node as latent variables.</s><s xml:id="_4J9dk3e" coords="24,394.03,119.47,137.28,9.42;24,80.70,131.43,346.01,9.42">From this view, attributed graph clustering can be transformed into a community membership estimation problem.</s><s xml:id="_VDwEDP3" coords="24,429.93,131.43,101.37,9.42;24,80.70,143.38,450.60,9.42;24,80.40,155.34,450.90,9.42;24,80.70,167.20,450.61,9.51;24,80.70,179.16,450.61,9.51;24,80.70,191.11,230.03,9.51">There are three ways to model the statistical relationships among node attributes (X), graph structure (G) and community memberships (F): (1) node attributes generate community memberships and then community memberships generate graph structure (i.e., → → ), such as <ref type="bibr" coords="24,232.29,167.29,15.12,9.42" target="#b82">[83]</ref>; (2) node attributes and community memberships together generate graph structure (i.e., → ← ), such as <ref type="bibr" coords="24,255.65,179.25,14.90,9.42" target="#b46">[47]</ref>; (3) community memberships generate both node attributes and graph structure (i.e., ← → ), such as <ref type="bibr" coords="24,263.39,191.20,15.12,9.42" target="#b77">[78,</ref><ref type="bibr" coords="24,281.31,191.20,11.50,9.42" target="#b78">79,</ref><ref type="bibr" coords="24,295.61,191.20,11.34,9.42" target="#b81">82]</ref>.</s><s xml:id="_eXeQpzj" coords="24,313.53,191.20,217.77,9.42;24,80.70,203.16,451.70,9.42;24,80.33,215.11,212.30,9.42">The generative process in the model, though having intuitive explanations, requires speciic decisions about statistical interactions and underlying distributions, where wrong decisions lead to highly biased models.</s><s xml:id="_tT6nvSt" coords="24,295.12,215.11,236.18,9.42;24,80.70,227.07,209.92,9.42">Like hybrid distance-based methods, probabilistic methods are equally hard to extend to other types of graphs.</s><s xml:id="_udxwBBt" coords="24,293.11,227.07,238.19,9.42;24,80.70,239.02,450.60,9.42;24,80.70,250.98,450.61,9.42;24,80.70,262.93,450.61,9.42;24,80.70,274.89,62.07,9.42">For example, on undirected, directed and hypergraphs, we have the Popularity Conditional Link and Direct Content Model (PCL-DC) <ref type="bibr" coords="24,381.73,239.02,16.26,9.42" target="#b82">[83]</ref> which cannot be easily extended to heterogeneous graphs since it uses the content probability to estimate the probability of a node being connected to another without taking into account the type of link (i.e., it is designed to work only when there is one type of edge relations).</s></p><p xml:id="_dm5c9JB"><s xml:id="_EebgBTG" coords="24,90.66,286.84,440.64,9.42;24,80.70,298.80,189.53,9.42">Nonnegative matrix-based methods introduce a nonnegative assignment matrix that associates each node with the strength of its belonging to each community.</s><s xml:id="_pUryctM" coords="24,272.04,298.80,259.27,9.42;24,80.70,310.75,450.60,9.42;24,80.40,322.71,46.37,9.42">In contrast to probabilistic model-based methods, the nonnegative assignment matrix is not regarded as a random variable but can be obtained by nonnegative matrix factorization (NMF) <ref type="bibr" coords="24,108.40,322.71,14.69,9.42" target="#b31">[32]</ref>.</s><s xml:id="_rZVc6GK" coords="24,129.20,322.71,402.10,9.42;24,80.70,334.67,433.61,9.42">NMF aims to ind two nonnegative low-rank matrices whose product provides a good approximation to the original one, and their nonnegativity ofers the interpretability for document co-clustering <ref type="bibr" coords="24,495.56,334.67,14.99,9.42" target="#b75">[76]</ref>.</s><s xml:id="_9EyrFVU" coords="24,517.66,334.67,13.83,9.42;24,80.70,346.62,450.60,9.42;24,80.70,358.58,450.61,9.42;24,80.70,370.53,328.96,9.42">For undirected graphs, one can extend GNMF <ref type="bibr" coords="24,249.49,346.62,11.59,9.42" target="#b6">[7]</ref> to combine both node attributes and graph structure, by modifying the Laplacian regularizer it uses to the Laplacian built from the graph structure (rather than that built from the manifold graph constructed from the node attributes as in their original paper).</s><s xml:id="_fWYFmEv" coords="24,412.22,370.53,119.09,9.42;24,80.70,382.49,450.61,9.42;24,80.70,394.44,357.69,9.42">Following this idea, diferent objectives that fuse both node attributes and graph structure information have been proposed on undirected graphs <ref type="bibr" coords="24,110.08,394.44,14.89,9.42" target="#b20">[21,</ref><ref type="bibr" coords="24,127.26,394.44,11.41,9.42" target="#b24">25,</ref><ref type="bibr" coords="24,140.96,394.44,11.17,9.42" target="#b68">69]</ref>, and recently eforts have been made to extend to hypergraphs <ref type="bibr" coords="24,406.33,394.44,14.89,9.42" target="#b16">[17,</ref><ref type="bibr" coords="24,423.50,394.44,11.17,9.42" target="#b70">71]</ref>.</s><s xml:id="_mYSQ47y" coords="24,440.68,394.44,90.62,9.42;24,80.70,406.40,392.82,9.42">In spite of these eforts to extend to other types of graphs, we remain unaware of any attempt on heterogeneous graphs.</s></p><p xml:id="_jSMQEkA"><s xml:id="_Vd3YcNy" coords="24,90.66,418.35,440.64,9.42;24,80.70,430.31,450.60,9.42;24,80.70,442.26,50.08,9.42">Node embedding-based methods aim to learn a vector representation of each node in an attributed graph, and then the traditional clustering methods, such as K-Means, are applied to ind clusters based on the learned node embeddings.</s><s xml:id="_mVJTzp7" coords="24,132.84,442.26,398.46,9.42;24,80.70,454.22,104.24,9.42">Techniques to generate node embeddings include dimensionality reduction <ref type="bibr" coords="24,431.41,442.26,10.30,9.42" target="#b4">[5]</ref>, random walk <ref type="bibr" coords="24,501.61,442.26,14.89,9.42" target="#b19">[20,</ref><ref type="bibr" coords="24,518.56,442.26,12.74,9.42" target="#b49">50]</ref> and neural networks <ref type="bibr" coords="24,166.48,454.22,14.77,9.42" target="#b67">[68]</ref>.</s><s xml:id="_VkB6Xpb" coords="24,187.42,454.22,331.16,9.42">However, these early works of node embedding only consider the graph structure.</s><s xml:id="_GPHT8Na" coords="24,521.07,454.22,10.23,9.42;24,80.70,466.17,450.61,9.42;24,80.70,478.13,224.96,9.42">To learn node embeddings that incorporate node attributes information, a common practice is to simply concatenate the learned structural embeddings and node attributes.</s><s xml:id="_Fc7NDdr" coords="24,308.15,478.13,223.15,9.42;24,80.70,490.08,147.49,9.42">In addition, random walk-based methods are extended to attributed graphs such as <ref type="bibr" coords="24,199.81,490.08,10.49,9.42" target="#b1">[2,</ref><ref type="bibr" coords="24,213.07,490.08,11.34,9.42" target="#b80">81]</ref>.</s><s xml:id="_y7uNnHN" coords="24,230.95,490.08,300.36,9.42;24,80.70,502.04,402.86,9.42">In recent years, graph neural networks <ref type="bibr" coords="24,395.94,490.08,15.12,9.42" target="#b72">[73,</ref><ref type="bibr" coords="24,413.83,490.08,12.88,9.42" target="#b86">87]</ref> have been demonstrated to efectively capture both node attributes and graph structure information into node embeddings.</s><s xml:id="_A2zfCPf" coords="24,486.04,502.04,45.25,9.42;24,80.70,513.99,451.70,9.42;24,80.70,525.95,450.61,9.42;24,80.70,537.90,378.53,9.42;24,459.23,536.19,3.38,6.88;24,463.11,537.90,2.15,9.42">Though on undirected graphs various such methods have been proposed and used for clustering <ref type="bibr" coords="24,430.26,513.99,102.14,9.42;24,80.70,525.95,56.46,9.42">[13, 24, 28, 29, 49, 59, 65ś 67, 72, 75, 84]</ref>, particularly related to our work and model GRACE are the graph convolution based based models <ref type="bibr" coords="24,111.24,537.90,14.89,9.42" target="#b27">[28,</ref><ref type="bibr" coords="24,128.28,537.90,11.41,9.42" target="#b28">29,</ref><ref type="bibr" coords="24,141.84,537.90,12.74,9.42" target="#b83">84]</ref> which have been shown to achieve the state-of-the-art-results for Undi-AGC <ref type="foot" coords="24,459.23,536.19,3.38,6.88" target="#foot_6">6</ref> .</s><s xml:id="_knZBPRw" coords="24,467.41,537.90,63.89,9.42;24,80.70,549.86,451.70,9.42;24,80.70,561.81,386.82,9.42">Recently, eforts have also been made to extend graph neural networks to other types of graphs such as directed graphs <ref type="bibr" coords="24,499.93,549.86,14.99,9.42" target="#b34">[35,</ref><ref type="bibr" coords="24,517.41,549.86,11.24,9.42" target="#b42">43]</ref>, hypergraphs <ref type="bibr" coords="24,136.59,561.81,10.49,9.42" target="#b3">[4,</ref><ref type="bibr" coords="24,150.39,561.81,11.50,9.42" target="#b18">19,</ref><ref type="bibr" coords="24,165.20,561.81,11.34,9.42" target="#b79">80]</ref>, and more recently heteorgeneous graphs <ref type="bibr" coords="24,359.90,561.81,15.11,9.42" target="#b17">[18,</ref><ref type="bibr" coords="24,378.33,561.81,11.50,9.42" target="#b21">22,</ref><ref type="bibr" coords="24,393.14,561.81,11.50,9.42" target="#b22">23,</ref><ref type="bibr" coords="24,407.96,561.81,11.50,9.42" target="#b35">36,</ref><ref type="bibr" coords="24,422.77,561.81,11.50,9.42" target="#b40">41,</ref><ref type="bibr" coords="24,437.59,561.81,11.50,9.42" target="#b56">57,</ref><ref type="bibr" coords="24,452.40,561.81,11.34,9.42" target="#b69">70]</ref>.</s><s xml:id="_MrdHqN2" coords="24,470.84,561.81,60.46,9.42;24,80.70,573.77,377.11,9.42">Amongst such extensions to heterogeneous graphs, we have GraphRec <ref type="bibr" coords="24,318.56,573.77,14.99,9.42" target="#b17">[18]</ref>, KCGN <ref type="bibr" coords="24,370.31,573.77,14.98,9.42" target="#b22">[23]</ref>, and FesoG <ref type="bibr" coords="24,439.08,573.77,14.99,9.42" target="#b40">[41]</ref>.</s><s xml:id="_PDtd5UZ" coords="24,460.89,573.77,70.42,9.42;24,80.70,585.72,248.03,9.42">GraphRec <ref type="bibr" coords="24,505.01,573.77,16.50,9.42" target="#b17">[18]</ref> is an attention network proposed for social recommendation.</s><s xml:id="_cPGSyRM" coords="24,331.88,585.72,200.52,9.42;24,80.70,597.68,450.61,9.42;24,80.70,609.63,450.79,9.42;24,80.70,621.59,320.07,9.42">Given a user-user graph and a user-item graph, GraphRec learns user embedding (as a combination of the user embedding from the user-user graph and the user embedding from the user-item graph), as well as item embedding, and inally combine the learned user embedding and item embedding to obtain a user rating prediction for an item.</s><s xml:id="_kfg9YWR" coords="24,403.27,621.59,128.03,9.42;25,80.70,107.52,450.61,9.42;25,80.70,119.47,80.13,9.42">Although GraphRec focuses on social recommendation, one could use the combined user embedding for user clustering or the item embedding for item clustering.</s><s xml:id="_rUE3uQU" coords="25,163.85,119.47,367.45,9.42;25,80.70,131.43,450.61,9.42;25,80.70,143.38,450.61,9.42;25,80.70,155.34,81.77,9.42">Compared with GRACE, it is non-trivial to generalize GraphRec to graph-types such as hypergraphs or multi-relational graphs, because in this case one would need to completely redesign the message passing scheme of GraphRec to adapt to multiple nodes in a single edge or message passing across diferent adjacency matrices.</s><s xml:id="_P6J6Dfn" coords="25,165.56,155.34,366.00,9.42;25,80.70,167.29,450.61,9.42;25,80.70,179.25,294.07,9.42">Moreover, it is also diicult to analyze what the efects of GraphRec on clustering may be (e.g., why and how it achieves a certain efect on the intra-cluster feature distance or inter-cluster edge density), even when it is paired with a suitable clustering loss function.</s><s xml:id="_cwKMsFs" coords="25,377.25,179.25,154.05,9.42;25,80.70,191.20,450.61,9.42;25,80.33,203.16,78.48,9.42">This is because it is not clear how we may incorporate GraphRec's message passing scheme in the analysis even if we follow a similar approach as we do in our paper.</s><s xml:id="_2xHsEYm" coords="25,161.30,203.16,370.00,9.42;25,80.70,215.11,450.61,9.42;25,80.70,227.07,186.95,9.42">FeSoG <ref type="bibr" coords="25,189.68,203.16,16.33,9.42" target="#b40">[41]</ref> proposes to employ federated learning to address the privacy concerns in social recommendation based on the fact that most graph neural networks for this task require a centralized storage of the social links and item interactions of users.</s><s xml:id="_yZ3xXUr" coords="25,270.14,227.07,261.15,9.42;25,80.70,239.02,450.61,9.42;25,80.70,250.98,246.05,9.42">The attention based graph neural network proposed in FeSoG is similar to GraphRec (discussed above), since FesoG is an attention network with a similar procedure to learn the embedding (besides the federated learning it employs).</s><s xml:id="_8T8rjC5" coords="25,329.77,250.98,201.53,9.42;25,80.70,262.93,136.38,9.42">Therefore, FeSoG shares the same limitations as GraphRec compared with GRACE.</s><s xml:id="_yMh8GTV" coords="25,219.30,262.93,312.01,9.42;25,80.70,274.89,450.60,9.42;25,80.40,286.84,196.15,9.42">KCGN <ref type="bibr" coords="25,247.31,262.93,16.22,9.42" target="#b22">[23]</ref> addresses issues that most social recommendation neural networks do not handle, i.e., <ref type="bibr" coords="25,157.18,274.89,10.53,9.42" target="#b0">(1)</ref> the interaction between items, (2) the presence of multi-typed user item interactions, and (3) the dynamic nature of user-item interactions.</s><s xml:id="_PwJHneS" coords="25,279.03,286.84,252.28,9.42;25,80.70,298.80,451.70,9.42;25,80.70,310.75,450.61,9.42;25,80.70,322.71,450.61,9.42;25,80.70,334.67,56.27,9.42">To address these issues, KCGN designs a new message passing framework and a new loss function that incorporate (a) multi-typed dynamic user-item interaction encoding, and (b) knowledge-aware user-user and item-item inter-dependent relations, where (a) captures the dynamic relationship between user and items and (b) captures the local relationship among users and the local relationship among items.</s><s xml:id="_kz5WBNJ" coords="25,140.11,334.67,391.19,9.42;25,80.70,346.62,348.59,9.42">KGCN uses a message passing framework to fuse user-item interactions and a graph leaning framework to fuse user-user interactions and item-item interactions in a coupled way.</s><s xml:id="_8ZTFrRG" coords="25,431.77,346.62,99.53,9.42;25,80.70,358.58,450.61,9.42;25,80.70,370.53,380.96,9.42">In contrast, GRACE uses graph convolution to fuse both user-user interactions and user-item (user-attributes in our case) interactions and then capture the interdependence in both by building the similarity matrix for clustering.</s><s xml:id="_3qBqKew" coords="25,464.14,370.53,67.15,9.42;25,80.70,382.49,450.61,9.42;25,80.70,394.44,450.61,9.42;25,80.70,406.40,452.13,9.42">An advantage of GRACE has over KCGN (and the previous discussed models as well) for the clustering task is that, as discussed in Sections 4 and 6, we show the direct efects of graph convolution on the fundamental measures of clustering and can thus use graph convolution to directly guide the clustering, in addition to the fact that no training is needed.</s><s xml:id="_We9caBZ" coords="25,80.70,418.35,450.61,9.42;25,80.70,430.31,450.60,9.42;25,80.70,442.26,64.22,9.42">Moreover, GRACE is easily generalized to diferent graph types so long as we have a well deined laplacian and a suitable low-pass ilter, which is not the case for KCGN as it is hard to extend KCGN to another graph type such as hypergraphs.</s><s xml:id="_nRFYnQj" coords="25,147.40,442.26,384.99,9.42;25,80.33,454.22,304.02,9.42">However, KCGN incorporates the dynamic nature of user-item interactions in their framework, which is an interesting direction to consider for GRACE as its future work.</s></p><p xml:id="_6uGrUd5"><s xml:id="_YYE23Kk" coords="25,90.66,466.17,440.65,9.42;25,80.70,478.13,450.61,9.42;25,80.70,490.08,450.61,9.42;25,80.70,502.04,450.61,9.42;25,80.70,513.99,126.35,9.42">Some major laws of these models are: (1) some of these models as noted are proposed speciically for speciic types of graphs and cannot be easily extended to other types, (2) Some of the state-of-the-art methods on each type of graphs (e.g., SpectralMix on heterogeneous graphs) are extremely time costly to run, (3) no study exists on how such a general method afects clustering on the diferent types of graphs and no performance nor analysis guarantees have been provided.</s><s xml:id="_eY7JKCE" coords="25,209.52,513.99,321.78,9.42;25,80.40,525.95,450.90,9.42;25,80.70,537.90,23.77,9.42">As a result of these drawbacks, the beneits of diferent types of graph structures (undirected, directed, hyper, heterogeneous, etc.) used to store information have never been compared with each other.</s><s xml:id="_fKDjFhP" coords="25,107.25,537.90,424.06,9.42;25,80.70,549.86,450.61,9.42;25,80.70,561.81,450.60,9.42;25,80.70,573.77,315.37,9.42">Thus, our aim in this work has been to address these challenges by <ref type="bibr" coords="25,390.17,537.90,10.78,9.42" target="#b0">(1)</ref> proposing an easy and general convolution framework for clustering on all types of graphs<ref type="foot" coords="25,317.24,548.15,3.38,6.88" target="#foot_7">7</ref> , (2) proposing a convolution model GRACE based on the framework which is both fast and memory eicient, and (3) providing theoretical and experimental analysis and guaranties of our model and framework in general on all types of graphs.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3" xml:id="_se4TexM">Diferences between GRACE and GRAC</head><p xml:id="_qV9HgBu"><s xml:id="_9r8YHrV" coords="25,80.35,611.58,425.08,9.42">A preliminary work of this paper is GRAC <ref type="bibr" coords="25,252.08,611.58,14.70,9.42" target="#b26">[27]</ref>, as GRACE can be considered as a generalization of GRAC.</s><s xml:id="_PuXt5XN" coords="25,507.92,611.58,23.39,9.42;25,80.70,623.54,232.32,9.42">There are however key diferences between GRACE and GRAC.</s></p><p xml:id="_ZUJV6BJ"><s xml:id="_N3ZsM8e" coords="26,90.66,107.52,440.64,9.42;26,80.70,119.47,248.24,9.42">First, GRACE is a framework for handling AGC on diferent types of attributed graphs with diferent types of edges, while GRAC was tailored speciically for hypergraphs.</s><s xml:id="_QA2apXK" coords="26,331.44,119.47,199.87,9.42;26,80.70,131.43,218.04,9.42">To achieve this, we use the convolution proposed by GRAC and propose GRACE as a general framework.</s><s xml:id="_9BTDZnV" coords="26,300.94,131.43,230.37,9.42;26,80.70,143.38,450.60,9.42;26,80.70,155.34,101.91,9.42">We make use diferent ilters for GRACE for each diferent type of graphs in order to address the diferent challenges imposed by diferent types of relations (edges) on the diferent types of graphs.</s></p><p xml:id="_vBTqCsh"><s xml:id="_CjrdkMP" coords="26,90.66,167.29,440.64,9.42;26,80.70,179.25,185.10,9.42">Second, We provide theoretical guarantees for the efects of GRACE on AGC by following GRAC in analyzing the efects of the graph convolution on AGC.</s><s xml:id="_v2zDsxn" coords="26,268.28,179.25,149.82,9.42">We modify the analysis from GRAC.</s><s xml:id="_MmexJS8" coords="26,420.58,179.25,110.71,9.42;26,80.70,191.20,155.47,9.42">Speciically, we modify the efects of the convolution on IntraFD.</s><s xml:id="_68QDj4R" coords="26,238.73,191.20,292.57,9.42;26,80.70,203.16,104.28,9.42">This can be seen by the fact that Equation <ref type="bibr" coords="26,415.64,191.20,15.51,9.42" target="#b10">(11)</ref> in this work is diferent from Equation ( <ref type="formula" coords="26,146.07,203.16,3.56,9.42" target="#formula_10">9</ref>) in <ref type="bibr" coords="26,166.34,203.16,14.91,9.42" target="#b26">[27]</ref>.</s><s xml:id="_aBarHCK" coords="26,187.46,203.16,343.84,9.42;26,97.45,215.02,319.86,9.51">This leads to the more precise conclusion that when is suiciently small such that ≤ 1 for all , then IntraFD is expected to increase exponentially as increases.</s><s xml:id="_YK8TF2t" coords="26,419.80,215.11,111.50,9.42;26,80.70,226.98,317.06,9.51;26,413.47,226.98,25.61,9.16;26,455.72,226.98,76.67,9.51;26,80.70,239.02,452.14,9.42">Otherwise, it may decrease exponentially (or increase more rapidly) with depending on the products (1 -) (1 -) in Equation ( <ref type="formula" coords="26,518.76,227.07,6.82,9.42" target="#formula_14">11</ref>), since IntraFD is assumed to follow the same trend with IntraFD_approx (as also shown in the experiments).</s><s xml:id="_Y324dqJ" coords="26,80.22,250.98,451.08,9.42;26,80.70,262.93,239.58,9.42">We also provide detailed time complexity analysis for GRACE on each type of graphs used, and modify the complexity provided in <ref type="bibr" coords="26,177.47,262.93,16.36,9.42" target="#b26">[27]</ref> with sparse matrix operations.</s></p><p xml:id="_W8WAsPm"><s xml:id="_W9FcCb2" coords="26,90.66,274.89,440.64,9.42;26,80.70,286.84,280.62,9.42">Third, we conducted extensive experiments on 14 diferent datasets to show that the analysis on the efects of graph convolution holds on the four diferent types of graphs we used.</s><s xml:id="_Z8Wztq3" coords="26,363.67,286.84,167.64,9.42;26,80.70,298.80,122.94,9.42">The 14 datasets used include each of these four diferent types of graphs.</s><s xml:id="_n7yzZRG" coords="26,206.13,298.80,325.36,9.42;26,80.70,310.75,52.77,9.42">We compared GRACE with the state-of-the-art methods to validate its superior performance.</s><s xml:id="_Q4Rj78C" coords="26,135.87,310.75,395.62,9.42;26,80.70,322.71,248.59,9.42">We also showed the efects of the diferent parameters of GRACE (as well as the ilters we chose for GRACE) on the performance of AGC for each type of graphs.</s></p><p xml:id="_6Rxgu6j"><s xml:id="_YAyYUWK" coords="26,90.66,334.67,440.64,9.42;26,80.70,346.62,329.93,9.42">Lastly, due to the diferent challenges that arise with diferent types of graph structure, we conducted an extensive survey of prior works for clustering the four types of graphs we studied.</s><s xml:id="_zfMTBGa" coords="26,413.13,346.62,118.18,9.42;26,80.70,358.58,450.61,9.42;26,80.70,370.53,319.73,9.42">Following <ref type="bibr" coords="26,455.51,346.62,14.71,9.42" target="#b26">[27]</ref>, we categorize these works into two categories; (1) methods that focus only on node attributes or graph structure, and (2) methods that combine the information from both graph structure and node attributes.</s><s xml:id="_dcUzsve" coords="26,403.10,370.53,128.20,9.42;26,80.70,382.49,450.61,9.42;26,80.70,394.44,199.56,9.42">We highlight the limitations of the methods in the irst category, as well as discuss that the methods in the second category are not easy to generalize to clustering diferent types of graphs.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8" xml:id="_MCVGCsZ">CONCLUSION</head><p xml:id="_bCNUnre"><s xml:id="_hrxavcN" coords="26,80.22,435.00,282.46,9.42">We studied the AGC problem with many diferent attributed graphs.</s><s xml:id="_jPt2Wnz" coords="26,365.17,435.00,166.40,9.42;26,80.70,446.96,451.70,9.42;26,80.70,458.91,226.93,9.42">Unlike existing AGC algorithms on only speciic graph types, we provided a general framework for AGC on various graph types, including undirected, directed, hyper-, and multi-relational attributed graphs.</s><s xml:id="_zEEFD5A" coords="26,310.10,458.91,221.20,9.42;26,80.33,470.87,296.06,9.42">We proposed efective and eicient graph convolution with well-designed graph Laplacians for each type of graph structures.</s><s xml:id="_gwT2YSu" coords="26,379.25,470.87,152.05,9.42;26,80.70,482.82,450.60,9.42;26,80.70,494.78,113.48,9.42">By performing graph convolution to remove the attribute noises, the processed node attributes integrate the graph structure information and can be directly used for clustering.</s><s xml:id="_hnfAJZK" coords="26,196.65,494.78,334.66,9.42;26,80.70,506.73,24.53,9.42">We conducted extensive experiments on 14 real-world datasets of diferent graph types.</s><s xml:id="_wS46JDK" coords="26,107.89,506.73,423.41,9.42;26,80.70,518.69,33.97,9.42">The results show that our algorithm outperforms the existing AGC methods while remaining fast and scalable.</s></p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,80.70,284.42,450.60,8.46;2,80.70,295.38,450.83,8.46;2,80.70,306.34,450.60,8.46;2,80.70,317.30,339.43,8.46"><head>Fig. 1 .</head><label>1</label><figDesc><div><p xml:id="_ZkSAVP8"><s xml:id="_eknPMwH" coords="2,80.70,284.42,21.57,8.46">Fig. 1.</s><s xml:id="_UnYX4wT" coords="2,106.75,284.42,245.57,8.46">An example of an atributed graph with diferent clustering results.</s><s xml:id="_vGV8hdm" coords="2,354.56,284.42,176.74,8.46;2,80.70,295.38,225.14,8.46">In (a), four nodes are connected with undirected edges and associated with two-dimensional atribute vectors.</s><s xml:id="_FkFkwHM" coords="2,308.09,295.38,223.43,8.46;2,80.70,306.34,322.23,8.46">In (b), only node atributes are used for clustering, in (c) only the graph structure is used, and in (d) both node atributes and graph structure are used.</s><s xml:id="_H9yF5fc" coords="2,405.16,306.34,126.14,8.46;2,80.70,317.30,339.43,8.46">The nodes are partitioned into two clusters (red and blue circles), and diferent node colors represent their ground truth classes.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,80.70,231.81,450.61,8.46;6,80.70,242.76,450.60,8.46;6,80.70,253.72,137.92,8.46"><head>Fig. 2 .</head><label>2</label><figDesc><div><p xml:id="_xhtGhH4"><s xml:id="_eTBwfwN" coords="6,80.70,231.81,226.92,8.46">Fig. 2. Examples of graph structures with four types of edges.</s><s xml:id="_GPjpDMZ" coords="6,309.86,231.81,221.45,8.46;6,80.70,242.76,120.55,8.46">In (a) and (b), pairwise nodes are connected with undirected and directed edges, respectively.</s><s xml:id="_ZtK9C8T" coords="6,203.50,242.76,218.77,8.46">In (c), hyper-edges are used to connect two or more nodes.</s><s xml:id="_t3Zg5TC" coords="6,424.51,242.76,106.79,8.46;6,80.70,253.72,137.92,8.46">In (d), solid lines and dashed lines represent two types of relations.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="7,80.70,321.33,450.61,8.46;7,80.70,332.29,422.86,8.46"><head>Fig. 3 .</head><label>3</label><figDesc><div><p xml:id="_UwKJckj"><s xml:id="_6YSpF5P" coords="7,80.70,321.33,22.73,8.46">Fig. 3.</s><s xml:id="_aeTVexZ" coords="7,107.91,321.33,255.47,8.46">The overview of graph convolution-based algorithm for Undi-AGC.</s><s xml:id="_5duD8UU" coords="7,366.26,321.33,165.04,8.46;7,80.70,332.29,422.86,8.46">It consists of two stages: (1) perform graph convolution on node atributes, and (2) feed processed node atributes into an atribute-based clustering algorithm.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="12,83.36,279.44,9.29,7.54;12,137.98,278.74,41.03,8.48;12,194.30,276.62,115.26,10.60;12,83.36,292.52,9.29,7.54;12,111.08,289.69,43.59,10.60;12,83.36,313.83,148.36,8.48;12,83.36,325.50,9.29,7.54;12,111.08,324.79,89.60,8.48;12,83.36,336.46,9.29,7.54;12,124.53,335.75,112.33,8.48;12,83.36,347.42,9.29,7.54;12,111.08,346.71,97.74,8.48;12,83.36,358.37,9.29,7.54;12,124.53,357.59,182.41,8.56;12,83.36,369.33,9.29,7.54;12,111.08,368.63,114.08,8.48;12,83.36,380.29,9.29,7.54;12,124.53,379.59,31.92,8.48;12,173.30,379.51,57.15,8.56;12,83.36,391.25,9.29,7.54;12,124.53,390.47,45.92,8.56;12,83.36,402.21,9.29,7.54;12,144.23,399.45,106.06,11.48;12,83.36,413.99,9.29,7.54;12,149.40,410.95,62.45,11.76;12,199.95,418.01,20.41,6.94;12,83.36,426.35,9.29,7.54;12,149.08,425.57,89.93,8.56;12,83.36,437.45,9.29,7.54;12,149.40,434.41,115.75,11.76;12,253.25,441.47,20.41,6.94;12,277.10,436.67,30.09,8.56;12,83.36,453.43,9.29,7.54"><head>12 :</head><label>12</label><figDesc><div><p xml:id="_7jWcmDm"><s xml:id="_wTtJ8Ne" coords="12,137.98,278.74,41.03,8.48;12,194.30,276.62,115.26,10.60;12,83.36,292.52,9.29,7.54;12,111.08,289.69,43.59,10.60;12,83.36,313.83,148.36,8.48;12,83.36,325.50,9.29,7.54;12,111.08,324.79,89.60,8.48;12,83.36,336.46,9.29,7.54;12,124.53,335.75,112.33,8.48;12,83.36,347.42,9.29,7.54;12,111.08,346.71,97.74,8.48;12,83.36,358.37,9.29,7.54;12,124.53,357.59,182.41,8.56;12,83.36,369.33,9.29,7.54;12,111.08,368.63,114.08,8.48;12,83.36,380.29,9.29,7.54;12,124.53,379.59,31.92,8.48;12,173.30,379.51,57.15,8.56;12,83.36,391.25,9.29,7.54;12,124.53,390.47,45.92,8.56;12,83.36,402.21,9.29,7.54;12,144.23,399.45,106.06,11.48;12,83.36,413.99,9.29,7.54;12,149.40,410.95,62.45,11.76;12,199.95,418.01,20.41,6.94;12,83.36,426.35,9.29,7.54;12,149.08,425.57,89.93,8.56;12,83.36,437.45,9.29,7.54;12,149.40,434.41,115.75,11.76;12,253.25,441.47,20.41,6.94;12,277.10,436.67,30.09,8.56;12,83.36,453.43,9.29,7.54">Recompute = BuildLaplacian(, , ( ) ) 13: Set = ( ) 14: function BuildLaplacian(, , ) 15: if is undirected then 16: Build adjacency matrix from 17: else if is directed then 18: Build adjacency matrix from , and set = + 19: else if is hyper-graph then 20: Initialize = 0 for ∀ , ∈ 21: for ∈ do 22: , = arg max , ∈ || -|| 2 23: , = , = 1 2| | -3 24: = { ∈ : ≠ , ≠ } 25: , = , = , = , = 1 2| | -3 for ∀ ∈ 26:</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="20,240.04,220.83,131.92,8.46"><head>Fig. 4 .</head><label>4</label><figDesc><div><p xml:id="_3nXrzxB"><s xml:id="_DvUUUNJ" coords="20,240.04,220.83,131.92,8.46">Fig. 4. Efects of the length of hops.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="20,231.59,424.60,148.82,8.46"><head>Fig. 5 .</head><label>5</label><figDesc><div><p xml:id="_ghcvmRm"><s xml:id="_uzeEpzg" coords="20,231.59,424.60,148.82,8.46">Fig. 5. Efects of the graph filtering rate.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="21,231.26,220.83,149.49,8.46"><head>Fig. 6 .</head><label>6</label><figDesc><div><p xml:id="_RGvYq6A"><s xml:id="_veCF9wS" coords="21,231.26,220.83,21.68,8.46">Fig. 6.</s><s xml:id="_JXPzryt" coords="21,257.42,220.83,123.32,8.46">Efects of the stopping algorithm.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7" coords="21,169.47,525.01,273.05,8.46"><head>Fig. 7 .</head><label>7</label><figDesc><div><p xml:id="_ktXgrQ2"><s xml:id="_AjjR2fN" coords="21,169.47,525.01,273.05,8.46">Fig. 7. Comparison of diferent graph Laplacians on diferent graph types.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,214.28,105.93,183.43,182.73"><head>Table 1 .</head><label>1</label><figDesc><div><p xml:id="_KNcBV9q"><s xml:id="_7PTYGfM" coords="4,303.83,105.93,36.53,8.46">Notations</s></p></div></figDesc><table coords="4,214.28,120.24,183.43,168.43"><row><cell cols="2">Name Description</cell></row><row><cell>V</cell><cell>A set of nodes</cell></row><row><cell></cell><cell>The -th node ( = 1, 2, • • • , )</cell></row><row><cell>x</cell><cell>The node attribute vector of</cell></row><row><cell>X</cell><cell>An attribute matrix of all nodes</cell></row><row><cell>E</cell><cell>A set of edges</cell></row><row><cell></cell><cell>The -th edge ( = 1, 2, • • • , )</cell></row><row><cell></cell><cell>An adjacency matrix</cell></row><row><cell></cell><cell>An incidence matrix</cell></row><row><cell></cell><cell>A degree matrix</cell></row><row><cell></cell><cell>The -th cluster ( = 1, 2, • • • , )</cell></row><row><cell></cell><cell>A cluster assignment matrix</cell></row><row><cell></cell><cell>A graph ilter function</cell></row><row><cell></cell><cell>A symmetric graph Laplacian matrix</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="10,125.18,105.93,229.33,38.47"><head>Table 2 .</head><label>2</label><figDesc><div><p xml:id="_4JtYckq"><s xml:id="_KyttzAP" coords="10,289.67,105.93,64.84,8.46">Graph Laplacians</s></p></div></figDesc><table coords="10,125.18,120.24,225.55,24.16"><row><cell>Name</cell><cell>Deinition</cell></row><row><cell>symmetric (undirected) graph Laplacian</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="12,80.33,107.45,306.64,68.40"><head></head><label></label><figDesc><div><p xml:id="_CE5Reqn"><s xml:id="_83dSxJv" coords="12,80.33,107.45,294.73,9.42;12,97.63,123.17,269.09,8.56;12,124.53,134.21,262.44,9.42;12,97.63,145.17,92.16,8.48;12,87.07,156.13,189.49,9.42">Algorithm 2 GRACE: A general graph convolution framework for AGC Input: Attributed graph = ( , ), graph type , number of clusters , graph iltering rate , maximum iteration number max , tolerance value Output: A set of clusters 1: procedure FindClusters(, , , , max , )</s></p></div></figDesc><table coords="12,87.07,168.32,5.59,7.54"><row><cell>2:</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="13,161.28,105.93,289.43,199.41"><head>Table 3 .</head><label>3</label><figDesc><div><p xml:id="_bxvPWUn"><s xml:id="_hve9k9U" coords="13,275.95,105.93,92.27,8.46">Statistics of the datasets.</s></p></div></figDesc><table coords="13,161.28,123.35,289.43,182.00"><row><cell>Dataset</cell><cell cols="2">Type #Node</cell><cell>#Edge</cell><cell cols="3">|R| #Attribute #Class</cell></row><row><cell>Undirected Cora</cell><cell>Undi</cell><cell>2708</cell><cell>5429</cell><cell>-</cell><cell>1433</cell><cell>7</cell></row><row><cell>Citeseer</cell><cell>Undi</cell><cell>3327</cell><cell>4732</cell><cell>-</cell><cell>3703</cell><cell>6</cell></row><row><cell>Pubmed</cell><cell>Undi</cell><cell>19717</cell><cell>44338</cell><cell>-</cell><cell>500</cell><cell>3</cell></row><row><cell>Wiki</cell><cell>Undi</cell><cell>2405</cell><cell>17981</cell><cell>-</cell><cell>4973</cell><cell>17</cell></row><row><cell>Cora-ML</cell><cell>Di</cell><cell>2995</cell><cell>8416</cell><cell>-</cell><cell>2879</cell><cell>7</cell></row><row><cell>Directed Citeseer</cell><cell>Di</cell><cell>3312</cell><cell>4715</cell><cell>-</cell><cell>3703</cell><cell>6</cell></row><row><cell>Cora Co-citation</cell><cell cols="2">Hyper 2708</cell><cell>1579</cell><cell>-</cell><cell>1433</cell><cell>7</cell></row><row><cell cols="3">Citeseer Co-citation Hyper 3327</cell><cell>1079</cell><cell>-</cell><cell>3703</cell><cell>6</cell></row><row><cell cols="3">Pubmed Co-citation Hyper 19717</cell><cell>7963</cell><cell>-</cell><cell>500</cell><cell>3</cell></row><row><cell cols="3">Cora Co-authorship Hyper 2708</cell><cell>1072</cell><cell>-</cell><cell>1433</cell><cell>7</cell></row><row><cell cols="3">DBLP Co-authorship Hyper 43413</cell><cell>22535</cell><cell>-</cell><cell>1425</cell><cell>6</cell></row><row><cell>ACM</cell><cell>MR</cell><cell>8916</cell><cell>2240042</cell><cell>2</cell><cell>1870</cell><cell>3</cell></row><row><cell>IMDB</cell><cell>MR</cell><cell>9717</cell><cell>80216</cell><cell>2</cell><cell>2000</cell><cell>3</cell></row><row><cell>Hete DBLP</cell><cell>MR</cell><cell cols="2">26128 12055179</cell><cell>3</cell><cell>334</cell><cell>4</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="14,236.95,447.36,137.85,8.46"><head>Table 4 .</head><label>4</label><figDesc><div><p xml:id="_TWm9fXA"><s xml:id="_Nj2nxzC" coords="14,269.38,447.36,105.43,8.46">Properties of the algorithms.</s></p></div></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="16,115.62,236.34,380.76,104.59"><head>Table 5 .</head><label>5</label><figDesc><div><p xml:id="_M8pPUJ4"><s xml:id="_J34wq7v" coords="16,215.53,236.34,213.11,8.46">Clustering performance on Undirected Cora and Citeseer.</s></p></div></figDesc><table coords="16,115.62,253.85,380.76,87.08"><row><cell>Baselines</cell><cell></cell><cell></cell><cell cols="2">Undirected Cora</cell><cell></cell><cell></cell><cell></cell><cell cols="2">Citeseer</cell><cell></cell></row><row><cell></cell><cell cols="2">Acc% NMI%</cell><cell>F1%</cell><cell cols="4">Time (Sec) Mem (MB) Acc% NMI%</cell><cell>F1%</cell><cell cols="2">Time (Sec) Mem (MB)</cell></row><row><cell>K-Means</cell><cell>37.22</cell><cell>16.64</cell><cell>32.09</cell><cell>01.11</cell><cell>172.58</cell><cell>43.04</cell><cell>20.68</cell><cell>39.26</cell><cell>03.61</cell><cell>234.76</cell></row><row><cell>N-cut</cell><cell>28.84</cell><cell>04.64</cell><cell>08.93</cell><cell>00.56</cell><cell>156.83</cell><cell>22.03</cell><cell>01.78</cell><cell>10.81</cell><cell>01.26</cell><cell>151.14</cell></row><row><cell>ARGE</cell><cell>62.19</cell><cell>44.13</cell><cell>63.60</cell><cell>128.32</cell><cell>5152.32</cell><cell>54.40</cell><cell>28.22</cell><cell>53.21</cell><cell>256.89</cell><cell>1608.60</cell></row><row><cell>ARVGE</cell><cell>68.24</cell><cell>50.49</cell><cell>68.04</cell><cell>111.10</cell><cell>4347.57</cell><cell>54.40</cell><cell>26.10</cell><cell>52.90</cell><cell>230.76</cell><cell>1694.24</cell></row><row><cell cols="4">AdaGCN 68.94 53.74 65.63</cell><cell>04.10</cell><cell>212.76</cell><cell>67.30</cell><cell>41.46</cell><cell>62.77</cell><cell>31.24</cell><cell>435.32</cell></row><row><cell>GRACE</cell><cell cols="3">72.01 53.30 72.35</cell><cell>07.18</cell><cell>240.00</cell><cell cols="3">68.14 42.06 63.58</cell><cell>16.34</cell><cell>427.00</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="16,115.62,375.81,380.76,104.59"><head>Table 6 .</head><label>6</label><figDesc><div><p xml:id="_YFERXjj"><s xml:id="_rTFX7FP" coords="16,216.13,375.81,211.93,8.46">Clustering performance on undirected Pubmed and Wiki.</s></p></div></figDesc><table coords="16,115.62,393.32,380.76,87.08"><row><cell>Baselines</cell><cell></cell><cell></cell><cell cols="2">Pubmed</cell><cell></cell><cell></cell><cell></cell><cell cols="2">Wiki</cell><cell></cell></row><row><cell></cell><cell cols="2">Acc% NMI%</cell><cell>F1%</cell><cell cols="4">Time (Sec) Mem (MB) Acc% NMI%</cell><cell>F1%</cell><cell cols="2">Time (Sec) Mem (MB)</cell></row><row><cell>K-Means</cell><cell>59.50</cell><cell>31.13</cell><cell>58.14</cell><cell>02.23</cell><cell>268.83</cell><cell>33.30</cell><cell>30.14</cell><cell>22.72</cell><cell>06.12</cell><cell>315.38</cell></row><row><cell>N-cut</cell><cell>58.96</cell><cell>18.30</cell><cell>43.53</cell><cell>26.63</cell><cell>359.00</cell><cell>35.67</cell><cell>35.51</cell><cell>27.90</cell><cell>01.23</cell><cell>251.67</cell></row><row><cell>ARGE</cell><cell>69.48</cell><cell>32.93</cell><cell>68.80</cell><cell>5667.13</cell><cell>15528.80</cell><cell>46.15</cell><cell>44.19</cell><cell>41.04</cell><cell>739.56</cell><cell>3997.67</cell></row><row><cell>ARVGE</cell><cell>67.99</cell><cell>30.39</cell><cell>67.37</cell><cell>4638.73</cell><cell>18451.83</cell><cell>45.29</cell><cell>44.03</cell><cell>39.90</cell><cell>728.08</cell><cell>3184.21</cell></row><row><cell cols="2">AdaGCN 69.82</cell><cell>31.56</cell><cell>68.77</cell><cell>32.77</cell><cell>421.04</cell><cell>46.90</cell><cell>44.30</cell><cell>38.51</cell><cell>08.98</cell><cell>412.83</cell></row><row><cell>GRACE</cell><cell cols="3">70.40 32.60 69.68</cell><cell>24.31</cell><cell>498.36</cell><cell cols="3">62.50 54.43 46.19</cell><cell>13.94</cell><cell>504.25</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="17,115.62,254.92,380.76,94.63"><head>Table 7 .</head><label>7</label><figDesc><div><p xml:id="_pUfNnmH"><s xml:id="_XkphnGu" coords="17,238.90,254.92,166.38,8.46">Clustering performance on directed datasets.</s></p></div></figDesc><table coords="17,115.62,272.42,380.76,77.12"><row><cell>Baselines</cell><cell></cell><cell></cell><cell cols="2">Cora-ML</cell><cell></cell><cell></cell><cell></cell><cell cols="2">Directed Citeseer</cell><cell></cell></row><row><cell></cell><cell cols="2">Acc% NMI%</cell><cell>F1%</cell><cell cols="4">Time (Sec) Mem (MB) Acc% NMI%</cell><cell>F1%</cell><cell cols="2">Time (Sec) Mem (MB)</cell></row><row><cell>K-Means</cell><cell>50.62</cell><cell>32.30</cell><cell>47.00</cell><cell>03.40</cell><cell>285.10</cell><cell>41.06</cell><cell>18.74</cell><cell>37.99</cell><cell>04.98</cell><cell>205.60</cell></row><row><cell>N-cut</cell><cell>52.35</cell><cell>32.56</cell><cell>48.58</cell><cell>00.37</cell><cell>296.23</cell><cell>46.49</cell><cell>21.27</cell><cell>43.15</cell><cell>00.40</cell><cell>307.53</cell></row><row><cell>GNMF</cell><cell>68.21</cell><cell>43.58</cell><cell>68.09</cell><cell>03.95</cell><cell>240.93</cell><cell>63.86</cell><cell>36.97</cell><cell>60.57</cell><cell>10.23</cell><cell>295.55</cell></row><row><cell>JNMF</cell><cell>50.62</cell><cell>24.79</cell><cell>48.68</cell><cell>64.52</cell><cell>278.44</cell><cell>64.46</cell><cell>36.59</cell><cell>60.55</cell><cell>135.19</cell><cell>330.49</cell></row><row><cell>GRACE</cell><cell cols="3">75.09 60.73 71.48</cell><cell>22.79</cell><cell>309.64</cell><cell cols="3">68.69 42.97 63.79</cell><cell>10.98</cell><cell>421.81</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="17,115.62,538.19,380.76,94.63"><head>Table 8 .</head><label>8</label><figDesc><div><p xml:id="_wMUB8Rc"><s xml:id="_S99txTs" coords="17,233.06,538.19,178.06,8.46">Clustering performance on Co-citation datasets.</s></p></div></figDesc><table coords="17,115.62,555.70,380.76,77.12"><row><cell>Baselines</cell><cell></cell><cell></cell><cell cols="2">Cora Co-citation</cell><cell></cell><cell></cell><cell></cell><cell cols="2">Pubmed Co-citation</cell><cell></cell></row><row><cell></cell><cell cols="2">Acc% NMI%</cell><cell>F1%</cell><cell cols="4">Time (Sec) Mem (MB) Acc% NMI%</cell><cell>F1%</cell><cell cols="2">Time (Sec) Mem (MB)</cell></row><row><cell>K-Means</cell><cell>33.27</cell><cell>13.07</cell><cell>22.12</cell><cell>01.48</cell><cell>179.64</cell><cell>59.47</cell><cell>31.10</cell><cell>58.14</cell><cell>02.64</cell><cell>195.45</cell></row><row><cell>N-cut</cell><cell>30.02</cell><cell>01.12</cell><cell>07.39</cell><cell>02.41</cell><cell>343.35</cell><cell>39.95</cell><cell>00.07</cell><cell>19.09</cell><cell>105.20</cell><cell>12525.82</cell></row><row><cell>GNMF</cell><cell>43.91</cell><cell>22.58</cell><cell>40.56</cell><cell>20.92</cell><cell>337.52</cell><cell>55.61</cell><cell>20.84</cell><cell>56.98</cell><cell>147.76</cell><cell>8828.43</cell></row><row><cell>JNMF</cell><cell>45.31</cell><cell>23.01</cell><cell>42.61</cell><cell>36.95</cell><cell>382.82</cell><cell>51.61</cell><cell>14.04</cell><cell>49.22</cell><cell>603.02</cell><cell>10751.11</cell></row><row><cell>GRACE</cell><cell cols="3">55.39 34.65 50.50</cell><cell>04.88</cell><cell>283.75</cell><cell cols="3">60.89 31.14 60.17</cell><cell>04.23</cell><cell>448.30</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" coords="18,115.62,105.93,380.76,94.63"><head>Table 9 .</head><label>9</label><figDesc><div><p xml:id="_CE3p2cM"><s xml:id="_7xyv9Kq" coords="18,227.05,105.93,190.09,8.46">Clustering performance on Co-authorship datasets.</s></p></div></figDesc><table coords="18,115.62,123.44,380.76,77.12"><row><cell>Baselines</cell><cell></cell><cell></cell><cell cols="2">Cora Co-authorship</cell><cell></cell><cell></cell><cell></cell><cell cols="2">DBLP Co-authorship</cell><cell></cell></row><row><cell></cell><cell cols="2">Acc% NMI%</cell><cell>F1%</cell><cell cols="4">Time (Sec) Mem (MB) Acc% NMI%</cell><cell>F1%</cell><cell cols="2">Time (Sec) Mem (MB)</cell></row><row><cell>K-Means</cell><cell>33.27</cell><cell>13.07</cell><cell>22.12</cell><cell>01.46</cell><cell>183.30</cell><cell>61.25</cell><cell>38.30</cell><cell>60.90</cell><cell>21.34</cell><cell>1262.65</cell></row><row><cell>N-cut</cell><cell>29.25</cell><cell>02.00</cell><cell>09.50</cell><cell>07.42</cell><cell>374.96</cell><cell>27.58</cell><cell>01.00</cell><cell>09.25</cell><cell>1751.96</cell><cell>54187.64</cell></row><row><cell>GNMF</cell><cell>51.22</cell><cell>27.49</cell><cell>44.57</cell><cell>21.01</cell><cell>327.47</cell><cell>63.71</cell><cell>47.91</cell><cell>58.38</cell><cell>1100.76</cell><cell>41845.62</cell></row><row><cell>JNMF</cell><cell>49.41</cell><cell>28.63</cell><cell>44.29</cell><cell>11.16</cell><cell>422.26</cell><cell>61.80</cell><cell>44.72</cell><cell>58.82</cell><cell>3642.91</cell><cell>48216.73</cell></row><row><cell>GRACE</cell><cell cols="3">60.08 37.44 59.19</cell><cell>11.10</cell><cell>276.61</cell><cell cols="3">64.49 56.27 65.82</cell><cell>92.65</cell><cell>1763.06</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" coords="18,120.86,501.14,370.28,90.58"><head>Table 10 .</head><label>10</label><figDesc><div><p xml:id="_BKXTYhq"><s xml:id="_dAmwyF8" coords="18,227.19,501.14,193.98,8.46">Clustering performance on multi-relational datasets.</s></p></div></figDesc><table coords="18,120.86,518.64,370.28,73.08"><row><cell>Baselines</cell><cell>ACM</cell><cell>IMDB</cell><cell>Hete DBLP</cell></row><row><cell></cell><cell>Acc% NMI% F1%</cell><cell>Acc% NMI% F1%</cell><cell cols="2">Acc% NMI% F1% Time(Sec)</cell></row><row><cell>K-Means</cell><cell cols="3">67.93 32.03 68.10 52.45 14.63 53.14 36.80 08.47 28.46</cell><cell>02.41</cell></row><row><cell>N-cut</cell><cell cols="3">34.35 07.00 23.68 34.84 00.07 32.54 92.31 76.54 91.81</cell><cell>03.42</cell></row><row><cell cols="4">SpectralMix 90.12 67.99 90.70 55.46 20.11 56.98 40.55 16.05 32.27</cell><cell>22572.54</cell></row><row><cell>GRACE</cell><cell cols="3">88.89 65.08 89.08 62.87 18.44 62.95 92.33 76.68 91.83</cell><cell>74.63</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="3,83.93,636.68,163.67,7.54"><p xml:id="_9uhGAU3"><s xml:id="_K3vhdPZ" coords="3,83.93,636.68,163.67,7.54">https://paperswithcode.com/task/graph-clustering</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="3,83.83,646.65,262.25,7.54"><p xml:id="_nv3jMCy"><s xml:id="_y6b4AMn" coords="3,83.83,646.65,262.25,7.54">The code of GRACE can be found at https://github.com/BarakeelFanseu/GRACE.</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2" coords="5,421.06,670.82,110.24,7.54"><p xml:id="_CA2CM3k"><s xml:id="_qdz2XDY" coords="5,421.06,670.82,39.48,7.54">ACM Trans.</s><s xml:id="_6C7aYkZ" coords="5,462.87,670.82,23.17,7.54">Knowl.</s><s xml:id="_4PepUVW" coords="5,488.36,670.82,23.47,7.54">Discov.</s><s xml:id="_WHSpXVe" coords="5,514.16,670.82,17.14,7.54">Data.</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_3" coords="14,84.07,646.50,266.65,7.54"><p xml:id="_gbjf8pv"><s xml:id="_raEkMJN" coords="14,84.07,646.50,266.65,7.54">https://gitlab.cs.univie.ac.at/yllis19cs/spectralmixpublic/-/tree/master/SpectralMix</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_4" coords="17,83.69,646.91,352.73,7.54"><p xml:id="_QkPefVJ"><s xml:id="_krhkHvD" coords="17,83.69,646.91,352.73,7.54">The comparison on the Citeseer Co-citation dataset is omitted, and it has very similar results as seen in<ref type="bibr" coords="17,421.57,646.91,11.87,7.54" target="#b26">[27]</ref>.</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_5" coords="22,84.07,646.65,447.09,7.54"><p xml:id="_pDj3t6D"><s xml:id="_kWHTJ5s" coords="22,84.07,646.65,447.09,7.54">Note that all undirected graph methods can easily be extended to directed graphs by making the directed graph structure undirected<ref type="bibr" coords="22,516.32,646.65,11.87,7.54" target="#b54">[55]</ref>.</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_6" coords="24,84.07,646.28,417.47,7.54"><p xml:id="_mJ7ZpmJ"><s xml:id="_ZPEJBPk" coords="24,84.07,646.28,417.47,7.54">One can ind the state-of-the-art models for Undi-AGC via the following link: https://paperswithcode.com/task/graph-clustering</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_7" coords="25,83.65,646.43,416.58,7.54"><p xml:id="_5TwAVRc"><s xml:id="_R3Hq7Mh" coords="25,83.65,646.43,416.58,7.54">An additional beneit of our framework is that it can be utilized by any convolution-based algorithms or NMF-based algorithms.</s></p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head xml:id="_2GhhBY5">ACKNOWLEDGMENTS</head><p xml:id="_eNcw5kj">We thank the reviewers for their valuable comments.This work was supported by <rs type="funder">GRF</rs> <rs type="grantNumber">14208318</rs> from the <rs type="funder">RGC of HKSAR</rs> and <rs type="funder">CUHK</rs> direct grant <rs type="grantNumber">4055146</rs>.<rs type="person">Lin Zhang</rs> and <rs type="person">Bo Li</rs> were supported in part by <rs type="funder">RGC RIF</rs> grant <rs type="grantNumber">R6021-20</rs> and <rs type="funder">RGC GRF</rs> grant under contracts <rs type="grantNumber">16209120</rs> and <rs type="grantNumber">16200221</rs>.<rs type="person">Bo Han</rs> was supported by the <rs type="funder">RGC Early Career Scheme</rs> No. <rs type="grantNumber">22200720</rs> and <rs type="funder">NSFC Young Scientists Fund</rs> No. <rs type="grantNumber">62006202</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_AH674zK">
					<idno type="grant-number">14208318</idno>
				</org>
				<org type="funding" xml:id="_U5Tu6Pg">
					<idno type="grant-number">4055146</idno>
				</org>
				<org type="funding" xml:id="_tWBgkD4">
					<idno type="grant-number">R6021-20</idno>
				</org>
				<org type="funding" xml:id="_jDsXcuH">
					<idno type="grant-number">16209120</idno>
				</org>
				<org type="funding" xml:id="_DTTPBdA">
					<idno type="grant-number">16200221</idno>
				</org>
				<org type="funding" xml:id="_kVDevC5">
					<idno type="grant-number">22200720</idno>
				</org>
				<org type="funding" xml:id="_Cuxc24B">
					<idno type="grant-number">62006202</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="26,97.77,635.10,433.53,7.54;26,97.77,645.06,123.53,7.54" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="26,300.60,635.10,109.82,7.54" xml:id="_Dtzznhf">Higher order learning with graphs</title>
		<author>
			<persName coords=""><forename type="first">Sameer</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kristin</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Serge</forename><forename type="middle">J</forename><surname>Belongie</surname></persName>
		</author>
		<idno type="DOI">10.1145/1143844.1143847</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_FqdGxKX" coord="26,416.65,635.10,114.65,7.54;26,97.77,645.06,99.90,7.54">Proceedings of the 23rd international conference on Machine learning - ICML &apos;06</title>
		<meeting>the 23rd international conference on Machine learning - ICML &apos;06</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Sameer Agarwal, Kristin Branson, and Serge J. Belongie. 2006. Higher order learning with graphs. Proceedings of the 23rd international conference on Machine learning (2006).</note>
</biblStruct>

<biblStruct coords="27,97.77,108.93,433.54,7.54;27,97.77,118.89,433.53,7.54;27,97.77,128.85,386.03,7.54" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="27,220.03,108.93,252.00,7.54" xml:id="_MhvGcff">Attributed Graph Clustering</title>
		<author>
			<persName coords=""><forename type="first">Esra</forename><surname>Akbas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Peixiang</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="DOI">10.1145/3110025.3110092</idno>
		<ptr target="https://doi.org/10.1145/3110025.3110092" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_ZGcg4sx" coord="27,486.46,108.93,44.84,7.54;27,97.77,118.89,305.16,7.54">Proceedings of the 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2017</title>
		<editor>
			<persName><forename type="first">Jana</forename><surname>Diesner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Elena</forename><surname>Ferrari</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Guandong</forename><surname>Xu</surname></persName>
		</editor>
		<meeting>the 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2017<address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017-07-31">2017. 2017. July 31 -August 03, 2017</date>
			<biblScope unit="page" from="305" to="308" />
		</imprint>
	</monogr>
	<note type="raw_reference">Esra Akbas and Peixiang Zhao. 2017. Attributed Graph Clustering: an Attribute-aware Graph Embedding Approach. In Proceedings of the 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2017, Sydney, Australia, July 31 -August 03, 2017, Jana Diesner, Elena Ferrari, and Guandong Xu (Eds.). ACM, 305ś308. https://doi.org/10.1145/3110025.3110092</note>
</biblStruct>

<biblStruct coords="27,97.77,138.82,434.76,7.54;27,97.77,148.78,153.30,7.54" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="27,259.31,138.82,140.82,7.54" xml:id="_tfvE8DR">Using PageRank to Locally Partition a Graph</title>
		<author>
			<persName coords=""><forename type="first">Reid</forename><surname>Andersen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fan</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kevin</forename><surname>Lang</surname></persName>
		</author>
		<idno type="DOI">10.1080/15427951.2007.10129139</idno>
		<ptr target="https://doi.org/10.1080/15427951.2007.10129139" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_DxHXMYk" coord="27,406.46,138.82,65.95,7.54">Internet Mathematics</title>
		<title level="j" type="abbrev">Internet Mathematics</title>
		<idno type="ISSN">1542-7951</idno>
		<idno type="ISSNe">1944-9488</idno>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="35" to="64" />
			<date type="published" when="2007-01">2007. 01 2007</date>
			<publisher>Internet Mathematics</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Reid Andersen, Fan Chung, and Kevin Lang. 2007. Using PageRank to Locally Partition a Graph. Internet Mathematics 4 (01 2007), 35ś64. https://doi.org/10.1080/15427951.2007.10129139</note>
</biblStruct>

<biblStruct coords="27,97.77,158.74,434.76,7.54;27,97.77,168.70,159.35,7.54" xml:id="b3">
	<analytic>
		<title level="a" type="main" xml:id="_mdK9Wax">Hypergraph convolution and hypergraph attention</title>
		<author>
			<persName coords=""><forename type="first">Song</forename><surname>Bai</surname></persName>
			<idno type="ORCID">0000-0002-2570-9118</idno>
		</author>
		<author>
			<persName coords=""><forename type="first">Feihu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Philip</forename><forename type="middle">H S</forename><surname>Torr</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.patcog.2020.107637</idno>
		<idno type="arXiv">arXiv:1901.08150</idno>
		<ptr target="http://arxiv.org/abs/1901.08150" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_kwtpsSJ">Pattern Recognition</title>
		<title level="j" type="abbrev">Pattern Recognition</title>
		<idno type="ISSN">0031-3203</idno>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="page">107637</biblScope>
			<date type="published" when="2019">2019. 2019</date>
			<publisher>Elsevier BV</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Song Bai, Feihu Zhang, and Philip H. S. Torr. 2019. Hypergraph Convolution and Hypergraph Attention. CoRR abs/1901.08150 (2019). arXiv:1901.08150 http://arxiv.org/abs/1901.08150</note>
</biblStruct>

<biblStruct coords="27,97.77,178.67,434.40,7.54;27,97.59,188.63,223.19,7.54" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="27,229.39,178.67,246.46,7.54" xml:id="_jHNBfNP">Laplacian Eigenmaps for Dimensionality Reduction and Data Representation</title>
		<author>
			<persName coords=""><forename type="first">Mikhail</forename><surname>Belkin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Partha</forename><surname>Niyogi</surname></persName>
		</author>
		<idno type="DOI">10.1162/089976603321780317</idno>
		<ptr target="https://doi.org/10.1162/089976603321780317" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_5nRFEGC" coord="27,482.07,178.67,50.10,7.54">Neural Computation</title>
		<title level="j" type="abbrev">Neural Computation</title>
		<idno type="ISSN">0899-7667</idno>
		<idno type="ISSNe">1530-888X</idno>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1373" to="1396" />
			<date type="published" when="2003-06-01">2003. 2003</date>
			<publisher>MIT Press - Journals</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Mikhail Belkin and Partha Niyogi. 2003. Laplacian Eigenmaps for Dimensionality Reduction and Data Representation. Neural Comput. 15, 6 (2003), 1373ś1396. https://doi.org/10.1162/089976603321780317</note>
</biblStruct>

<biblStruct coords="27,97.77,198.59,434.76,7.54;27,97.77,208.55,276.08,7.54" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="27,293.97,198.59,235.35,7.54" xml:id="_Cm74TGh">Graph regularized nonnegative matrix factorization for data representation</title>
		<author>
			<persName coords=""><forename type="first">Deng</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiaofei</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_FGGgfuG" coord="27,97.77,208.55,197.95,7.54">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<date type="published" when="2010">2010. 2010. 1548ś1560</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Deng Cai, Xiaofei He, Jiawei Han, and Thomas S Huang. 2010. Graph regularized nonnegative matrix factorization for data representation. IEEE transactions on pattern analysis and machine intelligence 33, 8 (2010), 1548ś1560.</note>
</biblStruct>

<biblStruct coords="27,97.77,218.52,433.53,7.54;27,97.77,228.48,386.05,7.54" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="27,320.46,218.52,210.84,7.54;27,97.77,228.48,47.38,7.54" xml:id="_sDnRPuq">Graph Regularized Nonnegative Matrix Factorization for Data Representation</title>
		<author>
			<persName coords=""><forename type="first">Deng</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiaofei</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
		<idno type="DOI">10.1109/TPAMI.2010.231</idno>
		<ptr target="https://doi.org/10.1109/TPAMI.2010.231" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_x9RdwGn" coord="27,151.40,228.48,121.30,7.54">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1548" to="1560" />
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Deng Cai, Xiaofei He, Jiawei Han, and Thomas S. Huang. 2011. Graph Regularized Nonnegative Matrix Factorization for Data Representation. IEEE Trans. Pattern Anal. Mach. Intell. 33, 8 (2011), 1548ś1560. https://doi.org/10.1109/TPAMI.2010.231</note>
</biblStruct>

<biblStruct coords="27,97.77,238.44,434.40,7.54;27,97.77,248.40,238.50,7.54" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="27,245.61,238.44,259.13,7.54" xml:id="_246Mc36">Generalizing the hypergraph Laplacian via a difusion process with mediators</title>
		<author>
			<persName coords=""><forename type="first">T.-H</forename><surname>Hubert Chan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhibin</forename><surname>Liang</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tcs.2019.07.024</idno>
		<ptr target="https://doi.org/10.1016/j.tcs.2019.07.024" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_mdxpqS9" coord="27,512.37,238.44,19.80,7.54;27,97.77,248.40,39.61,7.54">Theor. Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">806</biblScope>
			<biblScope unit="page" from="416" to="428" />
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">T.-H. Hubert Chan and Zhibin Liang. 2020. Generalizing the hypergraph Laplacian via a difusion process with mediators. Theor. Comput. Sci. 806 (2020), 416ś428. https://doi.org/10.1016/j.tcs.2019.07.024</note>
</biblStruct>

<biblStruct coords="27,97.77,258.37,433.53,7.54;27,97.77,268.33,419.69,7.54" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="27,359.09,258.37,144.82,7.54" xml:id="_pvjCcvH">Signal denoising on graphs via graph filtering</title>
		<author>
			<persName coords=""><forename type="first">Siheng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aliaksei</forename><surname>Sandryhaila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jose</forename><forename type="middle">M F</forename><surname>Moura</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jelena</forename><surname>Kovacevic</surname></persName>
		</author>
		<idno type="DOI">10.1109/globalsip.2014.7032244</idno>
		<ptr target="https://doi.org/10.1109/GlobalSIP.2014.7032244" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_taAynut" coord="27,517.43,258.37,13.87,7.54;27,97.77,268.33,193.72,7.54">2014 IEEE Global Conference on Signal and Information Processing (GlobalSIP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014-12">2014</date>
			<biblScope unit="page" from="872" to="876" />
		</imprint>
	</monogr>
	<note type="raw_reference">Siheng Chen, Aliaksei Sandryhaila, José M. F. Moura, and Jelena Kovacevic. 2014. Signal denoising on graphs via graph iltering. In 2014 IEEE Global Conference on Signal and Information Processing (GlobalSIP). 872ś876. https://doi.org/10.1109/GlobalSIP.2014.7032244</note>
</biblStruct>

<biblStruct coords="27,97.77,278.29,433.53,7.54;27,97.77,288.26,353.29,7.54" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="27,264.78,278.29,266.52,7.54;27,97.77,288.26,35.50,7.54" xml:id="_tZKStkw">Clustering Large Attributed Graphs</title>
		<author>
			<persName coords=""><forename type="first">Hong</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><forename type="middle">Xu</forename><surname>Yu</surname></persName>
		</author>
		<idno type="DOI">10.1145/1921632.1921638</idno>
		<ptr target="https://doi.org/10.1145/1921632.1921638" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_EWsYFRP" coord="27,139.09,288.26,103.46,7.54">ACM Transactions on Knowledge Discovery from Data</title>
		<title level="j" type="abbrev">ACM Trans. Knowl. Discov. Data</title>
		<idno type="ISSN">1556-4681</idno>
		<idno type="ISSNe">1556-472X</idno>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="33" />
			<date type="published" when="2011-02">2011. 2011</date>
			<publisher>Association for Computing Machinery (ACM)</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Hong Cheng, Yang Zhou, and Jefrey Xu Yu. 2011. Clustering Large Attributed Graphs: A Balance between Structural and Attribute Similarities. ACM Trans. Knowl. Discov. Data 5, 2 (2011), 12:1ś12:33. https://doi.org/10.1145/1921632.1921638</note>
</biblStruct>

<biblStruct coords="27,97.77,298.22,434.47,7.54;27,97.51,308.18,117.76,7.54" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="27,160.46,298.22,196.75,7.54" xml:id="_SHWRu78">Laplacians and the Cheeger Inequality for Directed Graphs</title>
		<author>
			<persName coords=""><forename type="first">Fan</forename><surname>Chung</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00026-005-0237-z</idno>
		<ptr target="https://doi.org/10.1007/s00026-005-0237-z" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_pdPVDAF" coord="27,365.49,298.22,80.15,7.54">Annals of Combinatorics</title>
		<title level="j" type="abbrev">Ann. Comb.</title>
		<idno type="ISSN">0218-0006</idno>
		<idno type="ISSNe">0219-3094</idno>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="19" />
			<date type="published" when="2005-04">2005. 04 2005</date>
			<publisher>Springer Science and Business Media LLC</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Fan Chung. 2005. Laplacians and the Cheeger Inequality for Directed Graphs. Annals of Combinatorics 9 (04 2005), 1ś19. https: //doi.org/10.1007/s00026-005-0237-z</note>
</biblStruct>

<biblStruct coords="27,97.77,318.14,433.53,7.54;27,97.77,328.11,93.52,7.54" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="27,227.83,318.14,214.58,7.54" xml:id="_ZJPAmPP">Community detection based on structural and attribute similarities</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">A</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Emmanuel</forename><surname>Viennet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_48adpHJ" coord="27,455.90,318.14,75.40,7.54;27,97.77,328.11,71.62,7.54">International conference on digital society (icds)</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="7" to="12" />
		</imprint>
	</monogr>
	<note type="raw_reference">TA Dang and Emmanuel Viennet. 2012. Community detection based on structural and attribute similarities. In International conference on digital society (icds). 7ś12.</note>
</biblStruct>

<biblStruct coords="27,97.77,338.07,434.76,7.54;27,97.77,348.03,433.54,7.54;27,97.77,357.99,318.36,7.54" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="27,294.20,338.07,234.96,7.54" xml:id="_WkrnEYd">Large-Scale Algorithms</title>
		<author>
			<persName coords=""><forename type="first">Olivier</forename><surname>Delalleau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Le Roux</surname></persName>
		</author>
		<idno type="DOI">10.7551/mitpress/6173.003.0025</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_vrZ75Y6" coord="27,106.08,348.03,425.23,7.54;27,97.77,357.99,121.39,7.54">Semi-Supervised Learning</title>
		<imprint>
			<publisher>The MIT Press</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="333" to="342" />
		</imprint>
	</monogr>
	<note type="raw_reference">Olivier Delalleau, Yoshua Bengio, and Nicolas Le Roux. 2005. Eicient Non-Parametric Function Induction in Semi-Supervised Learning. In Proceedings of the Tenth International Workshop on Artiicial Intelligence and Statistics (proceedings of the tenth international workshop on artiicial intelligence and statistics ed.). Society for Artiicial Intelligence and Statistics, 96ś103.</note>
</biblStruct>

<biblStruct coords="27,97.77,367.96,433.53,7.54;27,97.77,377.92,305.87,7.54" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="27,280.77,367.96,180.55,7.54" xml:id="_krPzYJj">Kernel k-means: spectral clustering and normalized cuts</title>
		<author>
			<persName coords=""><forename type="first">Yuqiang</forename><surname>Inderjit S Dhillon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Brian</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Kulis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_ndwU7hu" coord="27,474.93,367.96,56.37,7.54;27,97.77,377.92,272.02,7.54">Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the tenth ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="551" to="556" />
		</imprint>
	</monogr>
	<note type="raw_reference">Inderjit S Dhillon, Yuqiang Guan, and Brian Kulis. 2004. Kernel k-means: spectral clustering and normalized cuts. In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining. 551ś556.</note>
</biblStruct>

<biblStruct coords="27,97.77,387.88,433.53,7.54;27,97.77,397.84,112.81,7.54" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="27,211.93,387.88,168.88,7.54" xml:id="_BtbRmA2">&lt;i&gt;K&lt;/i&gt;-means clustering via principal component analysis</title>
		<author>
			<persName coords=""><forename type="first">Chris</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiaofeng</forename><surname>He</surname></persName>
		</author>
		<idno type="DOI">10.1145/1015330.1015408</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_URZyY7n" coord="27,394.44,387.88,136.86,7.54;27,97.77,397.84,98.54,7.54">Twenty-first international conference on Machine learning - ICML &apos;04</title>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">29</biblScope>
		</imprint>
	</monogr>
	<note type="raw_reference">Chris Ding and Xiaofeng He. 2004. K-means clustering via principal component analysis. In Proceedings of the twenty-irst international conference on Machine learning. 29.</note>
</biblStruct>

<biblStruct coords="27,97.77,407.81,433.53,7.54;27,97.77,417.77,275.16,7.54" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="27,266.42,407.81,253.17,7.54" xml:id="_9myyy7k">On the Equivalence of Nonnegative Matrix Factorization and Spectral Clustering</title>
		<author>
			<persName coords=""><forename type="first">Chris</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiaofeng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Horst</forename><forename type="middle">D</forename><surname>Simon</surname></persName>
		</author>
		<idno type="DOI">10.1137/1.9781611972757.70</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_stXTMHZ" coord="27,97.77,417.77,219.11,7.54">Proceedings of the 2005 SIAM International Conference on Data Mining</title>
		<meeting>the 2005 SIAM International Conference on Data Mining</meeting>
		<imprint>
			<publisher>Society for Industrial and Applied Mathematics</publisher>
			<date type="published" when="2005-01-09">2005</date>
			<biblScope unit="page">610</biblScope>
		</imprint>
	</monogr>
	<note type="raw_reference">Chris Ding, Xiaofeng He, and Horst D Simon. 2005. On the equivalence of nonnegative matrix factorization and spectral clustering. In Proceedings of the 2005 SIAM international conference on data mining. SIAM, 606ś610.</note>
</biblStruct>

<biblStruct coords="27,97.77,427.73,433.53,7.54;27,97.77,437.69,368.03,7.54" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="27,281.59,427.73,249.71,7.54;27,97.77,437.69,108.62,7.54" xml:id="_WGauP4C">Hybrid clustering based on content and connection structure using joint nonnegative matrix factorization</title>
		<author>
			<persName coords=""><forename type="first">Rundong</forename><surname>Du</surname></persName>
			<idno type="ORCID">0000-0003-0736-7983</idno>
		</author>
		<author>
			<persName coords=""><forename type="first">Barry</forename><forename type="middle">L</forename><surname>Drake</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Haesun</forename><surname>Park</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10898-017-0578-x</idno>
		<idno type="arXiv">arXiv:1703.09646</idno>
		<ptr target="http://arxiv.org/abs/1703.09646" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_vGGtSxG">Journal of Global Optimization</title>
		<title level="j" type="abbrev">J Glob Optim</title>
		<idno type="ISSN">0925-5001</idno>
		<idno type="ISSNe">1573-2916</idno>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="861" to="877" />
			<date type="published" when="2017-10-24">2017. 2017</date>
			<publisher>Springer Science and Business Media LLC</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Rundong Du, Barry L. Drake, and Haesun Park. 2017. Hybrid Clustering based on Content and Connection Structure using Joint Nonnegative Matrix Factorization. CoRR abs/1703.09646 (2017). arXiv:1703.09646 http://arxiv.org/abs/1703.09646</note>
</biblStruct>

<biblStruct coords="27,97.77,447.66,433.68,7.54;27,97.77,457.62,434.76,7.54;27,97.77,467.58,42.52,7.54" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="27,400.29,447.66,131.16,7.54;27,97.77,457.62,78.06,7.54" xml:id="_HCf4z3N">A Graph Neural Network Framework for Social Recommendations</title>
		<author>
			<persName coords=""><forename type="first">Wenqi</forename><surname>Fan</surname></persName>
			<idno type="ORCID">0000-0002-4049-1233</idno>
		</author>
		<author>
			<persName coords=""><forename type="first">Yao</forename><surname>Ma</surname></persName>
			<idno type="ORCID">0000-0002-4985-8724</idno>
		</author>
		<author>
			<persName coords=""><forename type="first">Qing</forename><surname>Li</surname></persName>
			<idno type="ORCID">0000-0003-3370-471X</idno>
		</author>
		<author>
			<persName coords=""><forename type="first">Jianping</forename><surname>Wang</surname></persName>
			<idno type="ORCID">0000-0002-9318-1482</idno>
		</author>
		<author>
			<persName coords=""><forename type="first">Guoyong</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jiliang</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dawei</forename><surname>Yin</surname></persName>
		</author>
		<idno type="DOI">10.1109/tkde.2020.3008732</idno>
		<ptr target="https://doi.org/10.1109/TKDE.2020.3008732" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_DDgQCtx" coord="27,182.53,457.62,171.91,7.54">IEEE Transactions on Knowledge and Data Engineering</title>
		<title level="j" type="abbrev">IEEE Trans. Knowl. Data Eng.</title>
		<idno type="ISSN">1041-4347</idno>
		<idno type="ISSNe">2326-3865</idno>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2033" to="2047" />
			<date type="published" when="2022-05-01">2022. 2022</date>
			<publisher>Institute of Electrical and Electronics Engineers (IEEE)</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Wenqi Fan, Yao Ma, Qing Li, Jianping Wang, Guoyong Cai, Jiliang Tang, and Dawei Yin. 2022. A Graph Neural Network Framework for Social Recommendations. IEEE Transactions on Knowledge and Data Engineering 34, 5 (2022), 2033ś2047. https://doi.org/10.1109/TKDE. 2020.3008732</note>
</biblStruct>

<biblStruct coords="27,97.77,477.55,402.34,7.54" xml:id="b18">
	<analytic>
		<title level="a" type="main" xml:id="_G4VqkHn">Hypergraph Neural Networks</title>
		<author>
			<persName coords=""><forename type="first">Yifan</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Haoxuan</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rongrong</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yue</forename><surname>Gao</surname></persName>
		</author>
		<idno type="DOI">10.1609/aaai.v33i01.33013558</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_y8Py6K2">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<title level="j" type="abbrev">AAAI</title>
		<idno type="ISSN">2159-5399</idno>
		<idno type="ISSNe">2374-3468</idno>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">01</biblScope>
			<biblScope unit="page" from="3558" to="3565" />
			<date type="published" when="2018">2018. 2018</date>
			<publisher>Association for the Advancement of Artificial Intelligence (AAAI)</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Yifan Feng, Haoxuan You, Zizhao Zhang, Rongrong Ji, and Yue Gao. 2018. Hypergraph Neural Networks. AAAI 2019 (2018).</note>
</biblStruct>

<biblStruct coords="27,97.77,487.51,433.53,7.54;27,97.77,497.47,214.82,7.54" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="27,230.48,487.51,163.65,7.54" xml:id="_tJjAn9n">node2vec</title>
		<author>
			<persName coords=""><forename type="first">Aditya</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<idno type="DOI">10.1145/2939672.2939754</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_tDYmEvt" coord="27,408.68,487.51,122.62,7.54;27,97.77,497.47,211.30,7.54">Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016-08-13">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Aditya Grover and Jure Leskovec. 2016. node2vec: Scalable Feature Learning for Networks. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.</note>
</biblStruct>

<biblStruct coords="27,97.77,507.43,434.76,7.54;27,97.77,517.40,245.00,7.54" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="27,312.26,507.43,217.09,7.54" xml:id="_nUKd57z">CFOND: Consensus Factorization for Co-Clustering Networked Data</title>
		<author>
			<persName coords=""><forename type="first">Ting</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shirui</forename><surname>Pan</surname></persName>
			<idno type="ORCID">0000-0003-0794-527X</idno>
		</author>
		<author>
			<persName coords=""><forename type="first">Xingquan</forename><surname>Zhu</surname></persName>
			<idno type="ORCID">0000-0003-4129-9611</idno>
		</author>
		<author>
			<persName coords=""><forename type="first">Chengqi</forename><surname>Zhang</surname></persName>
			<idno type="ORCID">0000-0001-5715-7154</idno>
		</author>
		<idno type="DOI">10.1109/tkde.2018.2846555</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_cDmKgRj" coord="27,97.77,517.40,174.16,7.54">IEEE Transactions on Knowledge and Data Engineering</title>
		<title level="j" type="abbrev">IEEE Trans. Knowl. Data Eng.</title>
		<idno type="ISSN">1041-4347</idno>
		<idno type="ISSNe">2326-3865</idno>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="706" to="719" />
			<date type="published" when="2018">2018. 2018</date>
			<publisher>Institute of Electrical and Electronics Engineers (IEEE)</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Ting Guo, Shirui Pan, Xingquan Zhu, and Chengqi Zhang. 2018. CFOND: consensus factorization for co-clustering networked data. IEEE Transactions on Knowledge and Data Engineering 31, 4 (2018), 706ś719.</note>
</biblStruct>

<biblStruct coords="27,97.77,527.36,434.76,7.54;27,97.77,537.32,162.46,7.54" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="27,314.71,527.36,115.58,7.54" xml:id="_PQ3PzRv">Heterogeneous Graph Transformer</title>
		<author>
			<persName coords=""><forename type="first">Ziniu</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yuxiao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kuansan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
		<idno type="DOI">10.1145/3366423.3380027</idno>
		<idno type="arXiv">arXiv:2003.01332</idno>
		<ptr target="https://arxiv.org/abs/2003.01332" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_ePqRpjB">Proceedings of The Web Conference 2020</title>
		<meeting>The Web Conference 2020</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2020-04-20">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ziniu Hu, Yuxiao Dong, Kuansan Wang, and Yizhou Sun. 2020. Heterogeneous Graph Transformer. CoRR abs/2003.01332 (2020). arXiv:2003.01332 https://arxiv.org/abs/2003.01332</note>
</biblStruct>

<biblStruct coords="27,97.77,547.28,434.76,7.54;27,97.77,557.25,433.53,7.54;27,97.77,567.21,314.30,7.54" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="27,97.77,557.25,264.21,7.54" xml:id="_hTnNZEX">Knowledge-aware Coupled Graph Neural Network for Social Recommendation</title>
		<author>
			<persName coords=""><forename type="first">Chao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Huance</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Peng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lianghao</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mengyin</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Liefeng</forename><surname>Bo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hao</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiaoping</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yanfang</forename><surname>Ye</surname></persName>
		</author>
		<idno type="DOI">10.1609/aaai.v35i5.16533</idno>
		<ptr target="https://ojs.aaai.org/index.php/AAAI/article/view/16533" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_5JmRjJe">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<title level="j" type="abbrev">AAAI</title>
		<idno type="ISSN">2159-5399</idno>
		<idno type="ISSNe">2374-3468</idno>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="4115" to="4122" />
			<date type="published" when="2021-05-18">2021. May 2021</date>
			<publisher>Association for the Advancement of Artificial Intelligence (AAAI)</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Chao Huang, Huance Xu, Yong Xu, Peng Dai, Lianghao Xia, Mengyin Lu, Liefeng Bo, Hao Xing, Xiaoping Lai, and Yanfang Ye. 2021. Knowledge-aware Coupled Graph Neural Network for Social Recommendation. Proceedings of the AAAI Conference on Artiicial Intelligence 35, 5 (May 2021), 4115ś4122. https://ojs.aaai.org/index.php/AAAI/article/view/16533</note>
</biblStruct>

<biblStruct coords="27,97.77,577.17,433.53,7.54;27,97.77,587.13,76.54,7.54" xml:id="b23">
	<analytic>
		<title level="a" type="main" xml:id="_VSwV4Ca">arXiv</title>
		<author>
			<persName coords=""><forename type="first">Po-Yao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Robert</forename><surname>Frederking</surname></persName>
		</author>
		<idno type="DOI">10.1090/mbk/121/79</idno>
		<idno type="arXiv">arXiv:1908.04003</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_HHgMSD2" coord="27,254.19,577.17,222.98,7.54">100 Years of Math Milestones</title>
		<imprint>
			<publisher>American Mathematical Society</publisher>
			<date type="published" when="2019-06-12">2019. 2019</date>
			<biblScope unit="page" from="433" to="437" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Po-Yao Huang, Robert Frederking, et al. 2019. RWR-GAE: Random Walk Regularization for Graph Auto Encoders. arXiv preprint arXiv:1908.04003 (2019).</note>
</biblStruct>

<biblStruct coords="27,97.77,597.10,433.53,7.54;27,97.49,607.06,434.68,7.54;27,97.77,617.02,434.41,7.54;27,97.51,626.99,312.09,7.54" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="27,335.06,597.10,196.24,7.54;27,97.49,607.06,57.69,7.54" xml:id="_fQpg7bc">Joint Weighted Nonnegative Matrix Factorization for Mining Attributed Graphs</title>
		<author>
			<persName coords=""><forename type="first">Zhichao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yunming</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xutao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Feng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Huajie</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-57454-7_29</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-57454-7_29" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_3pWZJ47" coord="27,169.44,607.06,256.72,7.54;27,151.69,617.02,57.03,7.54">Advances in Knowledge Discovery and Data Mining</title>
		<title level="s" xml:id="_cWGJsNj" coord="27,214.71,617.02,104.74,7.54">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Jinho</forename><surname>Kim</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Kyuseok</forename><surname>Shim</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Longbing</forename><surname>Cao</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jae-Gil</forename><surname>Lee</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Xuemin</forename><surname>Lin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Yang-Sae</forename><surname>Moon</surname></persName>
		</editor>
		<meeting><address><addrLine>Jeju, South Korea</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2017-05-23">2017. 2017. May 23-26, 2017</date>
			<biblScope unit="volume">10234</biblScope>
			<biblScope unit="page" from="368" to="380" />
		</imprint>
	</monogr>
	<note>Proceedings, Part I</note>
	<note type="raw_reference">Zhichao Huang, Yunming Ye, Xutao Li, Feng Liu, and Huajie Chen. 2017. Joint Weighted Nonnegative Matrix Factorization for Mining Attributed Graphs. In Advances in Knowledge Discovery and Data Mining -21st Paciic-Asia Conference, PAKDD 2017, Jeju, South Korea, May 23-26, 2017, Proceedings, Part I (Lecture Notes in Computer Science, Vol. 10234), Jinho Kim, Kyuseok Shim, Longbing Cao, Jae-Gil Lee, Xuemin Lin, and Yang-Sae Moon (Eds.). 368ś380. https://doi.org/10.1007/978-3-319-57454-7_29</note>
</biblStruct>

<biblStruct coords="27,97.77,636.95,433.53,7.54;27,97.77,646.91,180.47,7.54" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="27,194.13,636.95,131.67,7.54" xml:id="_VdQPkjY">Normalized cuts and image segmentation</title>
		<author>
			<persName coords=""><forename type="first">Jianbo</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<idno type="DOI">10.1109/34.868688</idno>
		<ptr target="https://doi.org/10.1109/34.868688" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_rDBvwaf" coord="27,332.16,636.95,199.15,7.54">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="888" to="905" />
			<date type="published" when="2000">2000. 2000</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Jianbo Shi and J. Malik. 2000. Normalized cuts and image segmentation. IEEE Transactions on Pattern Analysis and Machine Intelligence 22, 8 (2000), 888ś905. https://doi.org/10.1109/34.868688</note>
</biblStruct>

<biblStruct coords="28,97.77,108.93,433.53,7.54;28,97.77,118.89,398.77,7.54" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="28,388.37,108.93,142.93,7.54;28,97.77,118.89,75.80,7.54" xml:id="_BgCHJmn">HyperGraph Convolution Based Attributed HyperGraph Clustering</title>
		<author>
			<persName coords=""><forename type="first">Fanseu</forename><surname>Barakeel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lin</forename><surname>Kamhoua</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kaili</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bo</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_4zTENxd" coord="28,187.51,118.89,305.12,7.54">Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management</title>
		<meeting>the 30th ACM International Conference on Information &amp; Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Barakeel Fanseu Kamhoua, Lin Zhang, Kaili Ma, James Cheng, Bo Li, and Bo Han. 2021. HyperGraph Convolution Based Attributed HyperGraph Clustering. In Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management.</note>
</biblStruct>

<biblStruct coords="28,97.77,128.85,403.96,7.54" xml:id="b27">
	<analytic>
		<title level="a" type="main" coord="28,227.86,128.85,107.16,7.54" xml:id="_hsC4P7X">Variational Graph Auto-Encoders</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_4juVfNt" coord="28,341.49,128.85,136.61,7.54">NIPS Workshop on Bayesian Deep Learning</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Thomas N Kipf and Max Welling. 2016. Variational Graph Auto-Encoders. NIPS Workshop on Bayesian Deep Learning (2016).</note>
</biblStruct>

<biblStruct coords="28,97.77,138.82,433.53,7.54;28,97.77,148.78,113.47,7.54" xml:id="b28">
	<analytic>
		<title level="a" type="main" coord="28,226.21,138.82,214.95,7.54" xml:id="_ts6CZf5">Semi-Supervised Classiication with Graph Convolutional Networks</title>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_bkW2AKa" coord="28,455.08,138.82,76.22,7.54;28,97.77,148.78,110.27,7.54">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Thomas N. Kipf and Max Welling. 2017. Semi-Supervised Classiication with Graph Convolutional Networks. In International Conference on Learning Representations (ICLR).</note>
</biblStruct>

<biblStruct coords="28,97.77,158.74,433.53,7.54;28,97.77,168.70,216.52,7.54" xml:id="b29">
	<analytic>
		<title level="a" type="main" coord="28,251.96,158.74,209.08,7.54" xml:id="_a7YzZpz">Symmetric Nonnegative Matrix Factorization for Graph Clustering</title>
		<author>
			<persName coords=""><forename type="first">Da</forename><surname>Kuang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chris</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Haesun</forename><surname>Park</surname></persName>
		</author>
		<idno type="DOI">10.1137/1.9781611972825.10</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_h6xzgmK" coord="28,474.80,158.74,56.51,7.54;28,97.77,168.70,160.47,7.54">Proceedings of the 2012 SIAM International Conference on Data Mining</title>
		<meeting>the 2012 SIAM International Conference on Data Mining</meeting>
		<imprint>
			<publisher>Society for Industrial and Applied Mathematics</publisher>
			<date type="published" when="2012-04-26">2012</date>
			<biblScope unit="page" from="106" to="117" />
		</imprint>
	</monogr>
	<note type="raw_reference">Da Kuang, Chris Ding, and Haesun Park. 2012. Symmetric nonnegative matrix factorization for graph clustering. In Proceedings of the 2012 SIAM international conference on data mining. SIAM, 106ś117.</note>
</biblStruct>

<biblStruct coords="28,97.77,178.67,434.76,7.54;28,97.77,188.63,434.76,7.54;28,97.59,198.59,18.53,7.54" xml:id="b30">
	<analytic>
		<title level="a" type="main" coord="28,97.77,188.63,198.40,7.54" xml:id="_HWPvwtw">Hypergraph clustering by iteratively reweighted modularity maximization</title>
		<author>
			<persName coords=""><forename type="first">Tarun</forename><surname>Kumar</surname></persName>
			<idno type="ORCID">0000-0001-6265-629X</idno>
		</author>
		<author>
			<persName coords=""><forename type="first">Sankaran</forename><surname>Vaidyanathan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Harini</forename><surname>Ananthapadmanabhan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Srinivasan</forename><surname>Parthasarathy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Balaraman</forename><surname>Ravindran</surname></persName>
		</author>
		<idno type="DOI">10.1007/s41109-020-00300-3</idno>
		<idno type="arXiv">arXiv:1812.10869</idno>
		<ptr target="http://arxiv.org/abs/1812.10869" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_YmxMmmt">Applied Network Science</title>
		<title level="j" type="abbrev">Appl Netw Sci</title>
		<idno type="ISSNe">2364-8228</idno>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2018">2018. 2018</date>
			<publisher>Springer Science and Business Media LLC</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Tarun Kumar, Sankaran Vaidyanathan, Harini Ananthapadmanabhan, Srinivasan Parthasarathy, and Balaraman Ravindran. 2018. Hypergraph Clustering: A Modularity Maximization Approach. CoRR abs/1812.10869 (2018). arXiv:1812.10869 http://arxiv.org/abs/1812. 10869</note>
</biblStruct>

<biblStruct coords="28,97.77,208.55,433.53,7.54;28,97.77,218.52,434.41,7.54;28,97.77,228.48,420.78,7.54" xml:id="b31">
	<analytic>
		<title level="a" type="main" coord="28,247.47,208.55,165.50,7.54" xml:id="_TbYRSjF">Algorithms for Non-negative Matrix Factorization</title>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">Sebastian</forename><surname>Seung</surname></persName>
		</author>
		<ptr target="http://papers.nips.cc/paper/1861-algorithms-for-non-negative-matrix-factorization" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_QAZtTKy" coord="28,427.36,208.55,103.94,7.54;28,97.77,218.52,261.51,7.54">Advances in Neural Information Processing Systems 13, Papers from Neural Information Processing Systems (NIPS) 2000</title>
		<editor>
			<persName><forename type="first">Thomas</forename><forename type="middle">G</forename><surname>Leen</surname></persName>
		</editor>
		<editor>
			<persName><surname>Dietterich</surname></persName>
		</editor>
		<editor>
			<persName><surname>Volker Tresp</surname></persName>
		</editor>
		<meeting><address><addrLine>Denver, CO, USA, Todd</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">556</biblScope>
		</imprint>
	</monogr>
	<note type="raw_reference">Daniel D. Lee and H. Sebastian Seung. 2000. Algorithms for Non-negative Matrix Factorization. In Advances in Neural Information Processing Systems 13, Papers from Neural Information Processing Systems (NIPS) 2000, Denver, CO, USA, Todd K. Leen, Thomas G. Dietterich, and Volker Tresp (Eds.). MIT Press, 556ś562. http://papers.nips.cc/paper/1861-algorithms-for-non-negative-matrix-factorization</note>
</biblStruct>

<biblStruct coords="28,97.77,238.44,340.74,7.54" xml:id="b32">
	<analytic>
		<title level="a" type="main" xml:id="_DurDu9p">Semi-supervised learning and optimization for hypergraph matching</title>
		<author>
			<persName coords=""><forename type="first">Marius</forename><surname>Leordeanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrei</forename><surname>Zanfir</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Cristian</forename><surname>Sminchisescu</surname></persName>
		</author>
		<idno type="DOI">10.1109/iccv.2011.6126507</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_UjtvPz7" coord="28,268.20,238.44,103.26,7.54">2011 International Conference on Computer Vision</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012-01">2012. 01 2012</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Marius Leordeanu and Cristian Sminchisescu. 2012. Eicient Hypergraph Clustering. AISTATS (01 2012).</note>
</biblStruct>

<biblStruct coords="28,97.77,248.40,433.53,7.54;28,97.77,258.37,434.76,7.54;28,97.77,268.33,302.23,7.54" xml:id="b33">
	<analytic>
		<title level="a" type="main" coord="28,236.40,248.40,174.72,7.54" xml:id="_YG8e3ff">Learning to Discover Social Circles in Ego Networks</title>
		<author>
			<persName coords=""><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2012/ile/" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_tddVH8U" coord="28,426.59,248.40,104.72,7.54;28,97.77,258.37,60.03,7.54">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">F</forename><surname>Pereira</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">J C</forename><surname>Burges</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="539" to="547" />
		</imprint>
	</monogr>
	<note>a614fd06c325499f1680b9896beedeb-Paper.pdf</note>
	<note type="raw_reference">Jure Leskovec and Julian Mcauley. 2012. Learning to Discover Social Circles in Ego Networks. In Advances in Neural Information Processing Systems, F. Pereira, C. J. C. Burges, L. Bottou, and K. Q. Weinberger (Eds.), Vol. 25. Curran Associates, Inc., 539ś547. https://proceedings.neurips.cc/paper/2012/ile/7a614fd06c325499f1680b9896beedeb-Paper.pdf</note>
</biblStruct>

<biblStruct coords="28,97.77,278.29,433.53,7.54;28,97.77,288.26,388.36,7.54" xml:id="b34">
	<analytic>
		<title level="a" type="main" coord="28,337.96,278.29,193.35,7.54;28,97.77,288.26,110.49,7.54" xml:id="_qBEekXS">Scalable Graph Convolutional Networks With Fast Localized Spectral Filter for Directed Graphs</title>
		<author>
			<persName coords=""><forename type="first">Chensheng</forename><surname>Li</surname></persName>
			<idno type="ORCID">0000-0002-3500-754X</idno>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiaowei</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiaodong</forename><surname>Xu</surname></persName>
			<idno type="ORCID">0000-0001-9041-3826</idno>
		</author>
		<author>
			<persName coords=""><forename type="first">Dujia</forename><surname>Yang</surname></persName>
			<idno type="ORCID">0000-0002-9309-9067</idno>
		</author>
		<author>
			<persName coords=""><forename type="first">Guo</forename><surname>Wei</surname></persName>
		</author>
		<idno type="DOI">10.1109/access.2020.2999520</idno>
		<ptr target="https://doi.org/10.1109/ACCESS.2020.2999520" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_Pw4MMD4" coord="28,214.75,288.26,37.04,7.54">IEEE Access</title>
		<title level="j" type="abbrev">IEEE Access</title>
		<idno type="ISSNe">2169-3536</idno>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="105634" to="105644" />
			<date type="published" when="2020">2020. 2020</date>
			<publisher>Institute of Electrical and Electronics Engineers (IEEE)</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Chensheng Li, Xiaowei Qin, Xiaodong Xu, Dujia Yang, and Guo Wei. 2020. Scalable Graph Convolutional Networks With Fast Localized Spectral Filter for Directed Graphs. IEEE Access 8 (2020), 105634ś105644. https://doi.org/10.1109/ACCESS.2020.2999520</note>
</biblStruct>

<biblStruct coords="28,97.77,298.22,433.53,7.54;28,97.77,308.18,390.59,7.54" xml:id="b35">
	<analytic>
		<title level="a" type="main" coord="28,416.02,298.22,115.28,7.54;28,97.77,308.18,127.52,7.54" xml:id="_yCCr982">Higher-Order Attribute-Enhancing Heterogeneous Graph Neural Networks</title>
		<author>
			<persName coords=""><forename type="first">Jianxin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yuwei</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yingtong</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hekai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lifang</forename><surname>He</surname></persName>
		</author>
		<idno type="DOI">10.1109/tkde.2021.3074654</idno>
		<idno type="arXiv">arXiv:2104.07892</idno>
		<ptr target="https://arxiv.org/abs/2104.07892" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_mW9TJFf">IEEE Transactions on Knowledge and Data Engineering</title>
		<title level="j" type="abbrev">IEEE Trans. Knowl. Data Eng.</title>
		<idno type="ISSN">1041-4347</idno>
		<idno type="ISSNe">2326-3865</idno>
		<imprint>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2021">2021. 2021</date>
			<publisher>Institute of Electrical and Electronics Engineers (IEEE)</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Jianxin Li, Hao Peng, Yuwei Cao, Yingtong Dou, Hekai Zhang, Philip S. Yu, and Lifang He. 2021. Higher-Order Attribute-Enhancing Heterogeneous Graph Neural Networks. CoRR abs/2104.07892 (2021). arXiv:2104.07892 https://arxiv.org/abs/2104.07892</note>
</biblStruct>

<biblStruct coords="28,97.77,318.14,433.54,7.54;28,97.77,328.11,433.53,7.54;28,97.49,338.07,396.68,7.54" xml:id="b36">
	<analytic>
		<title level="a" type="main" coord="28,220.26,318.14,192.70,7.54" xml:id="_5xbuSeZ">Topic Analysis and Influential Paper Discovery on Scientific Publications</title>
		<author>
			<persName><forename type="first">Ye</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyan</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1109/wisa.2017.69</idno>
		<ptr target="https://proceedings.neurips.cc/paper/2017/ile/" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_ek3HNH2" coord="28,427.44,318.14,103.87,7.54;28,97.77,328.11,58.52,7.54">2017 14th Web Information Systems and Applications Conference (WISA)</title>
		<editor>
			<persName><forename type="first">R</forename><surname>Vishwanathan</surname></persName>
		</editor>
		<editor>
			<persName><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017-11">2017. 2308ś2318</date>
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
	<note>a50abba8132a77191791390c3eb19fe7-Paper.pdf</note>
	<note type="raw_reference">Pan Li and Olgica Milenkovic. 2017. Inhomogeneous Hypergraph Clustering with Applications. In Advances in Neural Information Processing Systems, I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (Eds.), Vol. 30. Curran Associates, Inc., 2308ś2318. https://proceedings.neurips.cc/paper/2017/ile/a50abba8132a77191791390c3eb19fe7-Paper.pdf</note>
</biblStruct>

<biblStruct coords="28,97.77,348.03,433.53,7.54;28,97.77,357.99,203.27,7.54" xml:id="b37">
	<analytic>
		<title level="a" type="main" coord="28,223.13,348.03,280.25,7.54" xml:id="_vvSmThD">Deeper Insights Into Graph Convolutional Networks for Semi-Supervised Learning</title>
		<author>
			<persName><forename type="first">Qimai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhichao</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao-Ming</forename><surname>Wu</surname></persName>
		</author>
		<idno type="DOI">10.1609/aaai.v32i1.11604</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Kt7KmtG">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<title level="j" type="abbrev">AAAI</title>
		<idno type="ISSN">2159-5399</idno>
		<idno type="ISSNe">2374-3468</idno>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2018-04-29">2018</date>
			<publisher>Association for the Advancement of Artificial Intelligence (AAAI)</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Q. Li, Z. Han, and X.-M. Wu. 2018. Deeper Insights into Graph Convolutional Networks for Semi-Supervised Learning. In The Thirty-Second AAAI Conference on Artiicial Intelligence. AAAI.</note>
</biblStruct>

<biblStruct coords="28,97.77,367.96,433.53,7.54;28,97.77,377.92,433.53,7.54;28,97.77,387.88,434.33,7.54;28,97.77,397.84,280.87,7.54" xml:id="b38">
	<analytic>
		<title level="a" type="main" coord="28,276.04,367.96,189.76,7.54" xml:id="_rr8zv6W">Spectral Clustering in Heterogeneous Information Networks</title>
		<author>
			<persName coords=""><forename type="first">Xiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ben</forename><surname>Kao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhaochun</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dawei</forename><surname>Yin</surname></persName>
		</author>
		<idno type="DOI">10.1609/aaai.v33i01.33014221</idno>
		<ptr target="https://doi.org/10.1609/aaai.v33i01.33014221" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_F9FJx3w" coord="28,374.09,387.88,17.40,7.54">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<title level="j" type="abbrev">AAAI</title>
		<idno type="ISSN">2159-5399</idno>
		<idno type="ISSNe">2374-3468</idno>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">01</biblScope>
			<biblScope unit="page" from="4221" to="4228" />
			<date type="published" when="2019-01-27">2019. 2019. January 27 -February 1, 2019</date>
			<publisher>Association for the Advancement of Artificial Intelligence (AAAI)</publisher>
			<pubPlace>Honolulu, Hawaii, USA</pubPlace>
		</imprint>
	</monogr>
	<note type="raw_reference">Xiang Li, Ben Kao, Zhaochun Ren, and Dawei Yin. 2019. Spectral Clustering in Heterogeneous Information Networks. In The Thirty-Third AAAI Conference on Artiicial Intelligence, AAAI 2019, The Thirty-First Innovative Applications of Artiicial Intelligence Conference, IAAI 2019, The Ninth AAAI Symposium on Educational Advances in Artiicial Intelligence, EAAI 2019, Honolulu, Hawaii, USA, January 27 - February 1, 2019. AAAI Press, 4221ś4228. https://doi.org/10.1609/aaai.v33i01.33014221</note>
</biblStruct>

<biblStruct coords="28,97.77,407.81,433.54,7.54;28,97.77,417.77,433.54,7.54;28,97.77,427.73,252.39,7.54" xml:id="b39">
	<analytic>
		<title level="a" type="main" coord="28,206.45,407.81,186.15,7.54" xml:id="_SJr9Rdk">Graph Filter-based Multi-view Attributed Graph Clustering</title>
		<author>
			<persName coords=""><forename type="first">Zhiping</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhao</forename><surname>Kang</surname></persName>
		</author>
		<idno type="DOI">10.24963/ijcai.2021/375</idno>
		<ptr target="https://doi.org/10.24963/ijcai.2021/375MainTrack" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_k8jWC2v" coord="28,405.55,407.81,125.76,7.54;28,97.77,417.77,220.75,7.54;28,340.88,417.77,190.43,7.54;28,97.77,427.73,78.64,7.54">Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence</title>
		<meeting>the Thirtieth International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<publisher>International Joint Conferences on Artificial Intelligence Organization</publisher>
			<date type="published" when="2021-08">2021</date>
		</imprint>
	</monogr>
	<note>International Joint Conferences on Artiicial Intelligence Organization, 2723ś2729</note>
	<note type="raw_reference">Zhiping Lin and Zhao Kang. 2021. Graph Filter-based Multi-view Attributed Graph Clustering. In Proceedings of the Thirtieth International Joint Conference on Artiicial Intelligence, IJCAI-21, Zhi-Hua Zhou (Ed.). International Joint Conferences on Artiicial Intelligence Organization, 2723ś2729. https://doi.org/10.24963/ijcai.2021/375 Main Track.</note>
</biblStruct>

<biblStruct coords="28,97.77,437.69,434.76,7.54;28,97.77,447.66,296.74,7.54" xml:id="b40">
	<analytic>
		<title level="a" type="main" coord="28,329.22,437.69,199.59,7.54" xml:id="_sXMCyfa">Federated Social Recommendation with Graph Neural Network</title>
		<author>
			<persName coords=""><forename type="first">Zhiwei</forename><surname>Liu</surname></persName>
			<idno type="ORCID">0000-0003-1525-1067</idno>
		</author>
		<author>
			<persName coords=""><forename type="first">Liangwei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ziwei</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<idno type="DOI">10.1145/3501815</idno>
		<ptr target="https://doi.org/10.1145/3501815JustAccepted" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_33UPfsX" coord="28,97.77,447.66,102.41,7.54">ACM Transactions on Intelligent Systems and Technology</title>
		<title level="j" type="abbrev">ACM Trans. Intell. Syst. Technol.</title>
		<idno type="ISSN">2157-6904</idno>
		<idno type="ISSNe">2157-6912</idno>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="24" />
			<date type="published" when="2021-11">2021. nov 2021</date>
			<publisher>Association for Computing Machinery (ACM)</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Zhiwei Liu, Liangwei Yang, Ziwei Fan, Hao Peng, and Philip S. Yu. 2021. Federated Social Recommendation with Graph Neural Network. ACM Trans. Intell. Syst. Technol. (nov 2021). https://doi.org/10.1145/3501815 Just Accepted.</note>
</biblStruct>

<biblStruct coords="28,97.77,457.62,434.38,7.54;28,97.77,467.58,35.71,7.54" xml:id="b41">
	<analytic>
		<title/>
		<author>
			<persName coords=""><forename type="first">Ulrike</forename><surname>Luxburg</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11222-007-9033-z</idno>
		<ptr target="https://doi.org/10.1007/s11222-007-9033-z" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_AkZVStb" coord="28,169.22,457.62,188.58,7.54">A Tutorial on Spectral Clustering. Statistics and Computing</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="395" to="416" />
			<date type="published" when="2004-01">2004. 01 2004</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ulrike Luxburg. 2004. A Tutorial on Spectral Clustering. Statistics and Computing 17 (01 2004), 395ś416. https://doi.org/10.1007/s11222- 007-9033-z</note>
</biblStruct>

<biblStruct coords="28,97.77,477.55,433.68,7.54;28,97.77,487.51,311.44,7.54" xml:id="b42">
	<monogr>
		<title level="m" type="main" coord="28,367.88,477.55,163.57,7.54;28,97.77,487.51,51.57,7.54" xml:id="_zwT2Dv8">Spectral-based Graph Convolutional Network for Directed Graphs</title>
		<author>
			<persName coords=""><forename type="first">Yi</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jianye</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yaodong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Han</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Junqi</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Guangyong</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.08990</idno>
		<ptr target="http://arxiv.org/abs/1907.08990" />
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Yi Ma, Jianye Hao, Yaodong Yang, Han Li, Junqi Jin, and Guangyong Chen. 2019. Spectral-based Graph Convolutional Network for Directed Graphs. CoRR abs/1907.08990 (2019). arXiv:1907.08990 http://arxiv.org/abs/1907.08990</note>
</biblStruct>

<biblStruct coords="28,97.77,497.47,433.53,7.54;28,97.77,507.43,317.96,7.54" xml:id="b43">
	<analytic>
		<title level="a" type="main" coord="28,197.29,497.47,244.55,7.54" xml:id="_qnRAmKv">Boise Geothermal Aquifer Study</title>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>Macqueen</surname></persName>
		</author>
		<idno type="DOI">10.2172/6460627</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_NSE9qqN" coord="28,456.72,497.47,74.58,7.54;28,97.77,507.43,198.68,7.54">Proceedings of the ifth Berkeley symposium on mathematical statistics and probability</title>
		<meeting>the ifth Berkeley symposium on mathematical statistics and probability<address><addrLine>Oakland, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Office of Scientific and Technical Information (OSTI)</publisher>
			<date type="published" when="1967">1967</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="281" to="297" />
		</imprint>
	</monogr>
	<note type="raw_reference">James MacQueen et al. 1967. Some methods for classiication and analysis of multivariate observations. In Proceedings of the ifth Berkeley symposium on mathematical statistics and probability, Vol. 1. Oakland, CA, USA, 281ś297.</note>
</biblStruct>

<biblStruct coords="28,97.77,517.40,433.53,7.54;28,97.77,527.36,317.96,7.54" xml:id="b44">
	<analytic>
		<title level="a" type="main" coord="28,197.29,517.40,244.55,7.54" xml:id="_umTZEt7">Boise Geothermal Aquifer Study</title>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>Macqueen</surname></persName>
		</author>
		<idno type="DOI">10.2172/6460627</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_QakxqPS" coord="28,456.72,517.40,74.58,7.54;28,97.77,527.36,198.68,7.54">Proceedings of the ifth Berkeley symposium on mathematical statistics and probability</title>
		<meeting>the ifth Berkeley symposium on mathematical statistics and probability<address><addrLine>Oakland, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Office of Scientific and Technical Information (OSTI)</publisher>
			<date type="published" when="1967">1967</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="281" to="297" />
		</imprint>
	</monogr>
	<note type="raw_reference">James MacQueen et al. 1967. Some methods for classiication and analysis of multivariate observations. In Proceedings of the ifth Berkeley symposium on mathematical statistics and probability, Vol. 1. Oakland, CA, USA, 281ś297.</note>
</biblStruct>

<biblStruct coords="28,97.77,537.32,433.53,7.54;28,97.77,547.28,222.79,7.54" xml:id="b45">
	<monogr>
		<title level="m" type="main" coord="28,282.39,537.32,225.43,7.54" xml:id="_QpqVnDD">Clustering and Community Detection in Directed Networks: A Survey</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Fragkiskos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michalis</forename><surname>Malliaros</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Vazirgiannis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1308.0971</idno>
		<ptr target="http://arxiv.org/abs/1308.0971" />
		<imprint>
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Fragkiskos D. Malliaros and Michalis Vazirgiannis. 2013. Clustering and Community Detection in Directed Networks: A Survey. CoRR abs/1308.0971 (2013). arXiv:1308.0971 http://arxiv.org/abs/1308.0971</note>
</biblStruct>

<biblStruct coords="28,97.77,557.25,433.53,7.54;28,97.77,567.21,434.40,7.54;28,97.77,577.17,434.77,7.54;28,97.39,587.13,373.59,7.54" xml:id="b46">
	<analytic>
		<title level="a" type="main" coord="28,241.37,557.25,171.83,7.54" xml:id="_Wy9GrqJ">Learning to Discover Social Circles in Ego Networks</title>
		<author>
			<persName coords=""><forename type="first">Julian</forename><forename type="middle">J</forename><surname>Mcauley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<ptr target="http://papers.nips.cc/paper/4532-learning-to-discover-social-circles-in-ego-networks" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_ftYcxcc" coord="28,427.83,557.25,103.47,7.54;28,97.77,567.21,373.63,7.54">Advances in Neural Information Processing Systems 25: 26th Annual Conference on Neural Information Processing Systems 2012. Proceedings of a meeting</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Burges</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Kilian</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</editor>
		<meeting><address><addrLine>Lake Tahoe, Nevada, United States, Peter L. Bartlett, Fernando C. N. Pereira, Christopher</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-12-03">2012. December 3-6, 2012</date>
			<biblScope unit="volume">548</biblScope>
		</imprint>
	</monogr>
	<note type="raw_reference">Julian J. McAuley and Jure Leskovec. 2012. Learning to Discover Social Circles in Ego Networks. In Advances in Neural Information Processing Systems 25: 26th Annual Conference on Neural Information Processing Systems 2012. Proceedings of a meeting held December 3-6, 2012, Lake Tahoe, Nevada, United States, Peter L. Bartlett, Fernando C. N. Pereira, Christopher J. C. Burges, Léon Bottou, and Kilian Q. Weinberger (Eds.). 548ś556. http://papers.nips.cc/paper/4532-learning-to-discover-social-circles-in-ego-networks</note>
</biblStruct>

<biblStruct coords="28,97.77,597.10,433.53,7.54;28,97.77,607.06,363.89,7.54" xml:id="b47">
	<analytic>
		<title level="a" type="main" coord="28,274.09,597.10,198.57,7.54" xml:id="_EEWg9dD">Dependency Networks for Relational Data</title>
		<author>
			<persName coords=""><forename type="first">Jennifer</forename><surname>Neville</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Jensen</surname></persName>
		</author>
		<idno type="DOI">10.1109/icdm.2004.10101</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_JVVA7HQ" coord="28,494.89,597.10,36.42,7.54;28,97.77,607.06,360.44,7.54">Fourth IEEE International Conference on Data Mining (ICDM&apos;04)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
	<note type="raw_reference">Jennifer Neville, Micah Adler, and David Jensen. 2003. Clustering relational data using attribute and link information. In In Proceedings of the Text Mining and Link Analysis Workshop, 18th International Joint Conference on Artiicial Intelligence. 9ś15.</note>
</biblStruct>

<biblStruct coords="28,97.77,617.02,433.69,7.54;28,97.77,626.99,131.06,7.54" xml:id="b48">
	<analytic>
		<title level="a" type="main" coord="28,371.88,617.02,159.58,7.54;28,97.77,626.99,55.54,7.54" xml:id="_Jn8GBng">Adversarially Regularized Graph Autoencoder for Graph Embedding</title>
		<author>
			<persName coords=""><forename type="first">Ruiqi</forename><surname>Shirui Pan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Guodong</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jing</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lina</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chengqi</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_vUknsTf" coord="28,171.33,626.99,16.45,7.54">IJCAI</title>
		<imprint>
			<date type="published" when="2018">2018. 2609ś2615</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Shirui Pan, Ruiqi Hu, Guodong Long, Jing Jiang, Lina Yao, and Chengqi Zhang. 2018. Adversarially Regularized Graph Autoencoder for Graph Embedding.. In IJCAI. 2609ś2615.</note>
</biblStruct>

<biblStruct coords="28,97.77,636.95,433.53,7.54;28,97.77,646.91,287.52,7.54" xml:id="b49">
	<analytic>
		<title level="a" type="main" coord="28,277.73,636.95,167.38,7.54" xml:id="_Xvhyr7K">DeepWalk</title>
		<author>
			<persName coords=""><forename type="first">Bryan</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rami</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Steven</forename><surname>Skiena</surname></persName>
		</author>
		<idno type="DOI">10.1145/2623330.2623732</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_7SNzErj" coord="28,459.02,636.95,72.28,7.54;28,97.77,646.91,253.68,7.54">Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 20th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014-08-24">2014</date>
			<biblScope unit="volume">701</biblScope>
		</imprint>
	</monogr>
	<note type="raw_reference">Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. Deepwalk: Online learning of social representations. In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining. 701ś710.</note>
</biblStruct>

<biblStruct coords="29,97.77,108.93,433.53,7.54;29,97.77,118.89,433.53,7.54" xml:id="b50">
	<analytic>
		<title level="a" type="main" coord="29,239.03,108.93,280.89,7.54" xml:id="_BgBgeHK">Community detection using nonnegative matrix factorization with orthogonal constraint</title>
		<author>
			<persName coords=""><forename type="first">Yaoyao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Caiyan</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yafang</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICACI.2016.7449802</idno>
		<ptr target="https://doi.org/10.1109/ICACI.2016.7449802" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_Md6Wt6r" coord="29,97.77,118.89,265.89,7.54">2016 Eighth International Conference on Advanced Computational Intelligence (ICACI)</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="49" to="54" />
		</imprint>
	</monogr>
	<note type="raw_reference">Yaoyao Qin, Caiyan Jia, and Yafang Li. 2016. Community detection using nonnegative matrix factorization with orthogonal constraint. In 2016 Eighth International Conference on Advanced Computational Intelligence (ICACI). 49ś54. https://doi.org/10.1109/ICACI.2016.7449802</note>
</biblStruct>

<biblStruct coords="29,97.77,128.85,434.41,7.54;29,97.59,138.82,321.31,7.54" xml:id="b51">
	<analytic>
		<title level="a" type="main" coord="29,166.86,128.85,221.21,7.54" xml:id="_dNEV4vx">On the Laplacian Eigenvalues and Metric Parameters of Hypergraphs</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Rodriguez</surname></persName>
		</author>
		<idno type="DOI">10.1080/03081080290011692</idno>
		<ptr target="https://doi.org/10.1080/03081080290011692" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_G2uAn8W" coord="29,394.60,128.85,97.78,7.54">Linear and Multilinear Algebra</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2002">2002. 2002</date>
		</imprint>
	</monogr>
	<note type="raw_reference">J.A. Rodriguez. 2002. On the Laplacian Eigenvalues and Metric Parameters of Hypergraphs. Linear and Multilinear Algebra 50, 1 (2002), 1ś14. https://doi.org/10.1080/03081080290011692 arXiv:https://doi.org/10.1080/03081080290011692</note>
</biblStruct>

<biblStruct coords="29,97.77,148.78,433.53,7.54;29,97.77,158.74,433.68,7.54;29,97.77,168.70,316.40,7.54" xml:id="b52">
	<analytic>
		<title level="a" type="main" coord="29,300.71,148.78,180.95,7.54" xml:id="_9VmEDxg">Spectral Clustering of Attributed Multi-Relational Graphs</title>
		<author>
			<persName coords=""><forename type="first">Ylli</forename><surname>Sadikaj</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yllka</forename><surname>Velaj</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sahar</forename><surname>Behzadi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Claudia</forename><surname>Plant</surname></persName>
		</author>
		<idno type="DOI">10.1145/3447548.3467381</idno>
		<ptr target="https://doi.org/10.1145/3447548.3467381" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_TZHTuY5" coord="29,495.22,148.78,36.09,7.54;29,97.77,158.74,378.68,7.54">Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (Virtual Event, Singapore) (KDD &apos;21)</title>
		<meeting>the 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (Virtual Event, Singapore) (KDD &apos;21)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1431" to="1440" />
		</imprint>
	</monogr>
	<note type="raw_reference">Ylli Sadikaj, Yllka Velaj, Sahar Behzadi, and Claudia Plant. 2021. Spectral Clustering of Attributed Multi-Relational Graphs. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (Virtual Event, Singapore) (KDD &apos;21). Association for Computing Machinery, New York, NY, USA, 1431ś1440. https://doi.org/10.1145/3447548.3467381</note>
</biblStruct>

<biblStruct coords="29,97.77,178.67,433.72,7.54;29,97.53,188.63,183.55,7.54" xml:id="b53">
	<monogr>
		<title level="m" type="main" coord="29,283.80,178.67,175.23,7.54" xml:id="_B8F9ruZ">Hypergraph p-Laplacian: A Diferential Geometry View</title>
		<author>
			<persName coords=""><forename type="first">Shota</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Danilo</forename><forename type="middle">P</forename><surname>Mandic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hideyuki</forename><surname>Suzuki</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.08171</idno>
		<ptr target="http://arxiv.org/abs/1711.08171" />
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Shota Saito, Danilo P. Mandic, and Hideyuki Suzuki. 2017. Hypergraph p-Laplacian: A Diferential Geometry View. CoRR abs/1711.08171 (2017). arXiv:1711.08171 http://arxiv.org/abs/1711.08171</note>
</biblStruct>

<biblStruct coords="29,97.77,198.59,433.69,7.54;29,97.77,208.55,308.99,7.54" xml:id="b54">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Venu</forename><surname>Satuluri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Srinivasan</forename><surname>Parthasarathy</surname></persName>
		</author>
		<idno type="DOI">10.1145/1951365.1951407</idno>
		<ptr target="https://doi.org/10.1145/1951365.1951407" />
		<title level="m" xml:id="_3UMECd4" coord="29,263.49,198.59,213.59,7.54">Symmetrizations for Clustering Directed Graphs (EDBT/ICDT &apos;11)</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="343" to="354" />
		</imprint>
	</monogr>
	<note type="raw_reference">Venu Satuluri and Srinivasan Parthasarathy. 2011. Symmetrizations for Clustering Directed Graphs (EDBT/ICDT &apos;11). Association for Computing Machinery, New York, NY, USA, 343ś354. https://doi.org/10.1145/1951365.1951407</note>
</biblStruct>

<biblStruct coords="29,97.77,218.52,434.41,7.54;29,97.59,228.48,162.31,7.54" xml:id="b55">
	<analytic>
		<title level="a" type="main" coord="29,229.66,218.52,203.54,7.54" xml:id="_8ZXCsKK">SPECTRAL CLUSTERING IN HETEROGENEOUS NETWORKS</title>
		<author>
			<persName coords=""><forename type="first">Srijan</forename><surname>Sengupta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yuguo</forename><surname>Chen</surname></persName>
		</author>
		<ptr target="http://www.jstor.org/stable/24721222" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_TV7xHEv" coord="29,440.93,218.52,50.66,7.54">Statistica Sinica</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<date type="published" when="2015">2015. 2015. 1081ś1106</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Srijan Sengupta and Yuguo Chen. 2015. SPECTRAL CLUSTERING IN HETEROGENEOUS NETWORKS. Statistica Sinica 25, 3 (2015), 1081ś1106. http://www.jstor.org/stable/24721222</note>
</biblStruct>

<biblStruct coords="29,97.77,238.44,433.68,7.54;29,97.77,248.40,317.99,7.54" xml:id="b56">
	<monogr>
		<title level="m" type="main" coord="29,388.41,238.44,143.04,7.54;29,97.77,248.40,54.73,7.54" xml:id="_9x6Hbgh">Heterogeneous Graph Neural Network for Recommendation</title>
		<author>
			<persName coords=""><forename type="first">Jinghan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Houye</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhiqiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jun</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.00799</idno>
		<ptr target="https://arxiv.org/abs/2009.00799" />
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Jinghan Shi, Houye Ji, Chuan Shi, Xiao Wang, Zhiqiang Zhang, and Jun Zhou. 2020. Heterogeneous Graph Neural Network for Recommendation. CoRR abs/2009.00799 (2020). arXiv:2009.00799 https://arxiv.org/abs/2009.00799</note>
</biblStruct>

<biblStruct coords="29,97.77,258.37,434.47,7.54;29,97.77,268.33,434.76,7.54;29,97.77,278.29,134.61,7.54" xml:id="b57">
	<analytic>
		<title level="a" type="main" coord="29,363.62,258.37,168.62,7.54;29,97.77,268.33,264.04,7.54" xml:id="_6zpgtUS">The emerging field of signal processing on graphs: Extending high-dimensional data analysis to networks and other irregular domains</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">I</forename><surname>Shuman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">K</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Frossard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ortega</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
		<idno type="DOI">10.1109/msp.2012.2235192</idno>
		<ptr target="https://doi.org/10.1109/MSP.2012.2235192" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_7jxByhe" coord="29,368.26,268.33,102.03,7.54">IEEE Signal Processing Magazine</title>
		<title level="j" type="abbrev">IEEE Signal Process. Mag.</title>
		<idno type="ISSN">1053-5888</idno>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="83" to="98" />
			<date type="published" when="2013-05">2013. 2013</date>
			<publisher>Institute of Electrical and Electronics Engineers (IEEE)</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">D. I. Shuman, S. K. Narang, P. Frossard, A. Ortega, and P. Vandergheynst. 2013. The emerging ield of signal processing on graphs: Extending high-dimensional data analysis to networks and other irregular domains. IEEE Signal Processing Magazine 30, 3 (2013), 83ś98. https://doi.org/10.1109/MSP.2012.2235192</note>
</biblStruct>

<biblStruct coords="29,97.77,288.26,433.74,7.54;29,97.77,298.22,434.47,7.54;29,97.51,308.18,83.16,7.54" xml:id="b58">
	<analytic>
		<title level="a" type="main" coord="29,502.33,288.26,29.18,7.54;29,97.77,298.22,207.47,7.54" xml:id="_cxEg73m">Network Embedding for Community Detection in Attributed Networks</title>
		<author>
			<persName coords=""><forename type="first">Heli</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fang</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jianbin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chenyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Liang</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhongbin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiaolin</forename><surname>Jia</surname></persName>
		</author>
		<idno type="DOI">10.1145/3385415</idno>
		<ptr target="https://doi.org/10.1145/3385415" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_Mt54zDD" coord="29,314.55,298.22,108.29,7.54">ACM Trans. Knowl. Discov. Data</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1" to="36" />
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Heli Sun, Fang He, Jianbin Huang, Yizhou Sun, Yang Li, Chenyu Wang, Liang He, Zhongbin Sun, and Xiaolin Jia. 2020. Network Embedding for Community Detection in Attributed Networks. ACM Trans. Knowl. Discov. Data 14, 3 (2020), 36:1ś36:25. https: //doi.org/10.1145/3385415</note>
</biblStruct>

<biblStruct coords="29,97.77,318.14,433.53,7.54;29,97.77,328.11,434.76,7.54;29,97.77,338.07,129.31,7.54" xml:id="b59">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Peixiang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhijun</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hong</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tianyi</forename><surname>Wu</surname></persName>
		</author>
		<idno type="DOI">10.1145/1516360.1516426</idno>
		<ptr target="https://doi.org/10.1145/1516360.1516426" />
		<title level="m" xml:id="_b7R8ym2" coord="29,380.06,318.14,151.25,7.54;29,97.77,328.11,201.21,7.54">RankClus: Integrating Clustering with Ranking for Heterogeneous Information Network Analysis (EDBT &apos;09)</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="565" to="576" />
		</imprint>
	</monogr>
	<note type="raw_reference">Yizhou Sun, Jiawei Han, Peixiang Zhao, Zhijun Yin, Hong Cheng, and Tianyi Wu. 2009. RankClus: Integrating Clustering with Ranking for Heterogeneous Information Network Analysis (EDBT &apos;09). Association for Computing Machinery, New York, NY, USA, 565ś576. https://doi.org/10.1145/1516360.1516426</note>
</biblStruct>

<biblStruct coords="29,97.77,348.03,433.74,7.54;29,97.77,357.99,434.05,7.54;29,97.59,367.96,53.64,7.54" xml:id="b60">
	<monogr>
		<title level="m" type="main" coord="29,250.87,348.03,280.64,7.54;29,97.77,357.99,319.99,7.54" xml:id="_s6mhTba">Ranking-based clustering of heterogeneous information networks with star network schema. Ranking-Based Clustering of Heterogeneous Information Networks with Star Network Schema</title>
		<author>
			<persName coords=""><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yintao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
		<idno type="DOI">10.1145/1557019.1557107</idno>
		<ptr target="https://doi.org/10.1145/1557019.1557107" />
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="797" to="806" />
		</imprint>
	</monogr>
	<note type="raw_reference">Yizhou Sun, Yintao Yu, and Jiawei Han. 2009. Ranking-based clustering of heterogeneous information networks with star network schema. Ranking-Based Clustering of Heterogeneous Information Networks with Star Network Schema, 797ś806. https://doi.org/10.1145/ 1557019.1557107</note>
</biblStruct>

<biblStruct coords="29,97.77,377.92,433.74,7.54;29,97.77,387.88,433.53,7.54;29,96.92,397.84,375.84,7.54" xml:id="b61">
	<analytic>
		<title level="a" type="main" coord="29,247.84,377.92,283.67,7.54;29,97.77,387.88,22.57,7.54" xml:id="_S87vjn6">Ranking-Based Clustering of Heterogeneous Information Networks with Star Network Schema</title>
		<author>
			<persName coords=""><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yintao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
		<idno type="DOI">10.1145/1557019.1557107</idno>
		<ptr target="https://doi.org/10.1145/1557019.1557107" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_y3syeGr" coord="29,134.64,387.88,328.91,7.54;29,517.94,387.88,13.37,7.54;29,96.92,397.84,10.77,7.54">Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining<address><addrLine>Paris, France; New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="797" to="806" />
		</imprint>
	</monogr>
	<note>KDD &apos;09)</note>
	<note type="raw_reference">Yizhou Sun, Yintao Yu, and Jiawei Han. 2009. Ranking-Based Clustering of Heterogeneous Information Networks with Star Network Schema. In Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (Paris, France) (KDD &apos;09). Association for Computing Machinery, New York, NY, USA, 797ś806. https://doi.org/10.1145/1557019.1557107</note>
</biblStruct>

<biblStruct coords="29,97.77,407.81,434.76,7.54;29,97.77,417.77,129.31,7.54" xml:id="b62">
	<monogr>
		<title level="m" type="main" coord="29,347.34,407.81,142.69,7.54" xml:id="_zBMT2dd">Hypergraph Clustering Based on PageRank</title>
		<author>
			<persName coords=""><forename type="first">Yuuki</forename><surname>Takai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Atsushi</forename><surname>Miyauchi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Masahiro</forename><surname>Ikeda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yuichi</forename><surname>Yoshida</surname></persName>
		</author>
		<idno type="DOI">10.1145/3394486.3403248</idno>
		<ptr target="https://doi.org/10.1145/3394486.3403248" />
		<imprint>
			<date type="published" when="2020">2020. 1970ś1978</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Yuuki Takai, Atsushi Miyauchi, Masahiro Ikeda, and Yuichi Yoshida. 2020. Hypergraph Clustering Based on PageRank. 1970ś1978. https://doi.org/10.1145/3394486.3403248</note>
</biblStruct>

<biblStruct coords="29,97.77,427.73,433.53,7.54;29,97.77,437.69,434.41,7.54;29,97.51,447.66,434.64,7.54;29,97.77,457.62,30.65,7.54" xml:id="b63">
	<analytic>
		<title level="a" type="main" coord="29,422.29,427.73,109.01,7.54;29,97.77,437.69,29.75,7.54" xml:id="_bNHp6wh">Digraph Inception Convolutional Networks</title>
		<author>
			<persName coords=""><forename type="first">Zekun</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yuxuan</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Changsheng</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xinke</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Rosenblum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrew</forename><surname>Lim</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2020/ile/cfb" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_G8nr8Ja" coord="29,141.91,437.69,161.47,7.54">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Larochelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Ranzato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Hadsell</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Balcan</surname></persName>
		</editor>
		<editor>
			<persName><surname>Lin</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2020">2020. 17907ś17918</date>
			<biblScope unit="volume">33</biblScope>
		</imprint>
	</monogr>
	<note type="raw_reference">Zekun Tong, Yuxuan Liang, Changsheng Sun, Xinke Li, David Rosenblum, and Andrew Lim. 2020. Digraph Inception Convolutional Networks. In Advances in Neural Information Processing Systems, H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin (Eds.), Vol. 33. Curran Associates, Inc., 17907ś17918. https://proceedings.neurips.cc/paper/2020/ile/cfb6e2288a630c2a787a64ccc67097c- Paper.pdf</note>
</biblStruct>

<biblStruct coords="29,97.77,467.58,434.76,7.54;29,97.77,477.55,408.69,7.54" xml:id="b64">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Petar</forename><surname>Veličković</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Arantxa</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pietro</forename><surname>Liò</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=rJXMpikCZ" />
		<title level="m" xml:id="_CRQyv4m" coord="29,445.33,467.58,87.20,7.54;29,97.77,477.55,168.96,7.54">Graph Attention Networks. International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note>accepted as poster</note>
	<note type="raw_reference">Petar Veličković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Liò, and Yoshua Bengio. 2018. Graph Attention Networks. International Conference on Learning Representations (2018). https://openreview.net/forum?id=rJXMpikCZ accepted as poster.</note>
</biblStruct>

<biblStruct coords="29,97.77,487.51,433.53,7.54;29,97.77,497.47,434.76,7.54;29,97.49,507.43,435.04,7.54;29,97.77,517.40,28.52,7.54" xml:id="b65">
	<analytic>
		<title level="a" type="main" coord="29,377.42,487.51,153.88,7.54;29,97.77,497.47,68.99,7.54" xml:id="_kh4kmqm">Attributed Graph Clustering: a Deep Attentional Embedding approach</title>
		<author>
			<persName coords=""><forename type="first">Chun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shirui</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ruiqi</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Guodong</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chengqi</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.24963/ijcai.2019/509</idno>
		<ptr target="https://doi.org/10.24963/ijcai.2019/509" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_ZqnUcpX" coord="29,182.01,497.47,331.05,7.54;29,97.49,507.43,294.97,7.54">Proceedings of the Twenty-Eighth International Joint Conference on Artiicial Intelligence, Sarit Kraus</title>
		<meeting>the Twenty-Eighth International Joint Conference on Artiicial Intelligence, Sarit Kraus</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3670" to="3676" />
		</imprint>
	</monogr>
	<note>Association for the Advancement of Artiicial Intelligence (AAAI), United States of America</note>
	<note type="raw_reference">Chun Wang, Shirui Pan, Ruiqi Hu, Guodong Long, Jing Jiang, and Chengqi Zhang. 2019. Attributed Graph Clustering: a Deep Attentional Embedding approach. In Proceedings of the Twenty-Eighth International Joint Conference on Artiicial Intelligence, Sarit Kraus (Ed.). Association for the Advancement of Artiicial Intelligence (AAAI), United States of America, 3670ś3676. https://doi.org/10.24963/ijcai. 2019/509</note>
</biblStruct>

<biblStruct coords="29,97.77,527.36,434.76,7.54;29,97.77,537.32,321.35,7.54" xml:id="b66">
	<analytic>
		<title level="a" type="main" coord="29,341.76,527.36,187.73,7.54" xml:id="_nBKUFw8">MGAE</title>
		<author>
			<persName coords=""><forename type="first">Chun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shirui</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Guodong</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xingquan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
		<idno type="DOI">10.1145/3132847.3132967</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_VmpfaJf" coord="29,106.45,537.32,278.40,7.54">Proceedings of the 2017 ACM on Conference on Information and Knowledge Management</title>
		<meeting>the 2017 ACM on Conference on Information and Knowledge Management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017-11-06">2017</date>
			<biblScope unit="page" from="889" to="898" />
		</imprint>
	</monogr>
	<note type="raw_reference">Chun Wang, Shirui Pan, Guodong Long, Xingquan Zhu, and Jing Jiang. 2017. Mgae: Marginalized graph autoencoder for graph clustering. In Proceedings of the 2017 ACM on Conference on Information and Knowledge Management. 889ś898.</note>
</biblStruct>

<biblStruct coords="29,97.77,547.28,433.53,7.54;29,97.77,557.25,434.41,7.54;29,97.49,567.21,433.81,7.54" xml:id="b67">
	<analytic>
		<title level="a" type="main" coord="29,246.66,547.28,114.50,7.54" xml:id="_HM3fna7">Structural Deep Network Embedding</title>
		<author>
			<persName coords=""><forename type="first">Daixin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Peng</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wenwu</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="DOI">10.1145/2939672.2939753</idno>
		<ptr target="https://doi.org/10.1145/2939672.2939753" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_WhgTXCw" coord="29,374.17,547.28,157.13,7.54;29,97.77,557.25,170.58,7.54">Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<editor>
			<persName><forename type="first">Balaji</forename><surname>Krishnapuram</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Mohak</forename><surname>Shah</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Alexander</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Charu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Dou</forename><surname>Aggarwal</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Rajeev</forename><surname>Shen</surname></persName>
		</editor>
		<editor>
			<persName><surname>Rastogi</surname></persName>
		</editor>
		<meeting>the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016-08-13">2016. August 13-17, 2016</date>
			<biblScope unit="page" from="1225" to="1234" />
		</imprint>
	</monogr>
	<note type="raw_reference">Daixin Wang, Peng Cui, and Wenwu Zhu. 2016. Structural Deep Network Embedding. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, San Francisco, CA, USA, August 13-17, 2016, Balaji Krishnapuram, Mohak Shah, Alexander J. Smola, Charu C. Aggarwal, Dou Shen, and Rajeev Rastogi (Eds.). ACM, 1225ś1234. https://doi.org/10.1145/2939672.2939753</note>
</biblStruct>

<biblStruct coords="29,97.77,577.17,433.53,7.54;29,97.77,587.13,433.53,7.54;29,97.77,597.10,433.72,7.54" xml:id="b68">
	<analytic>
		<title level="a" type="main" coord="29,349.56,577.17,181.74,7.54;29,97.77,587.13,30.16,7.54" xml:id="_XP3XgfA">Semantic Community Identification in Large Attribute Networks</title>
		<author>
			<persName coords=""><forename type="first">Xiao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Di</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiaochun</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Liang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Weixiong</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1609/aaai.v30i1.9977</idno>
		<ptr target="http://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/11964" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_RH5jw5J">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<title level="j" type="abbrev">AAAI</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Michael</surname></persName>
		</editor>
		<editor>
			<persName><surname>Wellman</surname></persName>
		</editor>
		<idno type="ISSN">2159-5399</idno>
		<idno type="ISSNe">2374-3468</idno>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="265" to="271" />
			<date type="published" when="2016-02-12">2016. February 12-17, 2016</date>
			<publisher>Association for the Advancement of Artificial Intelligence (AAAI)</publisher>
			<pubPlace>Phoenix, Arizona, USA</pubPlace>
		</imprint>
	</monogr>
	<note type="raw_reference">Xiao Wang, Di Jin, Xiaochun Cao, Liang Yang, and Weixiong Zhang. 2016. Semantic Community Identiication in Large Attribute Networks. In Proceedings of the Thirtieth AAAI Conference on Artiicial Intelligence, February 12-17, 2016, Phoenix, Arizona, USA, Dale Schuurmans and Michael P. Wellman (Eds.). AAAI Press, 265ś271. http://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/11964</note>
</biblStruct>

<biblStruct coords="29,97.77,607.06,433.53,7.54;29,97.77,617.02,290.27,7.54" xml:id="b69">
	<analytic>
		<title level="a" type="main" coord="29,279.69,607.06,251.61,7.54;29,97.77,617.02,27.48,7.54" xml:id="_CxSHJTR">Self-supervised Heterogeneous Graph Neural Network with Co-contrastive Learning</title>
		<author>
			<persName coords=""><forename type="first">Xiao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hui</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chuan</forename><surname>Shi</surname></persName>
		</author>
		<idno type="DOI">10.1145/3447548.3467415</idno>
		<idno type="arXiv">arXiv:2105.09111</idno>
		<ptr target="https://arxiv.org/abs/2105.09111" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_FR2eGJZ">Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2021-08-14">2021. 2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Xiao Wang, Nian Liu, Hui Han, and Chuan Shi. 2021. Self-supervised Heterogeneous Graph Neural Network with Co-contrastive Learning. CoRR abs/2105.09111 (2021). arXiv:2105.09111 https://arxiv.org/abs/2105.09111</note>
</biblStruct>

<biblStruct coords="29,97.77,626.99,434.47,7.54;29,97.77,636.95,434.76,7.54;29,97.59,646.91,74.74,7.54" xml:id="b70">
	<analytic>
		<title level="a" type="main" coord="29,507.76,626.99,24.49,7.54;29,97.77,636.95,175.16,7.54" xml:id="_2NZgTRJ">MEGA</title>
		<author>
			<persName coords=""><forename type="first">Joyce</forename><forename type="middle">Jiyoung</forename><surname>Whang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rundong</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sangwon</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Geon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Barry</forename><surname>Drake</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Qingqing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Seonggoo</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Haesun</forename><surname>Park</surname></persName>
		</author>
		<idno type="DOI">10.14778/3377369.3377378</idno>
		<ptr target="https://doi.org/10.14778/3377369.3377378" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_7sesxWt">Proceedings of the VLDB Endowment</title>
		<title level="j" type="abbrev">Proc. VLDB Endow.</title>
		<idno type="ISSN">2150-8097</idno>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="698" to="711" />
			<date type="published" when="2020-01">2020. 01 2020</date>
			<publisher>Association for Computing Machinery (ACM)</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Joyce Whang, Rundong Du, Sangwon Jung, Geon Lee, Barry Drake, Qingqing Liu, Seonggoo Kang, and Haesun Park. 2020. MEGA: multi-view semi-supervised clustering of hypergraphs. Proceedings of the VLDB Endowment 13 (01 2020), 698ś711. https://doi.org/10. 14778/3377369.3377378</note>
</biblStruct>

<biblStruct coords="30,97.77,108.93,433.53,7.54;30,97.77,118.89,328.48,7.54" xml:id="b71">
	<analytic>
		<title level="a" type="main" coord="30,420.00,108.93,111.30,7.54;30,97.77,118.89,29.75,7.54" xml:id="_QcvQ9Tq">Simplifying Graph Convolutional Networks</title>
		<author>
			<persName coords=""><forename type="first">Felix</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Amauri</forename><surname>Souza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tianyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christopher</forename><surname>Fifty</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kilian</forename><surname>Weinberger</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_vWvd5ux" coord="30,141.91,118.89,219.61,7.54">Proceedings of the 36th International Conference on Machine Learning</title>
		<meeting>the 36th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="6861" to="6871" />
		</imprint>
	</monogr>
	<note type="raw_reference">Felix Wu, Amauri Souza, Tianyi Zhang, Christopher Fifty, Tao Yu, and Kilian Weinberger. 2019. Simplifying Graph Convolutional Networks. In Proceedings of the 36th International Conference on Machine Learning. PMLR, 6861ś6871.</note>
</biblStruct>

<biblStruct coords="30,97.77,128.85,433.53,7.54;30,97.77,138.82,313.78,7.54" xml:id="b72">
	<monogr>
		<title level="m" type="main" coord="30,415.50,128.85,115.80,7.54;30,97.77,138.82,53.82,7.54" xml:id="_NMCChaq">A Comprehensive Survey on Graph Neural Networks</title>
		<author>
			<persName coords=""><forename type="first">Zonghan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shirui</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fengwen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Guodong</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chengqi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.00596</idno>
		<ptr target="http://arxiv.org/abs/1901.00596" />
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and Philip S. Yu. 2019. A Comprehensive Survey on Graph Neural Networks. CoRR abs/1901.00596 (2019). arXiv:1901.00596 http://arxiv.org/abs/1901.00596</note>
</biblStruct>

<biblStruct coords="30,97.77,148.78,431.64,7.54" xml:id="b73">
	<analytic>
		<title level="a" type="main" coord="30,241.87,148.78,254.08,7.54" xml:id="_jpKTubr">Robust Multi-View Spectral Clustering via Low-Rank and Sparse Decomposition</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Rongkai Xia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lei</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_strUmFN" coord="30,509.87,148.78,15.63,7.54">AAAI</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Rongkai Xia, Y. Pan, Lei Du, and J. Yin. 2014. Robust Multi-View Spectral Clustering via Low-Rank and Sparse Decomposition. In AAAI.</note>
</biblStruct>

<biblStruct coords="30,97.77,158.74,433.53,7.54;30,97.77,168.70,247.99,7.54" xml:id="b74">
	<analytic>
		<title level="a" type="main" coord="30,305.95,158.74,132.53,7.54" xml:id="_eaRg7sX">How Powerful are Graph Neural Networks</title>
		<author>
			<persName coords=""><forename type="first">Keyulu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=ryGs6iA5Km" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_rVgU7PG" coord="30,455.36,158.74,75.94,7.54;30,97.77,168.70,87.66,7.54">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. 2019. How Powerful are Graph Neural Networks?. In International Conference on Learning Representations. https://openreview.net/forum?id=ryGs6iA5Km</note>
</biblStruct>

<biblStruct coords="30,97.77,178.67,433.53,7.54;30,97.77,188.63,434.40,7.54;30,97.77,198.59,434.76,7.54;30,97.77,208.55,121.89,7.54" xml:id="b75">
	<analytic>
		<title level="a" type="main" coord="30,233.95,178.67,209.19,7.54" xml:id="_vMJDczV">Document clustering based on non-negative matrix factorization</title>
		<author>
			<persName coords=""><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yihong</forename><surname>Gong</surname></persName>
		</author>
		<idno type="DOI">10.1145/860435.860485</idno>
		<ptr target="https://doi.org/10.1145/860435.860485" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_Ewqjrjg" coord="30,456.87,178.67,74.44,7.54;30,97.77,188.63,352.02,7.54">Proceedings of the 26th annual international ACM SIGIR conference on Research and development in informaion retrieval</title>
		<editor>
			<persName><forename type="first">Gordon</forename><forename type="middle">V</forename><surname>Clarke</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jamie</forename><surname>Cormack</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">David</forename><surname>Callan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Alan</forename><forename type="middle">F</forename><surname>Hawking</surname></persName>
		</editor>
		<editor>
			<persName><surname>Smeaton</surname></persName>
		</editor>
		<meeting>the 26th annual international ACM SIGIR conference on Research and development in informaion retrieval<address><addrLine>Toronto, Canada, Charles L. A.</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2003-07-28">2003. July 28 -August 1, 2003</date>
			<biblScope unit="page" from="267" to="273" />
		</imprint>
	</monogr>
	<note type="raw_reference">Wei Xu, Xin Liu, and Yihong Gong. 2003. Document clustering based on non-negative matrix factorization. In SIGIR 2003: Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, July 28 -August 1, 2003, Toronto, Canada, Charles L. A. Clarke, Gordon V. Cormack, Jamie Callan, David Hawking, and Alan F. Smeaton (Eds.). ACM, 267ś273. https://doi.org/10.1145/860435.860485</note>
</biblStruct>

<biblStruct coords="30,97.77,218.52,434.76,7.54;30,97.77,228.48,434.05,7.54;30,97.77,238.44,53.64,7.54" xml:id="b76">
	<analytic>
		<title level="a" type="main" coord="30,345.65,218.52,183.72,7.54" xml:id="_zD2p7PN">A model-based approach to attributed graph clustering</title>
		<author>
			<persName coords=""><forename type="first">Zhiqiang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yiping</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hong</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>Cheng</surname></persName>
		</author>
		<idno type="DOI">10.1145/2213836.2213894</idno>
		<ptr target="https://doi.org/10.1145/2213836.2213894" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_7caPu3a" coord="30,97.77,228.48,333.14,7.54">Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data</title>
		<meeting>the 2012 ACM SIGMOD International Conference on Management of Data</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012-05-20">2012. 2012</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Zhiqiang Xu, Yiping Ke, Yi Wang, Hong Cheng, and James Cheng. 2012. A model-based approach to attributed graph clustering. Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data, SIGMOD &apos;12 (05 2012). https://doi.org/10.1145/ 2213836.2213894</note>
</biblStruct>

<biblStruct coords="30,97.77,248.40,433.53,7.54;30,97.77,258.37,434.41,7.54;30,97.77,268.33,434.05,7.54;30,97.77,278.29,53.64,7.54" xml:id="b77">
	<analytic>
		<title level="a" type="main" coord="30,338.52,248.40,180.80,7.54" xml:id="_DZHe5zC">A model-based approach to attributed graph clustering</title>
		<author>
			<persName coords=""><forename type="first">Zhiqiang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yiping</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hong</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>Cheng</surname></persName>
		</author>
		<idno type="DOI">10.1145/2213836.2213894</idno>
		<ptr target="https://doi.org/10.1145/2213836.2213894" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_H2hQu3H" coord="30,97.77,258.37,261.97,7.54">Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Selçuk Candan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Yi</forename><surname>Chen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Richard</forename><forename type="middle">T</forename><surname>Snodgrass</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Luis</forename><surname>Gravano</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ariel</forename><surname>Fuxman</surname></persName>
		</editor>
		<meeting>the 2012 ACM SIGMOD International Conference on Management of Data<address><addrLine>Scottsdale, AZ, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012-05-20">2012. 2012. May 20-24, 2012</date>
			<biblScope unit="page" from="505" to="516" />
		</imprint>
	</monogr>
	<note type="raw_reference">Zhiqiang Xu, Yiping Ke, Yi Wang, Hong Cheng, and James Cheng. 2012. A model-based approach to attributed graph clustering. In Proceedings of the ACM SIGMOD International Conference on Management of Data, SIGMOD 2012, Scottsdale, AZ, USA, May 20-24, 2012, K. Selçuk Candan, Yi Chen, Richard T. Snodgrass, Luis Gravano, and Ariel Fuxman (Eds.). ACM, 505ś516. https://doi.org/10.1145/ 2213836.2213894</note>
</biblStruct>

<biblStruct coords="30,97.77,288.26,433.53,7.54;30,97.77,298.22,315.58,7.54" xml:id="b78">
	<analytic>
		<title level="a" type="main" coord="30,330.92,288.26,200.38,7.54;30,97.77,298.22,32.60,7.54" xml:id="_enuPXwV">GBAGC</title>
		<author>
			<persName coords=""><forename type="first">Zhiqiang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yiping</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hong</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>Cheng</surname></persName>
		</author>
		<idno type="DOI">10.1145/2629616</idno>
		<ptr target="https://doi.org/10.1145/2629616" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_DchaX5E" coord="30,136.50,298.22,103.46,7.54">ACM Transactions on Knowledge Discovery from Data</title>
		<title level="j" type="abbrev">ACM Trans. Knowl. Discov. Data</title>
		<idno type="ISSN">1556-4681</idno>
		<idno type="ISSNe">1556-472X</idno>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="43" />
			<date type="published" when="2014-08-25">2014. 2014</date>
			<publisher>Association for Computing Machinery (ACM)</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Zhiqiang Xu, Yiping Ke, Yi Wang, Hong Cheng, and James Cheng. 2014. GBAGC: A General Bayesian Framework for Attributed Graph Clustering. ACM Trans. Knowl. Discov. Data 9, 1 (2014), 5:1ś5:43. https://doi.org/10.1145/2629616</note>
</biblStruct>

<biblStruct coords="30,97.77,308.18,433.83,7.54;30,97.77,318.14,434.04,7.54;30,97.77,328.11,125.34,7.54" xml:id="b79">
	<analytic>
		<title level="a" type="main" coord="30,467.08,308.18,64.52,7.54;30,97.77,318.14,224.65,7.54" xml:id="_xKdWVw2">NHP: Neural Hypergraph Link Prediction</title>
		<author>
			<persName coords=""><forename type="first">Naganand</forename><surname>Yadati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vikram</forename><surname>Nitin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Madhav</forename><surname>Nimishakavi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Prateek</forename><surname>Yadav</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anand</forename><surname>Louis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Partha</forename><surname>Talukdar</surname></persName>
		</author>
		<idno type="DOI">10.1145/3340531.3411870</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_2qp2MUs" coord="30,337.61,318.14,194.20,7.54">Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management</title>
		<meeting>the 29th ACM International Conference on Information &amp; Knowledge Management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019. 1509ś1520</date>
			<biblScope unit="page">32</biblScope>
		</imprint>
	</monogr>
	<note type="raw_reference">Naganand Yadati, Madhav Nimishakavi, Prateek Yadav, Vikram Nitin, Anand Louis, and Partha Talukdar. 2019. HyperGCN: A New Method For Training Graph Convolutional Networks on Hypergraphs. In Advances in Neural Information Processing Systems (NeurIPS) 32. Curran Associates, Inc., 1509ś1520.</note>
</biblStruct>

<biblStruct coords="30,97.77,338.07,433.53,7.54;30,97.77,348.03,434.41,7.54;30,97.77,357.99,421.86,7.54" xml:id="b80">
	<analytic>
		<title level="a" type="main" coord="30,367.64,338.07,163.65,7.54;30,97.77,348.03,38.19,7.54" xml:id="_XNp6yXU">Artificial Intelligence for Knowledge Management</title>
		<author>
			<persName coords=""><forename type="first">Cheng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Deli</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Edward</forename><forename type="middle">Y</forename><surname>Chang</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-55970-4</idno>
		<ptr target="http://ijcai.org/Abstract/15/299" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_ttvX5DM" coord="30,151.68,348.03,330.67,7.54">Proceedings of the Twenty-Fourth International Joint Conference on Artiicial Intelligence, IJCAI 2015</title>
		<editor>
			<persName><forename type="first">Qiang</forename><surname>Yang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Wooldridge</surname></persName>
		</editor>
		<meeting>the Twenty-Fourth International Joint Conference on Artiicial Intelligence, IJCAI 2015<address><addrLine>Buenos Aires, Argentina</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2015-07-25">2015. July 25-31, 2015. 2111ś2117</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Cheng Yang, Zhiyuan Liu, Deli Zhao, Maosong Sun, and Edward Y. Chang. 2015. Network Representation Learning with Rich Text Information. In Proceedings of the Twenty-Fourth International Joint Conference on Artiicial Intelligence, IJCAI 2015, Buenos Aires, Argentina, July 25-31, 2015, Qiang Yang and Michael J. Wooldridge (Eds.). AAAI Press, 2111ś2117. http://ijcai.org/Abstract/15/299</note>
</biblStruct>

<biblStruct coords="30,97.77,367.96,433.53,7.54;30,97.77,377.92,434.41,7.54;30,97.77,387.88,373.22,7.54" xml:id="b81">
	<analytic>
		<title level="a" type="main" coord="30,285.88,367.96,184.93,7.54" xml:id="_WwJxnGT">Community Detection in Networks with Node Attributes</title>
		<author>
			<persName coords=""><forename type="first">Jaewon</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Julian</forename><forename type="middle">J</forename><surname>Mcauley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<idno type="DOI">10.1109/icdm.2013.167</idno>
		<ptr target="https://doi.org/10.1109/ICDM.2013.167" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_npdzzGf" coord="30,484.65,367.96,46.65,7.54;30,97.77,377.92,126.72,7.54">2013 IEEE 13th International Conference on Data Mining</title>
		<editor>
			<persName><forename type="first">Hui</forename><surname>Xiong</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">George</forename><surname>Karypis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Bhavani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Diane</forename><forename type="middle">J</forename><surname>Thuraisingham</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Xindong</forename><surname>Cook</surname></persName>
		</editor>
		<editor>
			<persName><surname>Wu</surname></persName>
		</editor>
		<meeting><address><addrLine>Dallas, TX, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013-12-07">2013. December 7-10, 2013</date>
			<biblScope unit="page" from="1151" to="1156" />
		</imprint>
	</monogr>
	<note type="raw_reference">Jaewon Yang, Julian J. McAuley, and Jure Leskovec. 2013. Community Detection in Networks with Node Attributes. In 2013 IEEE 13th International Conference on Data Mining, Dallas, TX, USA, December 7-10, 2013, Hui Xiong, George Karypis, Bhavani M. Thuraisingham, Diane J. Cook, and Xindong Wu (Eds.). IEEE Computer Society, 1151ś1156. https://doi.org/10.1109/ICDM.2013.167</note>
</biblStruct>

<biblStruct coords="30,97.77,397.84,433.53,7.54;30,97.49,407.81,434.29,7.54;30,97.28,417.77,395.99,7.54" xml:id="b82">
	<analytic>
		<title level="a" type="main" coord="30,291.80,397.84,239.50,7.54;30,97.49,407.81,30.55,7.54" xml:id="_E56dWvw">Combining link and content for community detection</title>
		<author>
			<persName coords=""><forename type="first">Tianbao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rong</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yun</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shenghuo</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="DOI">10.1145/1557019.1557120</idno>
		<ptr target="https://doi.org/10.1145/1557019.1557120" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_QdRCxWX" coord="30,142.66,407.81,339.64,7.54;30,101.82,417.77,26.37,7.54">Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 15th ACM SIGKDD international conference on Knowledge discovery and data mining<address><addrLine>Paris, France; New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009-06-28">2009</date>
			<biblScope unit="page" from="927" to="936" />
		</imprint>
	</monogr>
	<note>KDD &apos;09)</note>
	<note type="raw_reference">Tianbao Yang, Rong Jin, Yun Chi, and Shenghuo Zhu. 2009. Combining Link and Content for Community Detection: A Discriminative Approach. In Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (Paris, France) (KDD &apos;09). Association for Computing Machinery, New York, NY, USA, 927ś936. https://doi.org/10.1145/1557019.1557120</note>
</biblStruct>

<biblStruct coords="30,97.77,427.73,434.76,7.54;30,97.77,437.69,123.18,7.54" xml:id="b83">
	<analytic>
		<title level="a" type="main" coord="30,297.36,427.73,194.76,7.54" xml:id="_p5KKpKT">Attributed Graph Clustering via Adaptive Graph Convolution</title>
		<author>
			<persName coords=""><forename type="first">Xiaotong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Han</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Qimai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiao-Ming</forename><surname>Wu</surname></persName>
		</author>
		<idno type="DOI">10.24963/ijcai.2019/601</idno>
		<ptr target="https://doi.org/10.24963/ijcai.2019/601" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_v8rBQt8">Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence</title>
		<meeting>the Twenty-Eighth International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<publisher>International Joint Conferences on Artificial Intelligence Organization</publisher>
			<date type="published" when="2019-08">2019</date>
			<biblScope unit="page" from="4327" to="4333" />
		</imprint>
	</monogr>
	<note type="raw_reference">Xiaotong Zhang, Han Liu, Qimai Li, and Xiao-Ming Wu. 2019. Attributed Graph Clustering via Adaptive Graph Convolution. 4327ś4333. https://doi.org/10.24963/ijcai.2019/601</note>
</biblStruct>

<biblStruct coords="30,97.77,447.66,434.76,7.54;30,97.77,457.62,390.16,7.54" xml:id="b84">
	<analytic>
		<title level="a" type="main" coord="30,304.58,447.66,224.16,7.54" xml:id="_arRe79v">Learning with Hypergraphs: Clustering, Classification, and Embedding</title>
		<author>
			<persName coords=""><forename type="first">Dengyong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jiayuan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bernhard</forename><surname>Schölkopf</surname></persName>
		</author>
		<idno type="DOI">10.7551/mitpress/7503.003.0205</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_es3KDDR" coord="30,97.77,457.62,283.73,7.54">Advances in Neural Information Processing Systems 19</title>
		<imprint>
			<publisher>The MIT Press</publisher>
			<date type="published" when="2006">2006. 2007. 1601ś1608</date>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="1601" to="1608" />
		</imprint>
	</monogr>
	<note type="raw_reference">Dengyong Zhou, Jiayuan Huang, and Bernhard Schölkopf. 2006. Learning with Hypergraphs: Clustering, Classiication, and Embedding. Advances in Neural Information Processing Systems 19: Proceedings of the 2006 Conference, 1601-1608 (2007) 19, 1601ś1608.</note>
</biblStruct>

<biblStruct coords="30,97.77,467.58,434.76,7.54;30,97.77,477.55,242.41,7.54" xml:id="b85">
	<analytic>
		<title level="a" type="main" xml:id="_jYQHYNt">Learning from labeled and unlabeled data on a directed graph</title>
		<author>
			<persName coords=""><forename type="first">Dengyong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jiayuan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Schölkopf</surname></persName>
		</author>
		<idno type="DOI">10.1145/1102351.1102482</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_wZFree5" coord="30,97.77,477.55,218.78,7.54">Proceedings of the 22nd international conference on Machine learning - ICML &apos;05</title>
		<meeting>the 22nd international conference on Machine learning - ICML &apos;05</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2005">2005. 2005</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Dengyong Zhou, Jiayuan Huang, and Bernhard Scholkopf. 2005. Learning from labeled and unlabeled data on a directed graph. Proceedings of the 22nd international conference on Machine learning (2005).</note>
</biblStruct>

<biblStruct coords="30,97.77,487.51,433.53,7.54;30,97.77,497.47,343.50,7.54" xml:id="b86">
	<analytic>
		<title level="a" type="main" coord="30,405.88,487.51,125.42,7.54;30,97.77,497.47,83.95,7.54" xml:id="_aQErNGR">Graph neural networks: A review of methods and applications</title>
		<author>
			<persName coords=""><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ganqu</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengding</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhengyan</forename><surname>Zhang</surname></persName>
			<idno type="ORCID">0000-0003-2988-0083</idno>
		</author>
		<author>
			<persName coords=""><forename type="first">Cheng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lifeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changcheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.aiopen.2021.01.001</idno>
		<idno type="arXiv">arXiv:1812.08434</idno>
		<ptr target="http://arxiv.org/abs/1812.08434" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_Dvcq7Y3">AI Open</title>
		<title level="j" type="abbrev">AI Open</title>
		<idno type="ISSN">2666-6510</idno>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="57" to="81" />
			<date type="published" when="2018">2018. 2018</date>
			<publisher>Elsevier BV</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Jie Zhou, Ganqu Cui, Zhengyan Zhang, Cheng Yang, Zhiyuan Liu, and Maosong Sun. 2018. Graph Neural Networks: A Review of Methods and Applications. CoRR abs/1812.08434 (2018). arXiv:1812.08434 http://arxiv.org/abs/1812.08434</note>
</biblStruct>

<biblStruct coords="30,97.77,507.43,434.41,7.54;30,97.59,517.40,28.36,7.54" xml:id="b87">
	<analytic>
		<title level="a" type="main" coord="30,237.21,507.43,196.89,7.54" xml:id="_z9qDRe9">Graph clustering based on structural/attribute similarities</title>
		<author>
			<persName><forename type="first">Yang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hong</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><forename type="middle">Xu</forename><surname>Yu</surname></persName>
		</author>
		<idno type="DOI">10.14778/1687627.1687709</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_spPGN6W">Proceedings of the VLDB Endowment</title>
		<title level="j" type="abbrev">Proc. VLDB Endow.</title>
		<idno type="ISSN">2150-8097</idno>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="718" to="729" />
			<date type="published" when="2009-08">2009. 2009</date>
			<publisher>Association for Computing Machinery (ACM)</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Y. Zhou, Hong Cheng, and J. X. Yu. 2009. Graph Clustering Based on Structural/Attribute Similarities. Proc. VLDB Endow. 2 (2009), 718ś729.</note>
</biblStruct>

<biblStruct coords="30,97.77,527.36,433.72,7.54;30,97.53,537.32,189.55,7.54" xml:id="b88">
	<analytic>
		<title level="a" type="main" coord="30,261.49,527.36,191.17,7.54" xml:id="_dcprfZs">Graph clustering based on structural/attribute similarities</title>
		<author>
			<persName coords=""><forename type="first">Yang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hong</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><forename type="middle">Xu</forename><surname>Yu</surname></persName>
		</author>
		<idno type="DOI">10.14778/1687627.1687709</idno>
		<ptr target="https://doi.org/10.14778/1687627.1687709" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_TTJFnTY">Proceedings of the VLDB Endowment</title>
		<title level="j" type="abbrev">Proc. VLDB Endow.</title>
		<idno type="ISSN">2150-8097</idno>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="718" to="729" />
			<date type="published" when="2009-08">2009. 2009</date>
			<publisher>Association for Computing Machinery (ACM)</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Yang Zhou, Hong Cheng, and Jefrey Xu Yu. 2009. Graph Clustering Based on Structural/Attribute Similarities. Proc. VLDB Endow. 2, 1 (2009), 718ś729. https://doi.org/10.14778/1687627.1687709</note>
</biblStruct>

<biblStruct coords="30,97.77,547.28,433.53,7.54;30,97.77,557.25,433.53,7.54;30,97.77,567.21,410.59,7.54" xml:id="b89">
	<analytic>
		<title level="a" type="main" coord="30,263.88,547.28,233.86,7.54" xml:id="_8QDq5Hu">Clustering Large Attributed Graphs: An Efficient Incremental Approach</title>
		<author>
			<persName coords=""><forename type="first">Yang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hong</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><forename type="middle">Xu</forename><surname>Yu</surname></persName>
		</author>
		<idno type="DOI">10.1109/icdm.2010.41</idno>
		<ptr target="https://doi.org/10.1109/ICDM.2010.41" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_j5ZVBFB" coord="30,512.27,547.28,19.04,7.54;30,97.77,557.25,187.75,7.54">2010 IEEE International Conference on Data Mining</title>
		<editor>
			<persName><forename type="first">Dimitrios</forename><surname>Gunopulos</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Xindong</forename><surname>Wu</surname></persName>
		</editor>
		<meeting><address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010-12-17">2010. 14-17 December 2010</date>
			<biblScope unit="page" from="689" to="698" />
		</imprint>
	</monogr>
	<note type="raw_reference">Yang Zhou, Hong Cheng, and Jefrey Xu Yu. 2010. Clustering Large Attributed Graphs: An Eicient Incremental Approach. In ICDM 2010, The 10th IEEE International Conference on Data Mining, Sydney, Australia, 14-17 December 2010, Geofrey I. Webb, Bing Liu, Chengqi Zhang, Dimitrios Gunopulos, and Xindong Wu (Eds.). IEEE Computer Society, 689ś698. https://doi.org/10.1109/ICDM.2010.41</note>
</biblStruct>

<biblStruct coords="30,97.77,577.17,433.69,7.54;30,97.77,587.13,308.99,7.54" xml:id="b90">
	<analytic>
		<title level="a" type="main" coord="30,200.00,577.17,277.13,7.54" xml:id="_q8dEZa7">Social influence based clustering of heterogeneous information networks</title>
		<author>
			<persName coords=""><forename type="first">Yang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ling</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1145/2487575.2487640</idno>
		<ptr target="https://doi.org/10.1145/2487575.2487640" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_JkaA4Yh">Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 19th ACM SIGKDD international conference on Knowledge discovery and data mining<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013-08-11">2013</date>
			<biblScope unit="page" from="338" to="346" />
		</imprint>
	</monogr>
	<note type="raw_reference">Yang Zhou and Ling Liu. 2013. Social Inluence Based Clustering of Heterogeneous Information Networks (KDD &apos;13). Association for Computing Machinery, New York, NY, USA, 338ś346. https://doi.org/10.1145/2487575.2487640</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
